import logging
import numpy as np
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import defaultdict
import sqlite3

logger = logging.getLogger('parser.ai')


class PublicationPredictor:
    """üî• –ü–†–ï–î–°–ö–ê–ó–ê–¢–ï–õ–¨ –í–û–õ–ù –ü–£–ë–õ–ò–ö–ê–¶–ò–ô –°–í–ï–ñ–ò–• –û–ë–™–Ø–í–õ–ï–ù–ò–ô"""

    def __init__(self, db_path="publication_patterns.db"):
        self.db_path = db_path
        self.publication_cycles = {}
        self.learning_rate = 0.1
        self.pattern_confidence = {}
        logger.info("üïí –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    async def predict_publication_time(self, product_data: Dict[str, Any]) -> str:
        """üéØ –ê–°–ò–ù–•–†–û–ù–ù–û–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            # –ò–º–∏—Ç–∏—Ä—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É
            await asyncio.sleep(0.001)

            time_listed = product_data.get('time_listed', 24)

            if time_listed <= 1:
                return "–º–µ–Ω–µ–µ —á–∞—Å–∞ –Ω–∞–∑–∞–¥"
            elif time_listed <= 3:
                return "1-3 —á–∞—Å–∞ –Ω–∞–∑–∞–¥"
            elif time_listed <= 6:
                return "3-6 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥"
            elif time_listed <= 12:
                return "6-12 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥"
            else:
                return "–±–æ–ª–µ–µ 12 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥"

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {e}")
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def get_prediction_stats(self) -> Dict[str, Any]:
        """üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        return {
            'status': 'active',
            'type': 'PublicationPredictor',
            'version': '1.0',
            'categories_analyzed': len(self.publication_cycles),
            'total_publications': sum(data['total_publications'] for data in self.publication_cycles.values())
        }

    async def analyze_publication_patterns(self, found_items):
        """üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π —Å–≤–µ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        try:
            logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –Ω–∞ {len(found_items)} –æ–±—ä—è–≤–ª–µ–Ω–∏—è—Ö...")

            for item in found_items:
                category = item.get('category', 'unknown')
                found_time = item.get('found_at')

                if category and found_time:
                    await self._update_publication_cycle(category, found_time)

            # üî• –ü–ï–†–ï–°–ß–ò–¢–´–í–ê–ï–ú –£–í–ï–†–ï–ù–ù–û–°–¢–¨ –ü–ê–¢–¢–ï–†–ù–û–í
            await self._recalculate_pattern_confidence()

            logger.info("üéØ –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {e}")

    async def _update_publication_cycle(self, category, found_time):
        """üîÑ –û–±–Ω–æ–≤–ª—è–µ—Ç —Ü–∏–∫–ª—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        try:
            if isinstance(found_time, str):
                found_time = datetime.fromisoformat(found_time.replace('Z', '+00:00'))

            if category not in self.publication_cycles:
                self.publication_cycles[category] = {
                    'hourly_pattern': [0] * 24,
                    'daily_pattern': [0] * 7,
                    'weekly_pattern': [0] * 4,
                    'total_publications': 0,
                    'last_updated': found_time.isoformat()
                }

            hour = found_time.hour
            day = found_time.weekday()
            week = found_time.isocalendar()[1] % 4  # –ù–µ–¥–µ–ª—è –º–µ—Å—è—Ü–∞

            # –û–ë–ù–û–í–õ–Ø–ï–ú –ü–ê–¢–¢–ï–†–ù–´
            self.publication_cycles[category]['hourly_pattern'][hour] += 1
            self.publication_cycles[category]['daily_pattern'][day] += 1
            self.publication_cycles[category]['weekly_pattern'][week] += 1
            self.publication_cycles[category]['total_publications'] += 1
            self.publication_cycles[category]['last_updated'] = found_time.isoformat()

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ü–∏–∫–ª–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {e}")

    async def _recalculate_pattern_confidence(self):
        """üéØ –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        for category, data in self.publication_cycles.items():
            total_pubs = data['total_publications']
            if total_pubs > 100:
                self.pattern_confidence[category] = 0.9
            elif total_pubs > 50:
                self.pattern_confidence[category] = 0.7
            elif total_pubs > 20:
                self.pattern_confidence[category] = 0.5
            else:
                self.pattern_confidence[category] = 0.3

    async def predict_next_publication_wave(self, category):
        """üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â—É—é –≤–æ–ª–Ω—É –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        try:
            if category not in self.publication_cycles:
                return await self._get_default_prediction()

            cycle_data = self.publication_cycles[category]

            if cycle_data['total_publications'] < 10:
                return await self._get_default_prediction()

            # üî• –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú –ü–ê–¢–¢–ï–†–ù–´
            hourly_peaks = self._find_peak_hours(cycle_data['hourly_pattern'])
            daily_peaks = self._find_peak_days(cycle_data['daily_pattern'])
            weekly_peaks = self._find_peak_weeks(cycle_data['weekly_pattern'])

            # üî• –†–ê–°–ß–ï–¢ –£–í–ï–†–ï–ù–ù–û–°–¢–ò
            confidence = self._calculate_confidence(cycle_data)

            prediction = {
                'peak_hours': hourly_peaks,
                'peak_days': daily_peaks,
                'peak_weeks': weekly_peaks,
                'confidence': confidence,
                'next_recommended_search': self._get_next_search_time(hourly_peaks),
                'total_analyzed_publications': cycle_data['total_publications']
            }

            logger.info(f"üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è {category}: {prediction}")
            return prediction

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–æ–ª–Ω –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {e}")
            return await self._get_default_prediction()

    def _find_peak_hours(self, hourly_pattern):
        """üïí –ù–∞—Ö–æ–¥–∏—Ç –ø–∏–∫–æ–≤—ã–µ —á–∞—Å—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        if not any(hourly_pattern):
            return [9, 14, 19]  # –£–º–æ–ª—á–∞–Ω–∏—è

        # –ù–û–†–ú–ê–õ–ò–ó–£–ï–ú
        total = sum(hourly_pattern)
        normalized = [count / total for count in hourly_pattern]

        # –ù–ê–•–û–î–ò–ú –ü–ò–ö–ò (–≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ + 1 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)
        mean = np.mean(normalized)
        std = np.std(normalized)
        threshold = mean + std

        peaks = [i for i, value in enumerate(normalized) if value > threshold]

        return peaks if peaks else [i for i, value in enumerate(normalized) if value > mean][:3]

    def _find_peak_days(self, daily_pattern):
        """üìÖ –ù–∞—Ö–æ–¥–∏—Ç –ø–∏–∫–æ–≤—ã–µ –¥–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        if not any(daily_pattern):
            return [0, 1, 2, 3, 4]  # –ë—É–¥–Ω–∏

        # –î–ù–ò –° –í–´–®–ï –°–†–ï–î–ù–ï–ô –ê–ö–¢–ò–í–ù–û–°–¢–¨–Æ
        mean = np.mean(daily_pattern)
        peaks = [i for i, count in enumerate(daily_pattern) if count > mean]

        return peaks if peaks else list(range(7))

    def _find_peak_weeks(self, weekly_pattern):
        """üóìÔ∏è –ù–∞—Ö–æ–¥–∏—Ç –ø–∏–∫–æ–≤—ã–µ –Ω–µ–¥–µ–ª–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        if not any(weekly_pattern):
            return [0, 1, 2, 3]

        mean = np.mean(weekly_pattern)
        peaks = [i for i, count in enumerate(weekly_pattern) if count > mean]

        return peaks if peaks else list(range(4))

    def _calculate_confidence(self, cycle_data):
        """üéØ –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏"""
        total_publications = cycle_data['total_publications']

        if total_publications > 100:
            return 0.9
        elif total_publications > 50:
            return 0.7
        elif total_publications > 20:
            return 0.5
        else:
            return 0.3

    def _get_next_search_time(self, peak_hours):
        """üïê –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç —Å–ª–µ–¥—É—é—â–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞"""
        current_hour = datetime.now().hour

        # –ò–©–ï–ú –°–õ–ï–î–£–Æ–©–ò–ô –ü–ò–ö–û–í–´–ô –ß–ê–°
        future_peaks = [h for h in peak_hours if h > current_hour]
        if future_peaks:
            return min(future_peaks)
        else:
            return min(peak_hours)  # –°–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å

    async def _get_default_prediction(self):
        """üîÑ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'peak_hours': [9, 14, 19],
            'peak_days': list(range(5)),  # –ë—É–¥–Ω–∏
            'peak_weeks': list(range(4)),
            'confidence': 0.1,
            'next_recommended_search': 9,
            'total_analyzed_publications': 0
        }

    async def get_patterns(self):
        """üìä –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∏–∑—É—á–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        return {
            'categories_analyzed': list(self.publication_cycles.keys()),
            'total_categories': len(self.publication_cycles),
            'category_details': {
                category: {
                    'total_publications': data['total_publications'],
                    'confidence': self._calculate_confidence(data),
                    'top_hours': self._find_peak_hours(data['hourly_pattern'])[:3]
                }
                for category, data in self.publication_cycles.items()
            }
        }

    async def get_model_info(self):
        """üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        return await self.get_prediction_stats()

    async def initialize_model(self):
        """üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        try:
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            await self.load_publication_patterns()
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {e}")
            return True

    async def load_publication_patterns(self):
        """üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –∏–∑ —Ñ–∞–π–ª–∞/–ë–î
            pass
        except Exception as e:
            logger.debug(f"üì• –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {e}")