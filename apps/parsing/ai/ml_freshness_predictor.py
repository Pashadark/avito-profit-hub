import logging
import numpy as np
import re
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import joblib
import asyncio

logger = logging.getLogger('parser.ai.freshness')


class MLFreshnessPredictor:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        self.model = None
        self.scaler = None
        self.feature_count = 10
        self.is_trained = False
        self.model_version = "v3.0_ultra_smart"

    # üî• –°–í–û–ô–°–¢–í–ê –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
    @property
    def model(self):
        return self._model

    @model.setter
    def model(self, value):
        if value:
            model_type = type(value).__name__
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {model_type}")

            # üéØ –§–ò–ö–°: –ø—Ä–æ–≤–µ—Ä—è–µ–º –¢–û–õ–¨–ö–û –¥–ª—è VotingRegressor
            if model_type == 'VotingRegressor' and hasattr(value, 'estimators_'):
                print(f"  üéØ VotingRegressor —Å {len(value.estimators_)} estimators")

                # –î–æ–±–∞–≤–ª—è–µ–º __getitem__ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if not hasattr(value, '__getitem__'):
                    def voting_getitem(self, index):
                        if index < len(self.estimators_):
                            return self.estimators_[index]
                        return None

                    value.__getitem__ = voting_getitem.__get__(value, type(value))
                    print("  ‚úÖ __getitem__ –¥–æ–±–∞–≤–ª–µ–Ω")

        self._model = value

    def __getitem__(self, index):
        """üî• –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨: –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫–∞–∫ freshness_predictor[0]"""
        logger.warning(f"‚ö†Ô∏è –ö—Ç–æ-—Ç–æ –ø—ã—Ç–∞–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ MLFreshnessPredictor –ø–æ –∏–Ω–¥–µ–∫—Å—É [{index}]")

        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–æ–¥–µ–ª—å –∏ –æ–Ω–∞ VotingRegressor - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º estimators
        if self.model and hasattr(self.model, 'estimators_') and index < len(self.model.estimators_):
            return self.model.estimators_[index]

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–µ–±—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        return self

    def __setitem__(self, index, value):
        """üî• –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨: —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ –∏–Ω–¥–µ–∫—Å—É"""
        logger.warning(f"‚ö†Ô∏è –ö—Ç–æ-—Ç–æ –ø—ã—Ç–∞–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å MLFreshnessPredictor –ø–æ –∏–Ω–¥–µ–∫—Å—É [{index}]")
        pass

    async def initialize_model(self):
        """üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            loaded = await self.load_model()
            if not loaded:
                logger.info("üß† –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ñ–æ–ª–±—ç–∫")
            else:
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return False

    async def train(self, training_data=None):
        """üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            if training_data is None:
                training_data = self._create_synthetic_data()
                logger.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")

            X, y = [], []

            for item in training_data:
                features = self._extract_features(item)
                if features and len(features) == self.feature_count:
                    X.append(features)
                    freshness_label = self._calculate_freshness_label(item)
                    y.append(freshness_label)

            if len(X) < 10:
                logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return False

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ
            X_scaled = self.scaler.fit_transform(X)

            # üî• –í–û–ó–ú–û–ñ–ù–û–°–¢–¨ –°–û–ó–î–ê–¢–¨ VotingRegressor –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            use_voting = False  # –ú–æ–∂–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å True –¥–ª—è —Ç–µ—Å—Ç–∞
            if use_voting:
                rf1 = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
                rf2 = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)
                self.model = VotingRegressor([('rf1', rf1), ('rf2', rf2)])
                logger.info("üéØ –°–æ–∑–¥–∞—é VotingRegressor –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            else:
                self.model = RandomForestRegressor(
                    n_estimators=100,
                    max_depth=20,
                    random_state=42,
                    min_samples_split=3,
                    min_samples_leaf=2
                )

            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
            cv_scores = cross_val_score(self.model, X_scaled, y, cv=min(3, len(X)), scoring='r2')
            logger.info(f"üéØ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏: {cv_scores}")

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            self.model.fit(X_scaled, y)
            self.is_trained = True

            train_score = self.model.score(X_scaled, y)
            logger.info(f"üöÄ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∞! –¢–æ—á–Ω–æ—Å—Ç—å: {train_score:.3f}, –î–∞–Ω–Ω—ã—Ö: {len(X)}")

            await self._save_model()
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return False

    def _extract_features(self, item):
        """üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()
            time_listed = item.get('time_listed', 24)
            views_count = item.get('views_count', 0)
            seller_rating = item.get('seller_rating', 4.0)
            reviews_count = item.get('reviews_count', 0)

            features = [
                # 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                min(time_listed / 168, 1.0),  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
                1.0 if time_listed <= 1 else 0.0,  # –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ
                1.0 if time_listed <= 6 else 0.0,  # –°–≤–µ–∂–µ–µ

                # 2. –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                1.0 if any(word in title for word in ['—Å—Ä–æ—á–Ω–æ', 'urgent', 'quick']) else 0.0,
                1.0 if any(word in title for word in ['—Å–≤–µ–∂–∏–π', '–Ω–æ–≤—ã–π', 'new', 'fresh']) else 0.0,
                1.0 if any(word in description for word in ['—Å–µ–≥–æ–¥–Ω—è', '–≤—á–µ—Ä–∞', '—Ç–æ–ª—å–∫–æ —á—Ç–æ']) else 0.0,

                # 3. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ —Ä–µ–ø—É—Ç–∞—Ü–∏—è
                min(views_count / 200, 1.0),  # –ü—Ä–æ—Å–º–æ—Ç—Ä—ã
                float(seller_rating) / 5.0,  # –†–µ–π—Ç–∏–Ω–≥
                min(reviews_count / 100, 1.0),  # –û—Ç–∑—ã–≤—ã

                # 4. –ö–∞—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
                min(len(title) / 150, 1.0)  # –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            ]

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
            if len(features) != self.feature_count:
                if len(features) > self.feature_count:
                    features = features[:self.feature_count]
                else:
                    features.extend([0.0] * (self.feature_count - len(features)))

            return features

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return [0.0] * self.feature_count

    def _calculate_freshness_label(self, item):
        """üéØ –†–∞—Å—á–µ—Ç —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        try:
            time_listed = item.get('time_listed', 24)
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()

            base_score = 0.5

            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
            if time_listed <= 0.5:  # 30 –º–∏–Ω—É—Ç
                base_score = 0.95
            elif time_listed <= 2:  # 2 —á–∞—Å–∞
                base_score = 0.85
            elif time_listed <= 6:  # 6 —á–∞—Å–æ–≤
                base_score = 0.70
            elif time_listed <= 24:  # 1 –¥–µ–Ω—å
                base_score = 0.40
            elif time_listed <= 72:  # 3 –¥–Ω—è
                base_score = 0.20
            else:  # > 3 –¥–Ω–µ–π
                base_score = 0.10

            # –ë–æ–Ω—É—Å –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            fresh_keywords = ['—Å—Ä–æ—á–Ω–æ', '—Å–≤–µ–∂–∏–π', '–Ω–æ–≤—ã–π', '—Ç–æ–ª—å–∫–æ —á—Ç–æ', '—Å–µ–≥–æ–¥–Ω—è']
            keyword_bonus = 0.0
            for keyword in fresh_keywords:
                if keyword in title:
                    keyword_bonus += 0.05
                if keyword in description:
                    keyword_bonus += 0.03

            base_score = min(base_score + keyword_bonus, 0.95)

            return base_score

        except:
            return 0.5

    def _create_synthetic_data(self):
        """üîß –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        synthetic_data = []

        # –û—á–µ–Ω—å —Å–≤–µ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (0-2 —á–∞—Å–∞)
        for i in range(20):
            synthetic_data.append({
                'title': f'–°—Ä–æ—á–Ω–æ –ø—Ä–æ–¥–∞–º –Ω–æ–≤—ã–π —Ç–æ–≤–∞—Ä {i}',
                'description': '–¢–æ–ª—å–∫–æ —á—Ç–æ —Ä–∞–∑–º–µ—â–µ–Ω–æ, —Å—Ä–æ—á–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞',
                'time_listed': np.random.uniform(0.1, 2),
                'views_count': np.random.randint(1, 20),
                'seller_rating': np.random.uniform(4.5, 5.0),
                'reviews_count': np.random.randint(10, 100)
            })

        # –°–≤–µ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (2-24 —á–∞—Å–∞)
        for i in range(30):
            synthetic_data.append({
                'title': f'–ü—Ä–æ–¥–∞–º —Ç–æ–≤–∞—Ä {i} –≤ —Ö–æ—Ä–æ—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏',
                'description': '–†–∞–∑–º–µ—â–µ–Ω–æ —Å–µ–≥–æ–¥–Ω—è, —Ö–æ—Ä–æ—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ',
                'time_listed': np.random.uniform(2, 24),
                'views_count': np.random.randint(10, 50),
                'seller_rating': np.random.uniform(4.0, 4.8),
                'reviews_count': np.random.randint(5, 50)
            })

        # –°—Ç–∞—Ä—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (>24 —á–∞—Å–æ–≤)
        for i in range(20):
            synthetic_data.append({
                'title': f'–¢–æ–≤–∞—Ä {i} –±/—É',
                'description': '–†–∞–∑–º–µ—â–µ–Ω–æ –¥–∞–≤–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–¥–∞–∂–∏',
                'time_listed': np.random.uniform(24, 168),
                'views_count': np.random.randint(0, 10),
                'seller_rating': np.random.uniform(3.5, 4.5),
                'reviews_count': np.random.randint(0, 20)
            })

        return synthetic_data

    def predict_freshness(self, product_data):
        """üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            if not self.is_trained or self.model is None:
                return self._fallback_prediction(product_data)

            features = self._extract_features(product_data)

            if len(features) != self.feature_count:
                return self._fallback_prediction(product_data)

            features_scaled = self.scaler.transform([features])
            freshness_score = self.model.predict(features_scaled)[0]

            return max(0.0, min(1.0, freshness_score))

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return self._fallback_prediction(product_data)

    def _fallback_prediction(self, product_data):
        """üîÑ –§–æ–ª–±—ç–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        try:
            time_listed = product_data.get('time_listed', 24)
            title = product_data.get('title', '').lower()

            base_score = 0.5

            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
            if time_listed <= 1:
                base_score = 0.9
            elif time_listed <= 6:
                base_score = 0.7
            elif time_listed <= 24:
                base_score = 0.5
            elif time_listed <= 72:
                base_score = 0.3
            else:
                base_score = 0.1

            # –ë–æ–Ω—É—Å –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            if any(word in title for word in ['—Å—Ä–æ—á–Ω–æ', '—Å–≤–µ–∂–∏–π', '–Ω–æ–≤—ã–π', '—Ç–æ–ª—å–∫–æ —á—Ç–æ']):
                base_score = min(base_score + 0.2, 0.95)

            return base_score

        except:
            return 0.5

    async def _save_model(self):
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        try:
            if self.model:
                model_data = {
                    'model': self.model,
                    'scaler': self.scaler,
                    'feature_count': self.feature_count,
                    'trained_at': datetime.now().isoformat()
                }
                joblib.dump(model_data, 'freshness_model.joblib')
                logger.info("üíæ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")

    async def load_model(self):
        """üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –í–ê–†–ò–ê–ù–¢"""
        try:
            import joblib
            from sklearn.preprocessing import StandardScaler

            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏...")

            try:
                loaded = joblib.load('freshness_model.joblib')

                # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—å—é
                if isinstance(loaded, dict) and 'model' in loaded:
                    model = loaded['model']
                    scaler = loaded.get('scaler', StandardScaler())

                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ setter
                    self.model = model
                    self.scaler = scaler

                    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {type(model).__name__}")

                elif hasattr(loaded, 'predict'):  # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –º–æ–¥–µ–ª—å
                    self.model = loaded
                    self.scaler = StandardScaler()
                    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–∞–∫ –æ–±—ä–µ–∫—Ç: {type(loaded).__name__}")

                else:
                    print("‚ö†Ô∏è –ù–µ–ø–æ–Ω—è—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö, —Å–æ–∑–¥–∞—é –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å")
                    raise ValueError("–ù–µ–ø–æ–Ω—è—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")

            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
                print("üîÑ –°–æ–∑–¥–∞—é –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å...")

                from sklearn.ensemble import RandomForestRegressor
                self.model = RandomForestRegressor(n_estimators=50, random_state=42)
                self.scaler = StandardScaler()

            self.feature_count = 10
            self.is_trained = True

            print(f"‚úÖ –ò—Ç–æ–≥: {type(self.model).__name__} –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
            return True

        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ load_model: {e}")
            import traceback
            traceback.print_exc()

            # –ê–≤–∞—Ä–∏–π–Ω—ã–π —Ñ–æ–ª–±—ç–∫
            try:
                from sklearn.ensemble import RandomForestRegressor
                from sklearn.preprocessing import StandardScaler
                self.model = RandomForestRegressor(n_estimators=20, random_state=42)
                self.scaler = StandardScaler()
                self.feature_count = 10
                self.is_trained = True
                print("üîÑ –°–æ–∑–¥–∞–Ω–∞ –∞–≤–∞—Ä–∏–π–Ω–∞—è —Ñ–æ–ª–±—ç–∫ –º–æ–¥–µ–ª—å")
                return True
            except:
                print("üíÄ –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∞–∂–µ —Ñ–æ–ª–±—ç–∫ –º–æ–¥–µ–ª—å")
                return False

    def get_freshness_category(self, freshness_score):
        """üìä –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        if freshness_score >= 0.8:
            return "üî• –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.6:
            return "‚úÖ –°–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.4:
            return "‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.2:
            return "üìÖ –°—Ä–µ–¥–Ω–µ —Å—Ç–∞—Ä—ã–π"
        else:
            return "üíÄ –°—Ç–∞—Ä—ã–π"

    async def get_model_info(self):
        """üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
        return {
            'is_trained': self.is_trained,
            'model_version': self.model_version,
            'feature_count': self.feature_count,
            'status': 'active' if self.is_trained else 'fallback'
        }

    # üî• –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò

    async def load_model_compat(self):
        """üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é –¥–ª—è VotingRegressor"""
        try:
            model_data = joblib.load('freshness_model.joblib')
            self.model = model_data['model']  # üî• –ò—Å–ø–æ–ª—å–∑—É–µ–º setter!
            self.scaler = model_data['scaler']
            self.feature_count = model_data.get('feature_count', 10)
            self.is_trained = True

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º VotingRegressor
            if isinstance(self.model, VotingRegressor):
                logger.info("üéØ –ó–∞–≥—Ä—É–∂–µ–Ω VotingRegressor –¥–ª—è —Å–≤–µ–∂–µ—Å—Ç–∏")

            logger.info("üìÇ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
            return False

    def predict_freshness_sync(self, product_data):
        """üéØ –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏"""
        return self.predict_freshness(product_data)

    def get_model_type(self):
        """üìä –¢–∏–ø –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not self.model:
            return "None"

        model_type = type(self.model).__name__
        if hasattr(self.model, 'estimators_'):
            model_type += f" ({len(self.model.estimators_)} estimators)"

        return model_type

    # üî• –ú–ï–¢–û–î–´ –î–õ–Ø –û–¢–õ–ê–î–ö–ò
    def debug_info(self):
        """üêõ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        return {
            'model_type': self.get_model_type(),
            'is_trained': self.is_trained,
            'feature_count': self.feature_count,
            'model_version': self.model_version,
            'has_scaler': self.scaler is not None,
            'supports_indexing': hasattr(self, '__getitem__')
        }

    def fix_voting_regressor_compatibility(self):
        """üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –¥–ª—è VotingRegressor"""
        try:
            if self.model and hasattr(self.model, 'estimators_'):
                logger.info("üéØ Fixing VotingRegressor compatibility...")

                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥ __getitem__
                def voting_getitem(idx):
                    if idx < len(self.model.estimators_):
                        return self.model.estimators_[idx]
                    raise IndexError(f"VotingRegressor –∏–º–µ–µ—Ç —Ç–æ–ª—å–∫–æ {len(self.model.estimators_)} estimators")

                if not hasattr(self.model, '__getitem__'):
                    self.model.__getitem__ = voting_getitem
                    logger.info("‚úÖ VotingRegressor compatibility added")
                    return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error fixing VotingRegressor: {e}")

        return False

    async def load_model_fixed(self):
        """üìÇ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        try:
            logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–µ–π —Å —Ñ–∏–∫—Å–æ–º...")

            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã
            try:
                data = joblib.load('ultra_price_model.joblib')

                # üî• –§–ò–ö–°: –ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                if isinstance(data, dict):
                    logger.info("üîß –ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è...")
                    if 'model' in data:
                        self.price_model = data['model']
                        self.scaler_price = data.get('scaler', StandardScaler())
                        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Ü–µ–Ω—ã –∏–∑–≤–ª–µ—á–µ–Ω–∞: {type(self.price_model).__name__}")

                        # üî• –í–ê–ñ–ù–û: –î—É–±–ª–∏—Ä—É–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                        self.model = self.price_model
                        self.feature_scaler = self.scaler_price
                    else:
                        raise ValueError("–ù–µ—Ç –∫–ª—é—á–∞ 'model' –≤ —Å–ª–æ–≤–∞—Ä–µ")
                else:
                    # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ –º–æ–¥–µ–ª—å (–Ω–µ —Å–ª–æ–≤–∞—Ä—å)
                    self.price_model = data
                    self.scaler_price = StandardScaler()
                    self.model = data
                    self.feature_scaler = StandardScaler()

                self.is_price_trained = True
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å —Ü–µ–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ultra_price_model: {e}")
                # –ü—Ä–æ–±—É–µ–º —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é
                try:
                    data = joblib.load('price_model.joblib')
                    if isinstance(data, dict) and 'model' in data:
                        self.price_model = data['model']
                    else:
                        self.price_model = data
                    logger.info("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è price_model.joblib")
                except:
                    logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã")

            # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏
            try:
                data = joblib.load('ultra_freshness_model.joblib')

                # üî• –§–ò–ö–°: ultra_freshness_model.joblib - —ç—Ç–æ —É–∂–µ –º–æ–¥–µ–ª—å, –Ω–µ —Å–ª–æ–≤–∞—Ä—å
                if isinstance(data, dict):
                    logger.warning("‚ö†Ô∏è ultra_freshness_model.joblib –æ–∫–∞–∑–∞–ª—Å—è —Å–ª–æ–≤–∞—Ä–µ–º!")
                    if 'model' in data:
                        self.freshness_model = data['model']
                        self.scaler_freshness = data.get('scaler', StandardScaler())
                    else:
                        raise ValueError("–ù–µ—Ç –∫–ª—é—á–∞ 'model'")
                else:
                    # –≠—Ç–æ —É–∂–µ –º–æ–¥–µ–ª—å RandomForestRegressor
                    self.freshness_model = data
                    self.scaler_freshness = StandardScaler()

                self.is_freshness_trained = True
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {type(self.freshness_model).__name__}")

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ultra_freshness_model: {e}")
                # –ü—Ä–æ–±—É–µ–º —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é
                try:
                    data = joblib.load('freshness_model.joblib')
                    if isinstance(data, dict) and 'model' in data:
                        self.freshness_model = data['model']
                        self.scaler_freshness = data.get('scaler', StandardScaler())
                    else:
                        self.freshness_model = data
                        self.scaler_freshness = StandardScaler()
                    logger.info("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è freshness_model.joblib")
                except Exception as e2:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏: {e2}")

            # 3. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥–∏
            self.is_trained = self.is_price_trained or hasattr(self, 'model')

            if self.is_trained:
                logger.info("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                return True
            else:
                logger.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ñ–æ–ª–±—ç–∫")
                return False

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return False

    def test_indexing(self):
        """üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        if self.model and hasattr(self.model, 'estimators_'):
            logger.info(f"üéØ –ú–æ–¥–µ–ª—å –∏–º–µ–µ—Ç {len(self.model.estimators_)} estimators")
            for i in range(len(self.model.estimators_)):
                estimator = self.model.estimators_[i]
                logger.info(f"  Estimator {i}: {type(estimator).__name__}")
            return True
        else:
            logger.info("üìä –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é estimators")
            return False