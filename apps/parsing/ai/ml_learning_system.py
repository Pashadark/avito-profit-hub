"""
üî• –ú–û–ó–ì –°–ò–°–¢–ï–ú–´ - –£–ú–ù–ê–Ø –û–ë–£–ß–ê–Æ–©–ê–Ø–°–Ø –°–ò–°–¢–ï–ú–ê
üéØ –û–ë–£–ß–ê–ï–¢–°–Ø –ù–ê –í–°–ï–• –î–ê–ù–ù–´–• –ò–ó –ë–ê–ó–´, –£–õ–£–ß–®–ê–ï–¢ –ê–õ–ì–û–†–ò–¢–ú–´
"""

import logging
import numpy as np
import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any
from collections import defaultdict, deque
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger('parser.ai.learning')


class MLLearningSystem:
    """üß† –ú–û–ó–ì –°–ò–°–¢–ï–ú–´ - –£–ú–ù–ê–Ø –û–ë–£–ß–ê–Æ–©–ê–Ø–°–Ø –°–ò–°–¢–ï–ú–ê"""

    def __init__(self, db_path="ml_knowledge.db"):
        self.db_path = db_path
        self.logger = logging.getLogger('parser.ai.learning')
        # üî• –ö–û–ú–ü–û–ù–ï–ù–¢–´ –ú–û–ó–ì–ê
        self.freshness_detector = None  # –î–µ—Ç–µ–∫—Ç–æ—Ä —Å–≤–µ–∂–µ—Å—Ç–∏
        self.freshness_scaler = None    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä —Ñ–∏—á

        # üî• –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô
        self.knowledge_base = {
            'freshness_patterns': defaultdict(list),
            'timing_patterns': defaultdict(dict),
            'successful_queries': defaultdict(list),
            'category_insights': defaultdict(dict),
            'seller_patterns': defaultdict(dict),
            'price_trends': defaultdict(list)
        }

        # üî• –ò–°–¢–û–†–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø
        self.learning_history = deque(maxlen=10000)  # 10000 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤
        self.found_items_history = set()  # –•—ç—à–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        self.improvement_rate = 0.0

        # üî• –ú–ï–¢–†–ò–ö–ò
        self.total_learned = 0
        self.fresh_items_found = 0
        self.successful_searches = 0
        self.avg_freshness_score = 0.0

        # üî• –§–õ–ê–ì–ò
        self.is_initialized = False
        self.continuous_learning = True

        logger.info("üß† –ú–û–ó–ì –°–ò–°–¢–ï–ú–´ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # üî• –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –ë–ï–ó–û–ü–ê–°–ù–û–ì–û –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–Ø
    def _safe_float(self, value, default=0.0):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ float"""
        try:
            if value is None:
                return default
            return float(value)
        except (ValueError, TypeError):
            return default

    def _safe_int(self, value, default=0):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ int"""
        try:
            if value is None:
                return default
            return int(value)
        except (ValueError, TypeError):
            return default

    async def initialize_from_database(self):
        """üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–ó–ì–ê –ò–ó –í–°–ï–ô –ë–ê–ó–´ –î–ê–ù–ù–´–•"""
        try:
            from apps.website.models import FoundItem
            from asgiref.sync import sync_to_async

            logger.info("üîç –ó–∞–≥—Ä—É–∑–∫–∞ –í–°–ï–• –∑–Ω–∞–Ω–∏–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")

            # üî• –ë–ï–†–ï–ú –í–°–ï –¢–û–í–ê–†–´ –ë–ï–ó –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ô
            all_items = await sync_to_async(list)(
                FoundItem.objects.all().values(
                    'title', 'description', 'price', 'category',
                    'seller_rating', 'reviews_count', 'found_at',
                    'posted_date', 'ml_freshness_score', 'priority_score',
                    'views_count', 'images'
                )
            )

            if not all_items:
                logger.warning("‚ö†Ô∏è –í –±–∞–∑–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–∑–≥–∞")
                return False

            total_items = len(all_items)
            logger.info(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –í–°–ï–ì–û {total_items} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–∑–≥–∞")

            # üî• –û–ë–£–ß–ê–ï–ú –ú–û–ó–ì –ù–ê –í–°–ï–• –¢–û–í–ê–†–ê–•
            for i, item in enumerate(all_items, 1):
                await self._deep_learn_from_item(item)
                if i % 500 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 500 —Ç–æ–≤–∞—Ä–æ–≤
                    logger.info(f"üìñ –û–±—É—á–∏–ª–∏ {i}/{total_items} —Ç–æ–≤–∞—Ä–æ–≤ ({i/total_items*100:.1f}%)")

            # üî• –û–ë–£–ß–ê–ï–ú –ú–û–î–ï–õ–ò
            await self._train_freshness_detector()

            self.is_initialized = True
            self.total_learned = total_items

            logger.info(f"üß† –ú–û–ó–ì –û–ë–£–ß–ï–ù –ù–ê {total_items} –¢–û–í–ê–†–ê–•!")
            logger.info(f"üéØ –ù–∞–π–¥–µ–Ω–æ —Å–≤–µ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤: {self.fresh_items_found}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await self._save_brain_state()

            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–∑–≥–∞: {e}")
            return False

    async def _deep_learn_from_item(self, item):
        """üéØ –ì–õ–£–ë–û–ö–û–ï –û–ë–£–ß–ï–ù–ò–ï –ù–ê –û–î–ù–û–ú –¢–û–í–ê–†–ï"""
        try:
            # üî• –ö–û–ù–í–ï–†–¢–ò–†–£–ï–ú –í–°–ï –î–ê–ù–ù–´–ï
            insights = {
                'timestamp': datetime.now().isoformat(),
                'item_data': {
                    'title': str(item.get('title', '')),
                    'description': str(item.get('description', '')),
                    'price': self._safe_float(item.get('price', 0)),
                    'category': str(item.get('category', 'unknown')),
                    'seller_rating': self._safe_float(item.get('seller_rating', 0)),
                    'reviews_count': self._safe_int(item.get('reviews_count', 0)),
                    'freshness_score': self._safe_float(item.get('ml_freshness_score', 0))
                },
                'freshness_score': self._safe_float(item.get('ml_freshness_score', 0)),
                'category': str(item.get('category', 'unknown')),
                'found_time': item.get('found_at', datetime.now()),
                'seller_rating': self._safe_float(item.get('seller_rating', 0)),
                'price': self._safe_float(item.get('price', 0))
            }

            # üî• –ê–ù–ê–õ–ò–ó –°–í–ï–ñ–ï–°–¢–ò
            await self._analyze_freshness_patterns(item)

            # üî• –ê–ù–ê–õ–ò–ó –í–†–ï–ú–ï–ù–ò
            await self._analyze_timing_patterns(item)

            # üî• –ê–ù–ê–õ–ò–ó –¶–ï–ù
            await self._analyze_price_patterns(item)

            # üî• –ê–ù–ê–õ–ò–ó –ü–†–û–î–ê–í–¶–û–í
            await self._analyze_seller_patterns(item)

            # üî• –ê–ù–ê–õ–ò–ó –ö–ê–¢–ï–ì–û–†–ò–ô
            await self._analyze_category_patterns(item)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.learning_history.append(insights)

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            freshness = insights['freshness_score']
            if freshness > 0.7:
                self.fresh_items_found += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —Å–≤–µ–∂–µ—Å—Ç—å
            if self.total_learned > 0:
                self.avg_freshness_score = (
                    (self.avg_freshness_score * self.total_learned + freshness) /
                    (self.total_learned + 1)
                )
            else:
                self.avg_freshness_score = freshness

            self.total_learned += 1

            return True

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False

    async def _analyze_freshness_patterns(self, item):
        """üî• –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í –°–í–ï–ñ–ï–°–¢–ò"""
        try:
            category = str(item.get('category', 'unknown'))
            freshness = self._safe_float(item.get('ml_freshness_score', 0))
            posted_date = item.get('posted_date')

            if not posted_date:
                return

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            if isinstance(posted_date, str):
                try:
                    posted_date = datetime.fromisoformat(posted_date.replace('Z', '+00:00'))
                except:
                    return

            hours_ago = (datetime.now() - posted_date).total_seconds() / 3600

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω
            title_lower = str(item.get('title', '')).lower()
            desc_lower = str(item.get('description', '')).lower()

            pattern = {
                'hours_ago': hours_ago,
                'freshness_score': freshness,
                'has_urgency': '—Å—Ä–æ—á–Ω–æ' in title_lower or '—Å—Ä–æ—á–Ω–æ' in desc_lower,
                'is_new': '–Ω–æ–≤—ã–π' in title_lower or '–Ω–æ–≤—ã–π' in desc_lower,
                'seller_type': '–ö–æ–º–ø–∞–Ω–∏—è' if self._safe_float(item.get('seller_rating', 0)) > 4.8 else '–ß–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ'
            }

            self.knowledge_base['freshness_patterns'][category].append(pattern)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
            if len(self.knowledge_base['freshness_patterns'][category]) > 1000:
                self.knowledge_base['freshness_patterns'][category] = \
                    self.knowledge_base['freshness_patterns'][category][-1000:]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")

    async def _analyze_timing_patterns(self, item):
        """üïí –ê–ù–ê–õ–ò–ó –í–†–ï–ú–ï–ù–ù–´–• –ü–ê–¢–¢–ï–†–ù–û–í"""
        try:
            category = str(item.get('category', 'unknown'))
            found_at = item.get('found_at', datetime.now())

            if isinstance(found_at, str):
                found_at = datetime.fromisoformat(found_at.replace('Z', '+00:00'))

            hour = found_at.hour
            day_of_week = found_at.weekday()

            if category not in self.knowledge_base['timing_patterns']:
                self.knowledge_base['timing_patterns'][category] = {
                    'hourly_counts': [0] * 24,
                    'daily_counts': [0] * 7,
                    'best_hours': [],
                    'best_days': []
                }

            self.knowledge_base['timing_patterns'][category]['hourly_counts'][hour] += 1
            self.knowledge_base['timing_patterns'][category]['daily_counts'][day_of_week] += 1

            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ª—É—á—à–∏–µ —á–∞—Å—ã
            hourly = self.knowledge_base['timing_patterns'][category]['hourly_counts']
            self.knowledge_base['timing_patterns'][category]['best_hours'] = \
                sorted(range(24), key=lambda h: hourly[h], reverse=True)[:3]

            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ª—É—á—à–∏–µ –¥–Ω–∏
            daily = self.knowledge_base['timing_patterns'][category]['daily_counts']
            self.knowledge_base['timing_patterns'][category]['best_days'] = \
                sorted(range(7), key=lambda d: daily[d], reverse=True)[:2]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–∏: {e}")

    async def _analyze_price_patterns(self, item):
        """üí∞ –ê–ù–ê–õ–ò–ó –¶–ï–ù–û–í–´–• –ü–ê–¢–¢–ï–†–ù–û–í"""
        try:
            category = str(item.get('category', 'unknown'))
            price = self._safe_float(item.get('price', 0))

            if price > 0:
                self.knowledge_base['price_trends'][category].append({
                    'price': price,
                    'timestamp': datetime.now().isoformat(),
                    'freshness': self._safe_float(item.get('ml_freshness_score', 0))
                })

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                if len(self.knowledge_base['price_trends'][category]) > 500:
                    self.knowledge_base['price_trends'][category] = \
                        self.knowledge_base['price_trends'][category][-500:]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ü–µ–Ω: {e}")

    async def _analyze_seller_patterns(self, item):
        """üë§ –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í –ü–†–û–î–ê–í–¶–û–í"""
        try:
            seller_rating = self._safe_float(item.get('seller_rating', 0))
            reviews_count = self._safe_int(item.get('reviews_count', 0))
            category = str(item.get('category', 'unknown'))

            if seller_rating > 0:
                if category not in self.knowledge_base['seller_patterns']:
                    self.knowledge_base['seller_patterns'][category] = {
                        'total_sellers': 0,
                        'avg_rating': 0.0,
                        'top_sellers': []
                    }

                seller_data = {
                    'rating': seller_rating,
                    'reviews': reviews_count,
                    'freshness_avg': self._safe_float(item.get('ml_freshness_score', 0))
                }

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥
                current_avg = self._safe_float(self.knowledge_base['seller_patterns'][category]['avg_rating'])
                total = self._safe_int(self.knowledge_base['seller_patterns'][category]['total_sellers'])

                self.knowledge_base['seller_patterns'][category]['avg_rating'] = \
                    (current_avg * total + seller_rating) / (total + 1)
                self.knowledge_base['seller_patterns'][category]['total_sellers'] = total + 1

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤: {e}")

    async def _analyze_category_patterns(self, item):
        """üè∑Ô∏è –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í –ö–ê–¢–ï–ì–û–†–ò–ô"""
        try:
            category = str(item.get('category', 'unknown'))

            if category not in self.knowledge_base['category_insights']:
                self.knowledge_base['category_insights'][category] = {
                    'total_items': 0,
                    'avg_freshness': 0.0,
                    'avg_price': 0.0,
                    'success_rate': 0.0,
                    'last_updated': datetime.now().isoformat()
                }

            insights = self.knowledge_base['category_insights'][category]

            # üî• –ö–û–ù–í–ï–†–¢–ò–†–£–ï–ú –í–°–Å –í –ß–ò–°–õ–ê
            total = self._safe_int(insights['total_items'])
            current_avg_freshness = self._safe_float(insights['avg_freshness'])
            current_avg_price = self._safe_float(insights['avg_price'])

            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ item
            item_freshness = self._safe_float(item.get('ml_freshness_score', 0))
            item_price = self._safe_float(item.get('price', 0))

            # üî• –ü–†–û–°–¢–û–ô –†–ê–°–ß–Å–¢ –ë–ï–ó –û–®–ò–ë–û–ö
            if total == 0:
                insights['avg_freshness'] = item_freshness
                if item_price > 0:
                    insights['avg_price'] = item_price
            else:
                insights['avg_freshness'] = (current_avg_freshness * total + item_freshness) / (total + 1)
                if item_price > 0:
                    insights['avg_price'] = (current_avg_price * total + item_price) / (total + 1)

            insights['total_items'] = total + 1
            insights['last_updated'] = datetime.now().isoformat()

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")

    async def _train_freshness_detector(self):
        """üéØ –û–ë–£–ß–ï–ù–ò–ï –î–ï–¢–ï–ö–¢–û–†–ê –°–í–ï–ñ–ï–°–¢–ò"""
        try:
            if not self.knowledge_base['freshness_patterns']:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Å–≤–µ–∂–µ—Å—Ç–∏")
                return False

            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            X, y = [], []

            for category, patterns in self.knowledge_base['freshness_patterns'].items():
                for pattern in patterns:
                    features = [
                        pattern['hours_ago'] / 168,  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ –Ω–µ–¥–µ–ª–∏
                        1.0 if pattern['has_urgency'] else 0.0,
                        1.0 if pattern['is_new'] else 0.0,
                        1.0 if pattern['seller_type'] == '–ö–æ–º–ø–∞–Ω–∏—è' else 0.0,
                        pattern['freshness_score']  # –≠—Ç–æ target
                    ]

                    X.append(features[:-1])  # –í—Å–µ –∫—Ä–æ–º–µ target
                    y.append(features[-1])   # –¢–æ–ª—å–∫–æ target

            if len(X) < 50:
                logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(X)} samples")
                return False

            # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            self.freshness_scaler = StandardScaler()
            X_scaled = self.freshness_scaler.fit_transform(X)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–≤–µ–∂–µ—Å—Ç—å –≤ –∫–ª–∞—Å—Å—ã
            y_classes = np.digitize(y, bins=[0.3, 0.6, 0.8])

            self.freshness_detector = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )

            self.freshness_detector.fit(X_scaled, y_classes)

            logger.info(f"üéØ –î–µ—Ç–µ–∫—Ç–æ—Ä —Å–≤–µ–∂–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω –Ω–∞ {len(X)} samples")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return False

    async def predict_freshness_category(self, product_data):
        """üîç –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ò –°–í–ï–ñ–ï–°–¢–ò"""
        try:
            if not self.freshness_detector or not self.freshness_scaler:
                return await self._simple_freshness_prediction(product_data)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏
            hours_ago = await self._get_hours_since_publication(product_data)
            title_lower = str(product_data.get('title', '')).lower()
            desc_lower = str(product_data.get('description', '')).lower()

            has_urgency = '—Å—Ä–æ—á–Ω–æ' in title_lower or '—Å—Ä–æ—á–Ω–æ' in desc_lower
            is_new = '–Ω–æ–≤—ã–π' in title_lower or '–Ω–æ–≤—ã–π' in desc_lower
            seller_type = '–ö–æ–º–ø–∞–Ω–∏—è' if self._safe_float(product_data.get('seller_rating', 0)) > 4.8 else '–ß–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ'

            features = [
                hours_ago / 168,
                1.0 if has_urgency else 0.0,
                1.0 if is_new else 0.0,
                1.0 if seller_type == '–ö–æ–º–ø–∞–Ω–∏—è' else 0.0
            ]

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
            features_scaled = self.freshness_scaler.transform([features])
            prediction = self.freshness_detector.predict(features_scaled)[0]

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–ª–∞—Å—Å –≤ —Ç–µ–∫—Å—Ç–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            categories = ['üíÄ –£—Å—Ç–∞—Ä–µ–≤—à–µ–µ', 'üåô –ú–∞–ª–æ —Å–≤–µ–∂–µ–µ', '‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ', 'üî• –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ']
            return categories[min(prediction, len(categories) - 1)]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return '‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ'

    async def _simple_freshness_prediction(self, product_data):
        """üîÑ –ü–†–û–°–¢–û–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –°–í–ï–ñ–ï–°–¢–ò"""
        try:
            hours_ago = await self._get_hours_since_publication(product_data)

            if hours_ago < 1:
                return 'üî• –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ'
            elif hours_ago < 6:
                return 'üî• –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ'
            elif hours_ago < 24:
                return '‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ'
            elif hours_ago < 48:
                return 'üåô –ú–∞–ª–æ —Å–≤–µ–∂–µ–µ'
            else:
                return 'üíÄ –£—Å—Ç–∞—Ä–µ–≤—à–µ–µ'

        except:
            return '‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ'

    async def _get_hours_since_publication(self, product_data):
        """‚è∞ –ü–æ–ª—É—á–µ–Ω–∏–µ —á–∞—Å–æ–≤ —Å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            posted_date = product_data.get('posted_date')
            if posted_date:
                if isinstance(posted_date, str):
                    posted_date = datetime.fromisoformat(posted_date.replace('Z', '+00:00'))

                hours_ago = (datetime.now() - posted_date).total_seconds() / 3600
                return hours_ago

            return 24.0
        except:
            return 24.0

    async def get_optimal_search_times(self, category):
        """üïí –õ–£–ß–®–ï–ï –í–†–ï–ú–Ø –î–õ–Ø –ü–û–ò–°–ö–ê"""
        try:
            category = str(category)
            if category in self.knowledge_base['timing_patterns']:
                pattern = self.knowledge_base['timing_patterns'][category]
                if pattern['best_hours']:
                    return pattern['best_hours']

            return [9, 14, 19]  # –£—Ç—Ä–æ, –æ–±–µ–¥, –≤–µ—á–µ—Ä

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏: {e}")
            return [9, 14, 19]

    async def find_fresh_deals(self, limit=20):
        """üîç –ü–û–ò–°–ö –°–ê–ú–´–• –°–í–ï–ñ–ò–• –¢–û–í–ê–†–û–í –í –ë–ê–ó–ï (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)"""
        try:
            from apps.website.models import FoundItem
            from asgiref.sync import sync_to_async

            # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã —Å –≤—ã—Å–æ–∫–æ–π —Å–≤–µ–∂–µ—Å—Ç—å—é
            fresh_items = await sync_to_async(list)(
                FoundItem.objects.filter(
                    ml_freshness_score__gte=0.7
                ).order_by('-ml_freshness_score', '-found_at')[:limit]
            )

            if not fresh_items:
                return []

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            results = []
            for item in fresh_items:
                # üî• –ë–ï–ó–û–ü–ê–°–ù–û –ü–†–û–í–ï–†–Ø–ï–ú expected_profit
                profit = 0
                try:
                    if hasattr(item, 'expected_profit') and item.expected_profit is not None:
                        profit = self._safe_float(item.expected_profit)
                except:
                    profit = 0

                results.append({
                    'id': item.id,
                    'title': item.title[:50] + '...' if len(item.title) > 50 else item.title,
                    'price': self._safe_float(item.price),
                    'freshness': self._safe_float(item.ml_freshness_score),
                    'category': str(item.category) if item.category else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                    'posted': str(item.posted_date) if item.posted_date else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                    'profit': profit  # üî• –ë–ï–ó–û–ü–ê–°–ù–û
                })

            return results

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–≤–µ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤: {e}")
            return []

    async def get_brain_stats(self):
        """üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ú–û–ó–ì–ê"""
        try:
            total_categories = len(self.knowledge_base['category_insights'])
            total_patterns = sum(len(patterns) for patterns in self.knowledge_base['freshness_patterns'].values())

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞
            intelligence_level = min((self.total_learned / 2000.0), 1.0)

            stats = {
                'brain_version': 'v2.0_smart',
                'total_learned': self._safe_int(self.total_learned),
                'fresh_items_found': self._safe_int(self.fresh_items_found),
                'successful_searches': self._safe_int(self.successful_searches),
                'avg_freshness_score': self._safe_float(self.avg_freshness_score),
                'categories_known': self._safe_int(total_categories),
                'patterns_learned': self._safe_int(total_patterns),
                'intelligence_level': f"{intelligence_level:.1%}",
                'continuous_learning': self.continuous_learning,
                'is_initialized': self.is_initialized,
                'freshness_detector_trained': self.freshness_detector is not None,
                'last_learning': datetime.now().isoformat()
            }

            # üî• –¢–û–ü –ö–ê–¢–ï–ì–û–†–ò–ô –ü–û –°–í–ï–ñ–ï–°–¢–ò
            top_categories = []
            for category, insights in self.knowledge_base['category_insights'].items():
                if insights['total_items'] >= 3:  # –ú–∏–Ω–∏–º—É–º 3 —Ç–æ–≤–∞—Ä–∞
                    avg_freshness = self._safe_float(insights.get('avg_freshness', 0))
                    total_items = self._safe_int(insights.get('total_items', 0))

                    if avg_freshness > 0:  # –¢–æ–ª—å–∫–æ —Å –¥–∞–Ω–Ω—ã–º–∏
                        top_categories.append({
                            'name': str(category),
                            'avg_freshness': round(avg_freshness, 3),
                            'total_items': total_items
                        })

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏
            top_categories.sort(key=lambda x: x['avg_freshness'], reverse=True)
            stats['top_fresh_categories'] = top_categories[:5]

            return stats

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

    async def _save_brain_state(self):
        """üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –°–û–°–¢–û–Ø–ù–ò–Ø –ú–û–ó–ì–ê"""
        try:
            def convert_for_json(obj):
                """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è JSON"""
                if isinstance(obj, (dict, list, tuple, str, int, bool, type(None), float)):
                    return obj
                elif hasattr(obj, '__dict__'):
                    return obj.__dict__
                else:
                    return str(obj)

            state = {
                'knowledge_base': self.knowledge_base,
                'stats': {
                    'total_learned': self.total_learned,
                    'fresh_items_found': self.fresh_items_found,
                    'avg_freshness_score': float(self.avg_freshness_score),
                    'successful_searches': self.successful_searches
                },
                'last_saved': datetime.now().isoformat()
            }

            with open('brain_state.json', 'w', encoding='utf-8') as f:
                json.dump(state, f, default=convert_for_json, ensure_ascii=False, indent=2)

            logger.info("üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–∑–≥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–∑–≥–∞: {e}")

    async def load_brain_state(self):
        """üìÇ –ó–ê–ì–†–£–ó–ö–ê –°–û–°–¢–û–Ø–ù–ò–Ø –ú–û–ó–ì–ê"""
        try:
            with open('brain_state.json', 'r', encoding='utf-8') as f:
                state = json.load(f)

            self.knowledge_base = defaultdict(list, state.get('knowledge_base', {}))

            stats = state.get('stats', {})
            self.total_learned = self._safe_int(stats.get('total_learned', 0))
            self.fresh_items_found = self._safe_int(stats.get('fresh_items_found', 0))
            self.avg_freshness_score = self._safe_float(stats.get('avg_freshness_score', 0))
            self.successful_searches = self._safe_int(stats.get('successful_searches', 0))

            self.is_initialized = True
            logger.info(f"üß† –ú–æ–∑–≥ –∑–∞–≥—Ä—É–∂–µ–Ω: {self.total_learned} –∑–Ω–∞–Ω–∏–π")

            return True

        except FileNotFoundError:
            logger.info("üß† –ú–æ–∑–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–∑–≥–∞: {e}")
            return False

    async def analyze_database(self):
        """üìä –ê–ù–ê–õ–ò–ó –í–°–ï–ô –ë–ê–ó–´ –î–ê–ù–ù–´–•"""
        try:
            from apps.website.models import FoundItem
            from asgiref.sync import sync_to_async
            from django.db.models import Count, Avg

            print("\n" + "=" * 60)
            print("üìä –ê–ù–ê–õ–ò–ó –í–°–ï–ô –ë–ê–ó–´ –î–ê–ù–ù–´–•")
            print("=" * 60)

            # 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_items = await sync_to_async(FoundItem.objects.count)()
            print(f"\nüì¶ –í–°–ï–ì–û –¢–û–í–ê–†–û–í –í –ë–ê–ó–ï: {total_items}")

            # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏
            freshness_stats = await sync_to_async(list)(
                FoundItem.objects.extra(
                    select={
                        'freshness_range': """
                            CASE 
                                WHEN ml_freshness_score >= 0.8 THEN 'üî• –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ (>0.8)'
                                WHEN ml_freshness_score >= 0.5 THEN '‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ (0.5-0.8)'
                                WHEN ml_freshness_score >= 0.3 THEN 'üåô –ú–∞–ª–æ —Å–≤–µ–∂–µ–µ (0.3-0.5)'
                                ELSE 'üíÄ –£—Å—Ç–∞—Ä–µ–≤—à–µ–µ (<0.3)'
                            END
                        """
                    }
                ).values('freshness_range').annotate(count=Count('id')).order_by('-count')
            )

            print("\nüìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –°–í–ï–ñ–ï–°–¢–ò:")
            for stat in freshness_stats:
                percentage = (stat['count'] / total_items) * 100
                print(f"  ‚Ä¢ {stat['freshness_range']}: {stat['count']} ({percentage:.1f}%)")

            # 3. –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
            top_categories = await sync_to_async(list)(
                FoundItem.objects.values('category').annotate(
                    count=Count('id'),
                    avg_freshness=Avg('ml_freshness_score'),
                    avg_price=Avg('price')
                ).filter(category__isnull=False).order_by('-count')[:10]
            )

            print(f"\nüèÜ –¢–û–ü-10 –ö–ê–¢–ï–ì–û–†–ò–ô –ü–û –ö–û–õ–ò–ß–ï–°–¢–í–£:")
            for cat in top_categories:
                avg_freshness = self._safe_float(cat.get('avg_freshness', 0))
                avg_price = self._safe_float(cat.get('avg_price', 0))
                print(
                    f"  ‚Ä¢ {cat['category']}: {cat['count']} —Ç–æ–≤–∞—Ä–æ–≤, —Å–≤–µ–∂–µ—Å—Ç—å: {avg_freshness:.2f}, —Ü–µ–Ω–∞: {avg_price:.0f} —Ä—É–±")

            # 4. –°–∞–º—ã–µ —Å–≤–µ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã
            fresh_items = await sync_to_async(list)(
                FoundItem.objects.filter(ml_freshness_score__gte=0.8)
                .order_by('-ml_freshness_score', '-found_at')[:5]
            )

            print(f"\nüéØ –°–ê–ú–´–ï –°–í–ï–ñ–ò–ï –¢–û–í–ê–†–´ (—Å–≤–µ–∂–µ—Å—Ç—å > 0.8):")
            for item in fresh_items:
                price = self._safe_float(item.price) if item.price else 0
                freshness = self._safe_float(item.ml_freshness_score) if item.ml_freshness_score else 0
                title = str(item.title)[:40] + '...' if len(str(item.title)) > 40 else str(item.title)
                print(f"  ‚Ä¢ {title} - —Å–≤–µ–∂–µ—Å—Ç—å: {freshness:.2f}, —Ü–µ–Ω–∞: {price} —Ä—É–±")

            print("\n" + "=" * 60)
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–∞–∑—ã: {e}")
            import traceback
            traceback.print_exc()
            return False

    # üî• –ü–ê–¢–ß –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –° –ü–ê–†–°–ï–†–û–ú
    async def load_learning_state(self):
        """üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è (–ø–∞—Ç—á –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        try:
            import logging
            logger = logging.getLogger('parser.ai.learning')
            logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è...")
            return await self.load_brain_state()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ load_learning_state: {e}")
            return False