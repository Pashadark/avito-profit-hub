# fix_main_parser.py
import os
import re
import shutil


def fix_selenium_parser():
    """–§–∏–∫—Å–∏–º –≥–ª–∞–≤–Ω—ã–π –ø–∞—Ä—Å–µ—Ä selenium_parser.py"""
    file_path = 'apps/parsing/utils/selenium_parser.py'

    if not os.path.exists(file_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return False

    print(f"üîß –ò—Å–ø—Ä–∞–≤–ª—è–µ–º: {file_path}")

    # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø
    backup_path = file_path + '.backup'
    shutil.copy2(file_path, backup_path)
    print(f"üíæ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_path}")

    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    original_content = content

    # 1. –ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    bad_imports = [
        'from apps.parsing.ai.query_optimizer import',
        'from apps.parsing.utils.freshness_query_optimizer import',
        'import QueryOptimizer',
        'import FreshnessQueryOptimizer'
    ]

    for bad_import in bad_imports:
        if bad_import in content:
            content = content.replace(bad_import, f'# –£–î–ê–õ–ï–ù–û {bad_import}')
            print(f"‚ùå –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω: {bad_import}")

    # 2. –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
    if 'simple_query_handler' not in content:
        # –ù–∞—Ö–æ–¥–∏–º –∫—É–¥–∞ –≤—Å—Ç–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç
        import_match = re.search(r'^from apps\.parsing\.utils\..*?import', content, re.MULTILINE)
        if import_match:
            insert_pos = import_match.end()
            simple_import = '\nfrom apps.parsing.utils.simple_query_handler import get_simple_queries  # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤'
            content = content[:insert_pos] + simple_import + content[insert_pos:]
            print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç simple_query_handler")

    # 3. –ù–∞—Ö–æ–¥–∏–º –∏ —Ñ–∏–∫—Å–∏–º –≤—ã–∑–æ–≤—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    # –ò—â–µ–º –≥–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
    optimizer_calls = [
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
        r'optimized_queries\s*=.*optimize_queries',
        r'await.*query_optimizer',
        r'üéØ AI-–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ó–ê–ü–†–û–°–´',
        r'query_optimizer\.optimize_queries',
    ]

    replacements_made = 0

    # –ó–∞–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    for pattern in optimizer_calls:
        matches = list(re.finditer(pattern, content, re.IGNORECASE))
        for match in matches:
            print(f"üîç –ù–∞–π–¥–µ–Ω –≤—ã–∑–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞: {match.group()[:50]}...")

            # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–º–µ–Ω–∞
            if 'optimize_queries' in match.group():
                # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É –ø–æ–ª–Ω–æ—Å—Ç—å—é
                line_start = content.rfind('\n', 0, match.start()) + 1
                line_end = content.find('\n', match.end())
                full_line = content[line_start:line_end]

                # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç—Ä–æ–∫—É
                new_line = '# ' + full_line + '  # –£–î–ê–õ–ï–ù–û - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n' + \
                           '                optimized_queries = get_simple_queries(keywords)'

                content = content[:line_start] + new_line + content[line_end:]
                print(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞: {full_line[:50]}...")
                replacements_made += 1
                break  # –í—ã—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π –∑–∞–º–µ–Ω—ã

    # 4. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∏—â–µ–º –≤—Ä—É—á–Ω—É—é
    if replacements_made == 0:
        print("üîç –ò—â–µ–º –≤—Ä—É—á–Ω—É—é —Å—Ç—Ä–æ–∫–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π...")

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        lines = content.split('\n')
        new_lines = []

        for i, line in enumerate(lines):
            if 'optimize_queries' in line or 'query_optimizer' in line:
                print(f"üîß –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É {i + 1}: {line[:60]}...")
                # –ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—É—é —Å—Ç—Ä–æ–∫—É
                new_lines.append('# ' + line + '  # –£–î–ê–õ–ï–ù–û - AI –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä')
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
                new_lines.append('                optimized_queries = get_simple_queries(keywords)  # –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã')
                replacements_made += 1
            else:
                new_lines.append(line)

        content = '\n'.join(new_lines)

    # 5. –ó–∞–º–µ–Ω—è–µ–º AI –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ
    content = content.replace('üéØ AI-–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ó–ê–ü–†–û–°–´', 'üéØ –ü–†–û–°–¢–´–ï –ó–ê–ü–†–û–°–´')

    if content != original_content:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"\n‚úÖ –§–∞–π–ª –∏—Å–ø—Ä–∞–≤–ª–µ–Ω! –í–Ω–µ—Å–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {replacements_made}")
        print(f"üíæ –ë—ç–∫–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {backup_path}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        print("\nüìù –ü—Ä–∏–º–µ—Ä –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:")
        print("   –ë–´–õ–û: optimized_queries = await query_optimizer.optimize_queries(keywords)")
        print("   –°–¢–ê–õ–û: optimized_queries = get_simple_queries(keywords)")
        return True
    else:
        print("‚ÑπÔ∏è –ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ—Å—å")
        return False


def show_fixes():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –±—ã–ª–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ"""
    print("\n" + "=" * 60)
    print("üéØ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –í SELENIUM_PARSER.PY:")
    print("=" * 60)

    print("1. ‚ùå –£–¥–∞–ª–µ–Ω—ã –∏–º–ø–æ—Ä—Ç—ã AI –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞")
    print("2. ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç simple_query_handler")
    print("3. üîß –ó–∞–º–µ–Ω–µ–Ω—ã –≤—ã–∑–æ–≤—ã optimize_queries() –Ω–∞ get_simple_queries()")
    print("4. üéØ 'AI-–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ó–ê–ü–†–û–°–´' ‚Üí '–ü–†–û–°–¢–´–ï –ó–ê–ü–†–û–°–´'")

    print("\nüìù –¢–µ–ø–µ—Ä—å –ª–æ–≥–∏ –±—É–¥—É—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å:")
    print("   üéØ –ü–†–û–°–¢–´–ï –ó–ê–ü–†–û–°–´:")
    print("   - 'iphone 12'")
    print("   - 'iphone 13'")
    print("   - 'iphone 14'")
    print("\n   –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –±—Ä–µ–¥–∞:")
    print("   üéØ AI-–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ó–ê–ü–†–û–°–´:")
    print("   - '—Ç–æ–ª—å–∫–æ —á—Ç–æ iphone 12'")
    print("   - '–¥–Ω–µ–≤–Ω–∞—è iphone 13'")
    print("   - '—Å–µ–≥–æ–¥–Ω—è iphone 14'")

    print("=" * 60)


if __name__ == "__main__":
    print("üîß –§–ò–ö–° –ì–õ–ê–í–ù–û–ì–û –ü–ê–†–°–ï–†–ê SELENIUM_PARSER.PY")
    print("=" * 60)

    success = fix_selenium_parser()

    if success:
        show_fixes()

        print("\nüöÄ –ó–∞–ø—É—Å–∫–∞–π –ø–∞—Ä—Å–µ—Ä –∏ –ø—Ä–æ–≤–µ—Ä—è–π:")
        print("   cd C:\\Users\\pasahdark\\PycharmProjects\\avito_profit_hub")
        print("   .venv\\Scripts\\python.exe run.py")
        print("\n–í—ã–±–µ—Ä–∏ –æ–ø—Ü–∏—é 1 –∏ —Å–º–æ—Ç—Ä–∏ –ª–æ–≥–∏ - –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å '—Ç–æ–ª—å–∫–æ —á—Ç–æ', '—Å–µ–≥–æ–¥–Ω—è'!")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª")