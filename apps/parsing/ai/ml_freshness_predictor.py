import logging
import numpy as np
import re
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import joblib
import asyncio

logger = logging.getLogger('parser.ai.freshness')


class MLFreshnessPredictor:
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.feature_count = 10
        self.model_version = "v1.0"

        logger.info(f"üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ML –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–≤–µ–∂–µ—Å—Ç–∏ {self.model_version}")

    async def initialize_model(self):
        """üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            loaded = await self.load_model()
            if not loaded:
                logger.info("üß† –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ñ–æ–ª–±—ç–∫")
            else:
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return False

    async def train(self, training_data=None):
        """üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            if training_data is None:
                training_data = self._create_synthetic_data()
                logger.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")

            X, y = [], []

            for item in training_data:
                features = self._extract_features(item)
                if features and len(features) == self.feature_count:
                    X.append(features)
                    freshness_label = self._calculate_freshness_label(item)
                    y.append(freshness_label)

            if len(X) < 10:
                logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return False

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ
            X_scaled = self.scaler.fit_transform(X)

            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=20,
                random_state=42,
                min_samples_split=3,
                min_samples_leaf=2
            )

            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
            cv_scores = cross_val_score(self.model, X_scaled, y, cv=min(3, len(X)), scoring='r2')
            logger.info(f"üéØ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏: {cv_scores}")

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            self.model.fit(X_scaled, y)
            self.is_trained = True

            train_score = self.model.score(X_scaled, y)
            logger.info(f"üöÄ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∞! –¢–æ—á–Ω–æ—Å—Ç—å: {train_score:.3f}, –î–∞–Ω–Ω—ã—Ö: {len(X)}")

            await self._save_model()
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return False

    def _extract_features(self, item):
        """üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()
            time_listed = item.get('time_listed', 24)
            views_count = item.get('views_count', 0)
            seller_rating = item.get('seller_rating', 4.0)
            reviews_count = item.get('reviews_count', 0)

            features = [
                # 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                min(time_listed / 168, 1.0),  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
                1.0 if time_listed <= 1 else 0.0,  # –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ
                1.0 if time_listed <= 6 else 0.0,  # –°–≤–µ–∂–µ–µ

                # 2. –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                1.0 if any(word in title for word in ['—Å—Ä–æ—á–Ω–æ', 'urgent', 'quick']) else 0.0,
                1.0 if any(word in title for word in ['—Å–≤–µ–∂–∏–π', '–Ω–æ–≤—ã–π', 'new', 'fresh']) else 0.0,
                1.0 if any(word in description for word in ['—Å–µ–≥–æ–¥–Ω—è', '–≤—á–µ—Ä–∞', '—Ç–æ–ª—å–∫–æ —á—Ç–æ']) else 0.0,

                # 3. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ —Ä–µ–ø—É—Ç–∞—Ü–∏—è
                min(views_count / 200, 1.0),  # –ü—Ä–æ—Å–º–æ—Ç—Ä—ã
                float(seller_rating) / 5.0,  # –†–µ–π—Ç–∏–Ω–≥
                min(reviews_count / 100, 1.0),  # –û—Ç–∑—ã–≤—ã

                # 4. –ö–∞—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
                min(len(title) / 150, 1.0)  # –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            ]

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
            if len(features) != self.feature_count:
                if len(features) > self.feature_count:
                    features = features[:self.feature_count]
                else:
                    features.extend([0.0] * (self.feature_count - len(features)))

            return features

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return [0.0] * self.feature_count

    def _calculate_freshness_label(self, item):
        """üéØ –†–∞—Å—á–µ—Ç —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        try:
            time_listed = item.get('time_listed', 24)
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()

            base_score = 0.5

            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
            if time_listed <= 0.5:  # 30 –º–∏–Ω—É—Ç
                base_score = 0.95
            elif time_listed <= 2:  # 2 —á–∞—Å–∞
                base_score = 0.85
            elif time_listed <= 6:  # 6 —á–∞—Å–æ–≤
                base_score = 0.70
            elif time_listed <= 24:  # 1 –¥–µ–Ω—å
                base_score = 0.40
            elif time_listed <= 72:  # 3 –¥–Ω—è
                base_score = 0.20
            else:  # > 3 –¥–Ω–µ–π
                base_score = 0.10

            # –ë–æ–Ω—É—Å –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            fresh_keywords = ['—Å—Ä–æ—á–Ω–æ', '—Å–≤–µ–∂–∏–π', '–Ω–æ–≤—ã–π', '—Ç–æ–ª—å–∫–æ —á—Ç–æ', '—Å–µ–≥–æ–¥–Ω—è']
            keyword_bonus = 0.0
            for keyword in fresh_keywords:
                if keyword in title:
                    keyword_bonus += 0.05
                if keyword in description:
                    keyword_bonus += 0.03

            base_score = min(base_score + keyword_bonus, 0.95)

            return base_score

        except:
            return 0.5

    def _create_synthetic_data(self):
        """üîß –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        synthetic_data = []

        # –û—á–µ–Ω—å —Å–≤–µ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (0-2 —á–∞—Å–∞)
        for i in range(20):
            synthetic_data.append({
                'title': f'–°—Ä–æ—á–Ω–æ –ø—Ä–æ–¥–∞–º –Ω–æ–≤—ã–π —Ç–æ–≤–∞—Ä {i}',
                'description': '–¢–æ–ª—å–∫–æ —á—Ç–æ —Ä–∞–∑–º–µ—â–µ–Ω–æ, —Å—Ä–æ—á–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞',
                'time_listed': np.random.uniform(0.1, 2),
                'views_count': np.random.randint(1, 20),
                'seller_rating': np.random.uniform(4.5, 5.0),
                'reviews_count': np.random.randint(10, 100)
            })

        # –°–≤–µ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (2-24 —á–∞—Å–∞)
        for i in range(30):
            synthetic_data.append({
                'title': f'–ü—Ä–æ–¥–∞–º —Ç–æ–≤–∞—Ä {i} –≤ —Ö–æ—Ä–æ—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏',
                'description': '–†–∞–∑–º–µ—â–µ–Ω–æ —Å–µ–≥–æ–¥–Ω—è, —Ö–æ—Ä–æ—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ',
                'time_listed': np.random.uniform(2, 24),
                'views_count': np.random.randint(10, 50),
                'seller_rating': np.random.uniform(4.0, 4.8),
                'reviews_count': np.random.randint(5, 50)
            })

        # –°—Ç–∞—Ä—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (>24 —á–∞—Å–æ–≤)
        for i in range(20):
            synthetic_data.append({
                'title': f'–¢–æ–≤–∞—Ä {i} –±/—É',
                'description': '–†–∞–∑–º–µ—â–µ–Ω–æ –¥–∞–≤–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–¥–∞–∂–∏',
                'time_listed': np.random.uniform(24, 168),
                'views_count': np.random.randint(0, 10),
                'seller_rating': np.random.uniform(3.5, 4.5),
                'reviews_count': np.random.randint(0, 20)
            })

        return synthetic_data

    def predict_freshness(self, product_data):
        """üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            if not self.is_trained or self.model is None:
                return self._fallback_prediction(product_data)

            features = self._extract_features(product_data)

            if len(features) != self.feature_count:
                return self._fallback_prediction(product_data)

            features_scaled = self.scaler.transform([features])
            freshness_score = self.model.predict(features_scaled)[0]

            return max(0.0, min(1.0, freshness_score))

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return self._fallback_prediction(product_data)

    def _fallback_prediction(self, product_data):
        """üîÑ –§–æ–ª–±—ç–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        try:
            time_listed = product_data.get('time_listed', 24)
            title = product_data.get('title', '').lower()

            base_score = 0.5

            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
            if time_listed <= 1:
                base_score = 0.9
            elif time_listed <= 6:
                base_score = 0.7
            elif time_listed <= 24:
                base_score = 0.5
            elif time_listed <= 72:
                base_score = 0.3
            else:
                base_score = 0.1

            # –ë–æ–Ω—É—Å –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            if any(word in title for word in ['—Å—Ä–æ—á–Ω–æ', '—Å–≤–µ–∂–∏–π', '–Ω–æ–≤—ã–π', '—Ç–æ–ª—å–∫–æ —á—Ç–æ']):
                base_score = min(base_score + 0.2, 0.95)

            return base_score

        except:
            return 0.5

    async def _save_model(self):
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        try:
            if self.model:
                model_data = {
                    'model': self.model,
                    'scaler': self.scaler,
                    'feature_count': self.feature_count,
                    'trained_at': datetime.now().isoformat()
                }
                joblib.dump(model_data, 'freshness_model.joblib')
                logger.info("üíæ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")

    async def load_model(self):
        """üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        try:
            model_data = joblib.load('freshness_model.joblib')
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.feature_count = model_data.get('feature_count', 10)
            self.is_trained = True
            logger.info("üìÇ –ú–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
            return False

    def get_freshness_category(self, freshness_score):
        """üìä –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        if freshness_score >= 0.8:
            return "üî• –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.6:
            return "‚úÖ –°–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.4:
            return "‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.2:
            return "üìÖ –°—Ä–µ–¥–Ω–µ —Å—Ç–∞—Ä—ã–π"
        else:
            return "üíÄ –°—Ç–∞—Ä—ã–π"

    async def get_model_info(self):
        """üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
        return {
            'is_trained': self.is_trained,
            'model_version': self.model_version,
            'feature_count': self.feature_count,
            'status': 'active' if self.is_trained else 'fallback'
        }