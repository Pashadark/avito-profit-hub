import logging
import numpy as np
import pandas as pd
import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Tuple
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import warnings

warnings.filterwarnings('ignore')

logger = logging.getLogger('parser.ai')


class MLPricePredictor:
    def __init__(self, db_path="ml_knowledge.db"):
        self.model_version = "v3.0_ultra_smart"
        self.db_path = db_path

        # üî• –û–°–ù–û–í–ù–´–ï –ú–û–î–ï–õ–ò
        self.price_model = None  # –î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã
        self.freshness_model = None  # –î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏
        self.scaler_price = None
        self.scaler_freshness = None
        self.is_trained = False  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ø–∞—Ä—Å–µ—Ä–æ–º
        self.model = None  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.feature_scaler = None  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

        # üî• –§–õ–ê–ì–ò –û–ë–£–ß–ï–ù–ò–Ø
        self.is_price_trained = False
        self.is_freshness_trained = False

        # üî• –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
        self.config = {
            'price_features_count': 35,
            'freshness_features_count': 15,
            'min_training_samples': 50,
            'max_training_samples': 10000,
            'validation_split': 0.2,
            'model_update_frequency': 100
        }

        # üî• –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–ê–¢–¢–ï–†–ù–û–í
        self._initialize_patterns()

        # üî• –õ–û–ì–ò
        self.training_log = []

        logger.info(f"üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω Advanced ML Predictor v{self.model_version}")

    async def initialize_model(self):
        """üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ø–∞—Ä—Å–µ—Ä–æ–º)"""
        try:
            logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–æ–¥–µ–ª–∏...")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
            return await self.initialize_all_models()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return await self.load_model()  # –§–æ–ª–±—ç–∫

    async def load_freshness_model(self):
        """üéØ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ø–∞—Ä—Å–µ—Ä–æ–º)"""
        try:
            logger.info("üéØ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏...")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –º–µ—Ç–æ–¥
            return await self._load_freshness_model()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return False

    async def predict_price(self, product_data):
        """üí∞ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ø–∞—Ä—Å–µ—Ä–æ–º)"""
        try:
            return await self.predict_price_ultra(product_data)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ predict_price: {e}")
            return float(product_data.get('price', 0)) * 1.2

    async def predict_freshness(self, product_data):
        """üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤–µ–∂–µ—Å—Ç–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ø–∞—Ä—Å–µ—Ä–æ–º)"""
        try:
            return await self.predict_freshness_ultra(product_data)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ predict_freshness: {e}")
            hours_since = self._get_hours_since_publication(product_data)
            return self._calculate_time_based_freshness(hours_since)

    def _initialize_patterns(self):
        """üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""

        # üìä –ë–†–ï–ù–î–´
        self.brand_patterns = {
            'apple': ['iphone', 'macbook', 'ipad', 'airpods', 'apple watch', 'imac'],
            'samsung': ['samsung', 'galaxy', 'note', 'fold', 'flip'],
            'xiaomi': ['xiaomi', 'redmi', 'poco', 'mi ', 'redmi note'],
            'huawei': ['huawei', 'honor', 'p series', 'mate'],
            'sony': ['sony', 'playstation', 'ps5', 'ps4', 'xperia'],
            'nike': ['nike', 'air force', 'air max', 'jordan'],
            'adidas': ['adidas', 'yeezy', 'ultraboost', 'stan smith']
        }

        # üìä –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê –°–û–°–¢–û–Ø–ù–ò–Ø (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –§–û–†–ú–ê–¢!)
        self.condition_keywords = {
            'perfect': {
                'keywords': ['–Ω–æ–≤—ã–π', '–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è', '—Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π', '–æ—Ä–∏–≥–∏–Ω–∞–ª', '–∑–∞–≤–æ–¥—Å–∫–∞—è —É–ø–∞–∫–æ–≤–∫–∞'],
                'weight': 1.2  # +20% –∫ —Ü–µ–Ω–µ
            },
            'excellent': {
                'keywords': ['–æ—Ç–ª–∏—á–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ', '–∫–∞–∫ –Ω–æ–≤—ã–π', '–ø–æ—á—Ç–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è', '–∏–¥–µ–∞–ª—å–Ω–æ–µ'],
                'weight': 1.1  # +10% –∫ —Ü–µ–Ω–µ
            },
            'good': {
                'keywords': ['—Ö–æ—Ä–æ—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ', '–Ω–µ–±–æ–ª—å—à–∏–µ —Å–ª–µ–¥—ã', '–º—è–≥–∫–∏–µ –ø–æ—Ç–µ—Ä—Ç–æ—Å—Ç–∏', '—Ä–∞–±–æ—Ç–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ'],
                'weight': 1.0  # –±–∞–∑–æ–≤–∞—è —Ü–µ–Ω–∞
            },
            'satisfactory': {
                'keywords': ['—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ', '—Ü–∞—Ä–∞–ø–∏–Ω—ã', '–ø–æ—Ç–µ—Ä—Ç–æ—Å—Ç–∏', '—Å–ª–µ–¥—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è'],
                'weight': 0.9  # -10% –æ—Ç —Ü–µ–Ω—ã
            },
            'bad': {
                'keywords': ['—Ç—Ä–µ–±—É–µ—Ç —Ä–µ–º–æ–Ω—Ç–∞', '–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç', '—Å–ª–æ–º–∞–Ω', '–±/—É –≤ –ø–ª–æ—Ö–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏'],
                'weight': 0.7  # -30% –æ—Ç —Ü–µ–Ω—ã
            }
        }

        # üìä –ò–ù–î–ò–ö–ê–¢–û–†–´ –°–í–ï–ñ–ï–°–¢–ò
        self.freshness_indicators = {
            'time_keywords': ['—Ç–æ–ª—å–∫–æ —á—Ç–æ', '—Å–µ–≥–æ–¥–Ω—è', '–º–∏–Ω—É—Ç', '—á–∞—Å', '—Å–≤–µ–∂–∏–π'],
            'urgency_keywords': ['—Å—Ä–æ—á–Ω–æ', '–±—ã—Å—Ç—Ä–æ', '—Å—Ä–æ—á–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞'],
            'new_keywords': ['–Ω–æ–≤—ã–π', '–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è', '—Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π', '–æ—Ä–∏–≥–∏–Ω–∞–ª']
        }

    async def initialize_all_models(self):
        """üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –í–°–ï–• –ú–û–î–ï–õ–ï–ô –°–†–ê–ó–£"""
        try:
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π...")

            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            price_loaded = await self._load_price_model()
            freshness_loaded = await self._load_freshness_model()

            # –ï—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å - –æ–±—É—á–∞–µ–º
            if not price_loaded:
                logger.info("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ü–µ–Ω—ã...")
                await self.train_price_model_full()

            if not freshness_loaded:
                logger.info("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏...")
                await self.train_freshness_model_full()

            logger.info("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ!")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return False

    async def train_price_model_full(self):
        """üéØ –ü–û–õ–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –¶–ï–ù–´ –ù–ê –í–°–ï–• –î–ê–ù–ù–´–•"""
        try:
            from apps.website.models import FoundItem
            from asgiref.sync import sync_to_async

            logger.info("üîç –ó–∞–≥—Ä—É–∑–∫–∞ –í–°–ï–• —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Ü–µ–Ω—ã...")

            # üî• –ó–ê–ì–†–£–ñ–ê–ï–ú –í–°–ï –¢–û–í–ê–†–´ –ë–ï–ó –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ô
            items = await sync_to_async(list)(
                FoundItem.objects.filter(
                    price__isnull=False,
                    price__gt=0
                ).values(
                    'id', 'title', 'description', 'price', 'category',
                    'seller_rating', 'reviews_count', 'posted_date',
                    'found_at', 'ml_freshness_score', 'views_count',
                    'address', 'metro_stations'
                ).order_by('-found_at')[:self.config['max_training_samples']]
            )

            total_items = len(items)
            logger.info(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {total_items} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã")

            if total_items < self.config['min_training_samples']:
                logger.warning(f"‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {total_items} —Ç–æ–≤–∞—Ä–æ–≤")
                return await self._train_fallback_price_model()

            # üî• –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
            X, y = [], []

            for i, item in enumerate(items, 1):
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ price –Ω–µ None –∏ –º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ float
                    price_str = item.get('price')
                    if price_str is None:
                        continue

                    price = float(price_str)
                    if price <= 0:
                        continue

                    features = self._extract_ultra_features(item)
                    if features and len(features) == self.config['price_features_count']:
                        X.append(features)
                        y.append(price)

                    if i % 1000 == 0:
                        logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{total_items} —Ç–æ–≤–∞—Ä–æ–≤")

                except (ValueError, TypeError) as e:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–≤–∞—Ä—ã —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ü–µ–Ω–æ–π
                    continue

            valid_samples = len(X)
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {valid_samples} –≤–∞–ª–∏–¥–Ω—ã—Ö samples –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

            if valid_samples < self.config['min_training_samples']:
                logger.warning(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {valid_samples}")
                return await self._train_fallback_price_model()

            # üî• –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=self.config['validation_split'], random_state=42
            )

            # üî• –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì
            self.scaler_price = RobustScaler()
            X_train_scaled = self.scaler_price.fit_transform(X_train)
            X_test_scaled = self.scaler_price.transform(X_test)

            # üî• –û–ë–£–ß–ï–ù–ò–ï –£–õ–¨–¢–†–ê-–ú–û–î–ï–õ–ò
            rf_model = RandomForestRegressor(
                n_estimators=200,
                max_depth=30,
                min_samples_split=3,
                min_samples_leaf=1,
                max_features='sqrt',
                bootstrap=True,
                random_state=42,
                n_jobs=-1
            )

            gb_model = GradientBoostingRegressor(
                n_estimators=150,
                max_depth=15,
                learning_rate=0.1,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42
            )

            # üî• –ê–ù–°–ê–ú–ë–õ–¨
            self.price_model = VotingRegressor([
                ('rf', rf_model),
                ('gb', gb_model)
            ])

            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
            cv_scores = cross_val_score(
                self.price_model, X_train_scaled, y_train,
                cv=min(3, len(X_train) // 100),
                scoring='r2',
                n_jobs=-1
            )

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            self.price_model.fit(X_train_scaled, y_train)

            # üî• –í–ê–õ–ò–î–ê–¶–ò–Ø
            y_pred = self.price_model.predict(X_test_scaled)

            metrics = {
                'mae': mean_absolute_error(y_test, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                'r2': r2_score(y_test, y_pred),
                'mape': np.mean(np.abs((y_test - y_pred) / np.maximum(y_test, 1))) * 100
            }

            # üî• –î–ï–¢–ê–õ–¨–ù–´–ô –õ–û–ì
            self.training_log.append({
                'model': 'price',
                'timestamp': datetime.now().isoformat(),
                'samples': valid_samples,
                'metrics': metrics,
                'cv_scores': cv_scores.tolist()
            })

            logger.info(f"üöÄ –ú–û–î–ï–õ–¨ –¶–ï–ù–´ –û–ë–£–ß–ï–ù–ê –ù–ê {valid_samples} –¢–û–í–ê–†–ê–•!")
            logger.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏:")
            logger.info(f"   ‚Ä¢ MAE: {metrics['mae']:.0f} —Ä—É–±")
            logger.info(f"   ‚Ä¢ RMSE: {metrics['rmse']:.0f} —Ä—É–±")
            logger.info(f"   ‚Ä¢ R¬≤: {metrics['r2']:.4f}")
            logger.info(f"   ‚Ä¢ MAPE: {metrics['mape']:.1f}%")
            logger.info(f"   ‚Ä¢ CV R¬≤: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

            # üî• –ê–ù–ê–õ–ò–ó –í–ê–ñ–ù–û–°–¢–ò –§–ò–ß–ï–ô
            if hasattr(rf_model, 'feature_importances_'):
                importances = rf_model.feature_importances_
                top_indices = np.argsort(importances)[-5:][::-1]
                logger.info(f"üéØ –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö —Ñ–∏—á–µ–π:")
                for idx in top_indices:
                    logger.info(f"   ‚Ä¢ –§–∏—á–∞ {idx}: {importances[idx]:.4f}")

            # üî• –°–û–•–†–ê–ù–ï–ù–ò–ï
            await self._save_price_model()
            self.is_price_trained = True

            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Ü–µ–Ω—ã: {e}")
            import traceback
            traceback.print_exc()
            return await self._train_fallback_price_model()

    async def train_freshness_model_full(self):
        """üéØ –ü–û–õ–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –°–í–ï–ñ–ï–°–¢–ò"""
        try:
            from apps.website.models import FoundItem
            from asgiref.sync import sync_to_async

            logger.info("üîç –ó–∞–≥—Ä—É–∑–∫–∞ –í–°–ï–• —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏...")

            # üî• –ë–ï–†–ï–ú –í–°–ï –¢–û–í–ê–†–´ –° –û–¶–ï–ù–ö–û–ô –°–í–ï–ñ–ï–°–¢–ò
            items = await sync_to_async(list)(
                FoundItem.objects.filter(
                    ml_freshness_score__isnull=False
                ).values(
                    'id', 'title', 'description', 'category',
                    'seller_rating', 'reviews_count', 'posted_date',
                    'found_at', 'ml_freshness_score', 'views_count',
                    'price'
                ).order_by('-found_at')[:self.config['max_training_samples']]
            )

            total_items = len(items)
            logger.info(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {total_items} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏")

            if total_items < self.config['min_training_samples']:
                logger.warning("‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏")
                return await self._train_fallback_freshness_model()

            # üî• –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
            X, y = [], []

            for item in items:
                features = self._extract_freshness_features(item)
                freshness_score = float(item.get('ml_freshness_score', 0.5))

                if features and len(features) == self.config['freshness_features_count']:
                    X.append(features)
                    y.append(freshness_score)

            valid_samples = len(X)
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {valid_samples} –≤–∞–ª–∏–¥–Ω—ã—Ö samples –¥–ª—è —Å–≤–µ–∂–µ—Å—Ç–∏")

            if valid_samples < self.config['min_training_samples']:
                return await self._train_fallback_freshness_model()

            # üî• –†–ê–ó–î–ï–õ–ï–ù–ò–ï
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=self.config['validation_split'], random_state=42
            )

            # üî• –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì
            self.scaler_freshness = StandardScaler()
            X_train_scaled = self.scaler_freshness.fit_transform(X_train)
            X_test_scaled = self.scaler_freshness.transform(X_test)

            # üî• –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –°–í–ï–ñ–ï–°–¢–ò
            self.freshness_model = RandomForestRegressor(
                n_estimators=100,
                max_depth=20,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            )

            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
            cv_scores = cross_val_score(
                self.freshness_model, X_train_scaled, y_train,
                cv=min(3, len(X_train) // 100),
                scoring='r2'
            )

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            self.freshness_model.fit(X_train_scaled, y_train)

            # üî• –í–ê–õ–ò–î–ê–¶–ò–Ø
            y_pred = self.freshness_model.predict(X_test_scaled)

            metrics = {
                'mae': mean_absolute_error(y_test, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                'r2': r2_score(y_test, y_pred)
            }

            # üî• –õ–û–ì
            self.training_log.append({
                'model': 'freshness',
                'timestamp': datetime.now().isoformat(),
                'samples': valid_samples,
                'metrics': metrics,
                'cv_scores': cv_scores.tolist()
            })

            logger.info(f"üéØ –ú–û–î–ï–õ–¨ –°–í–ï–ñ–ï–°–¢–ò –û–ë–£–ß–ï–ù–ê –ù–ê {valid_samples} –¢–û–í–ê–†–ê–•!")
            logger.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ —Å–≤–µ–∂–µ—Å—Ç–∏:")
            logger.info(f"   ‚Ä¢ MAE: {metrics['mae']:.4f}")
            logger.info(f"   ‚Ä¢ RMSE: {metrics['rmse']:.4f}")
            logger.info(f"   ‚Ä¢ R¬≤: {metrics['r2']:.4f}")
            logger.info(f"   ‚Ä¢ CV R¬≤: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

            # üî• –°–û–•–†–ê–ù–ï–ù–ò–ï
            await self._save_freshness_model()
            self.is_freshness_trained = True

            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return await self._train_fallback_freshness_model()

    def _extract_ultra_features(self, item):
        """üîÆ –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –£–õ–¨–¢–†–ê-–§–ò–ß –î–õ–Ø –¶–ï–ù–´"""
        try:
            title = str(item.get('title', '')).lower()
            description = str(item.get('description', '')).lower()
            category = str(item.get('category', ''))

            features = []

            # üî• –¢–ï–ö–°–¢–û–í–´–ï –§–ò–ß–ò (10 —Ñ–∏—á)
            text_features = self._extract_text_features(title, description)
            features.extend(text_features)

            # üî• –ë–†–ï–ù–î–û–í–´–ï –§–ò–ß–ò (5 —Ñ–∏—á)
            brand_features = self._extract_brand_features(title)
            features.extend(brand_features)

            # üî• –§–ò–ß–ò –°–û–°–¢–û–Ø–ù–ò–Ø (5 —Ñ–∏—á)
            condition_features = self._extract_condition_features(title, description)
            features.extend(condition_features)

            # üî• –§–ò–ß–ò –ü–†–û–î–ê–í–¶–ê (5 —Ñ–∏—á)
            seller_features = self._extract_seller_features(item)
            features.extend(seller_features)

            # üî• –í–†–ï–ú–ï–ù–ù–´–ï –§–ò–ß–ò (5 —Ñ–∏—á)
            time_features = self._extract_time_features(item)
            features.extend(time_features)

            # üî• –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –§–ò–ß–ò (5 —Ñ–∏—á)
            extra_features = self._extract_extra_features(item)
            features.extend(extra_features)

            # üî• –ì–ê–†–ê–ù–¢–ò–Ø –†–ê–ó–ú–ï–†–ê
            if len(features) < self.config['price_features_count']:
                features.extend([0.0] * (self.config['price_features_count'] - len(features)))
            elif len(features) > self.config['price_features_count']:
                features = features[:self.config['price_features_count']]

            return features

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á: {e}")
            return [0.0] * self.config['price_features_count']

    def _extract_freshness_features(self, item):
        """üîç –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –§–ò–ß –î–õ–Ø –°–í–ï–ñ–ï–°–¢–ò"""
        try:
            title = str(item.get('title', '')).lower()
            description = str(item.get('description', '')).lower()

            features = []

            # üî• –í–†–ï–ú–Ø –ü–£–ë–õ–ò–ö–ê–¶–ò–ò
            hours_since = self._get_hours_since_publication(item)
            features.append(min(hours_since / 168, 1.0))  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ –Ω–µ–¥–µ–ª–∏

            # üî• –¢–ï–ö–°–¢–û–í–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´
            text = f"{title} {description}"

            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
            urgency_score = 0.0
            for word in self.freshness_indicators['urgency_keywords']:
                if word in text:
                    urgency_score += 0.2
            features.append(min(urgency_score, 1.0))

            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–æ–≤–∏–∑–Ω—ã
            new_score = 0.0
            for word in self.freshness_indicators['new_keywords']:
                if word in text:
                    new_score += 0.25
            features.append(min(new_score, 1.0))

            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤—Ä–µ–º–µ–Ω–∏
            time_score = 0.0
            for word in self.freshness_indicators['time_keywords']:
                if word in text:
                    time_score += 0.3
            features.append(min(time_score, 1.0))

            # üî• –ü–†–û–î–ê–í–ï–¶
            seller_rating = float(item.get('seller_rating', 0))
            reviews_count = float(item.get('reviews_count', 0))

            features.append(seller_rating / 5.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            features.append(min(reviews_count / 1000, 1.0))  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è

            # üî• –ê–ö–¢–ò–í–ù–û–°–¢–¨
            views_count = float(item.get('views_count', 0))
            features.append(min(views_count / 500, 1.0))

            # üî• –ö–ê–ß–ï–°–¢–í–û –û–ü–ò–°–ê–ù–ò–Ø
            features.append(min(len(title) / 100, 1.0))
            features.append(min(len(description) / 500, 1.0))

            # üî• –¶–ï–ù–ê (–¥–æ—Ä–æ–≥–∏–µ —Ç–æ–≤–∞—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Å–≤–µ–∂–µ–µ)
            price = float(item.get('price', 0))
            features.append(min(price / 100000, 1.0) if price > 0 else 0.0)

            # üî• –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï
            category = str(item.get('category', ''))
            features.append(1.0 if 'iphone' in category.lower() else 0.0)
            features.append(1.0 if 'apple' in title else 0.0)

            # üî• –ì–ê–†–ê–ù–¢–ò–Ø –†–ê–ó–ú–ï–†–ê
            if len(features) < self.config['freshness_features_count']:
                features.extend([0.0] * (self.config['freshness_features_count'] - len(features)))

            return features[:self.config['freshness_features_count']]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return [0.0] * self.config['freshness_features_count']

    def _extract_text_features(self, title, description):
        """üìù –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∏—á–∏"""
        text = f"{title} {description}"

        return [
            min(len(title) / 100, 1.0),  # –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            min(len(description) / 500, 1.0),  # –î–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è
            min(title.count(' ') / 20, 1.0),  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
            min(description.count(' ') / 50, 1.0),  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
            1.0 if 'iphone' in title else 0.0,  # –°–æ–¥–µ—Ä–∂–∏—Ç iPhone
            1.0 if '–ø—Ä–æ' in title else 0.0,  # –°–æ–¥–µ—Ä–∂–∏—Ç "–ø—Ä–æ"
            1.0 if 'max' in title else 0.0,  # –°–æ–¥–µ—Ä–∂–∏—Ç "max"
            1.0 if 'gb' in title or '–≥–±' in title else 0.0,  # –£–∫–∞–∑–∞–Ω–∞ –ø–∞–º—è—Ç—å
            1.0 if '202' in title else 0.0,  # –£–∫–∞–∑–∞–Ω –≥–æ–¥
            min(text.count('!') / 5, 1.0)  # –í–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏
        ]

    def _extract_brand_features(self, title):
        """üè∑Ô∏è –ë—Ä–µ–Ω–¥–æ–≤—ã–µ —Ñ–∏—á–∏"""
        brand_score = 0.0
        premium_brand = 0.0

        for brand, patterns in self.brand_patterns.items():
            for pattern in patterns:
                if pattern in title:
                    brand_score = 1.0
                    if brand in ['apple', 'samsung', 'sony']:
                        premium_brand = 1.0
                    break

        return [
            brand_score,
            premium_brand,
            1.0 if 'pro' in title else 0.0,
            1.0 if 'ultra' in title else 0.0,
            1.0 if 'plus' in title else 0.0
        ]

    def _extract_condition_features(self, title, description):
        """üîç –§–∏—á–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        text = f"{title} {description}"

        condition_scores = [0.0] * 5

        for i, (condition, data) in enumerate(self.condition_keywords.items()):
            for keyword in data['keywords']:
                if keyword in text:
                    condition_scores[i] = data['weight']
                    break

        return condition_scores

    def _extract_seller_features(self, item):
        """üë§ –§–∏—á–∏ –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        seller_rating = float(item.get('seller_rating', 0))
        reviews_count = float(item.get('reviews_count', 0))

        return [
            seller_rating / 5.0,  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥
            min(reviews_count / 1000, 1.0),  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
            1.0 if seller_rating > 4.5 else 0.0,  # –í—ã—Å–æ–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥
            1.0 if reviews_count > 100 else 0.0,  # –ú–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–æ–≤
            1.0 if seller_rating > 4.8 and reviews_count > 50 else 0.0  # –¢–æ–ø –ø—Ä–æ–¥–∞–≤–µ—Ü
        ]

    def _extract_time_features(self, item):
        """‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏"""
        try:
            found_at = item.get('found_at')
            if found_at:
                if isinstance(found_at, str):
                    found_at = datetime.fromisoformat(found_at.replace('Z', '+00:00'))

                now = datetime.now().replace(tzinfo=found_at.tzinfo) if found_at.tzinfo else datetime.now()
                hours_ago = (now - found_at).total_seconds() / 3600

                return [
                    min(hours_ago / 168, 1.0),  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ –Ω–µ–¥–µ–ª–∏
                    1.0 if hours_ago < 1 else 0.0,  # –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ
                    1.0 if hours_ago < 24 else 0.0,  # –°–µ–≥–æ–¥–Ω—è—à–Ω–µ–µ
                    1.0 if hours_ago > 168 else 0.0,  # –ë–æ–ª—å—à–µ 1 –Ω–µ–¥–µ–ª–∏
                    min(hours_ago / 24, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ –¥–Ω–µ–π
                ]
        except:
            pass

        return [0.5, 0.0, 0.0, 0.0, 0.5]

    def _extract_extra_features(self, item):
        """‚ûï –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏—á–∏"""
        views_count = float(item.get('views_count', 0))
        price = float(item.get('price', 0))

        return [
            min(views_count / 1000, 1.0),  # –ü—Ä–æ—Å–º–æ—Ç—Ä—ã
            min(price / 200000, 1.0) if price > 0 else 0.0,  # –¶–µ–Ω–∞
            1.0 if len(item.get('metro_stations', [])) > 0 else 0.0,  # –ú–µ—Ç—Ä–æ
            1.0 if item.get('address') else 0.0,  # –ê–¥—Ä–µ—Å
            min(len(item.get('images', [])) / 10, 1.0)  # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        ]

    def _get_hours_since_publication(self, item):
        """‚è∞ –†–∞—Å—á–µ—Ç —á–∞—Å–æ–≤ —Å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            posted_date = item.get('posted_date')
            if posted_date:
                if isinstance(posted_date, str):
                    posted_date = datetime.fromisoformat(posted_date.replace('Z', '+00:00'))

                now = datetime.now()
                hours_ago = (now - posted_date).total_seconds() / 3600
                return hours_ago

            found_at = item.get('found_at')
            if found_at:
                if isinstance(found_at, str):
                    found_at = datetime.fromisoformat(found_at.replace('Z', '+00:00'))

                now = datetime.now().replace(tzinfo=found_at.tzinfo) if found_at.tzinfo else datetime.now()
                hours_ago = (now - found_at).total_seconds() / 3600
                return hours_ago
        except:
            pass

        return 24.0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

    async def predict_price_ultra(self, product_data):
        """üéØ –£–õ–¨–¢–†–ê-–ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –¶–ï–ù–´"""
        try:
            if not self.is_price_trained or not self.price_model or not self.scaler_price:
                await self.train_price_model_full()

            features = self._extract_ultra_features(product_data)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            if len(features) != self.config['price_features_count']:
                logger.warning(f"‚ö†Ô∏è –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π: {len(features)}")
                features = [0.0] * self.config['price_features_count']

            features_scaled = self.scaler_price.transform([features])
            predicted_price = self.price_model.predict(features_scaled)[0]

            # üî• –ü–û–°–¢-–û–ë–†–ê–ë–û–¢–ö–ê
            original_price = float(product_data.get('price', 0))

            if original_price > 0:
                # –£–º–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
                correction_factor = self._calculate_price_correction(product_data)
                final_price = predicted_price * correction_factor

                # –ó–∞—â–∏—Ç–∞ –æ—Ç –∞–Ω–æ–º–∞–ª–∏–π
                if abs(final_price - original_price) / original_price > 2.0:
                    final_price = original_price * 1.3  # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
            else:
                final_price = predicted_price

            logger.info(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∞ —Ü–µ–Ω–∞: {final_price:.0f} —Ä—É–± (–æ—Ä–∏–≥–∏–Ω–∞–ª: {original_price:.0f} —Ä—É–±)")

            return max(1000, final_price)  # –ú–∏–Ω–∏–º—É–º 1000 —Ä—É–±

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã: {e}")
            return float(product_data.get('price', 0)) * 1.2

    async def predict_freshness_ultra(self, product_data):
        """üéØ –£–õ–¨–¢–†–ê-–ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –°–í–ï–ñ–ï–°–¢–ò"""
        try:
            if not self.is_freshness_trained or not self.freshness_model or not self.scaler_freshness:
                await self.train_freshness_model_full()

            features = self._extract_freshness_features(product_data)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            if len(features) != self.config['freshness_features_count']:
                features = [0.0] * self.config['freshness_features_count']

            features_scaled = self.scaler_freshness.transform([features])
            freshness_score = self.freshness_model.predict(features_scaled)[0]

            # üî• –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ö–û–†–†–ï–ö–¶–ò–Ø –ü–û –í–†–ï–ú–ï–ù–ò
            hours_since = self._get_hours_since_publication(product_data)
            time_based_freshness = self._calculate_time_based_freshness(hours_since)

            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
            final_freshness = freshness_score * 0.7 + time_based_freshness * 0.3

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
            final_freshness = max(0.0, min(1.0, final_freshness))

            logger.info(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∞ —Å–≤–µ–∂–µ—Å—Ç—å: {final_freshness:.3f} (—á–∞—Å–æ–≤: {hours_since:.1f})")

            return final_freshness

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            hours_since = self._get_hours_since_publication(product_data)
            return self._calculate_time_based_freshness(hours_since)

    def _calculate_price_correction(self, product_data):
        """üîß –†–∞—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ü–µ–Ω—ã"""
        correction = 1.0

        title = str(product_data.get('title', '')).lower()
        description = str(product_data.get('description', '')).lower()
        text = f"{title} {description}"

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        for condition, data in self.condition_keywords.items():
            for keyword in data['keywords']:
                if keyword in text:
                    correction *= data['weight']
                    break

        # –ü—Ä–æ–¥–∞–≤–µ—Ü
        seller_rating = float(product_data.get('seller_rating', 0))
        if seller_rating > 4.8:
            correction *= 1.05
        elif seller_rating < 3.5:
            correction *= 0.95

        # –°–≤–µ–∂–µ—Å—Ç—å
        freshness = float(product_data.get('ml_freshness_score', 0.5))
        if freshness > 0.8:
            correction *= 1.08
        elif freshness < 0.3:
            correction *= 0.9

        return max(0.5, min(2.0, correction))  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

    def _calculate_time_based_freshness(self, hours_since):
        """‚è∞ –†–∞—Å—á–µ—Ç —Å–≤–µ–∂–µ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–∏"""
        if hours_since < 0.5:  # 30 –º–∏–Ω—É—Ç
            return 0.95
        elif hours_since < 1:  # 1 —á–∞—Å
            return 0.92
        elif hours_since < 3:  # 3 —á–∞—Å–∞
            return 0.88
        elif hours_since < 6:  # 6 —á–∞—Å–æ–≤
            return 0.80
        elif hours_since < 12:  # 12 —á–∞—Å–æ–≤
            return 0.70
        elif hours_since < 24:  # 1 –¥–µ–Ω—å
            return 0.55
        elif hours_since < 48:  # 2 –¥–Ω—è
            return 0.40
        elif hours_since < 72:  # 3 –¥–Ω—è
            return 0.25
        elif hours_since < 96:  # 4 –¥–Ω—è
            return 0.15
        elif hours_since < 120:  # 5 –¥–Ω–µ–π
            return 0.10
        elif hours_since < 144:  # 6 –¥–Ω–µ–π
            return 0.07
        elif hours_since < 168:  # 1 –Ω–µ–¥–µ–ª—è
            return 0.05
        else:  # > 1 –Ω–µ–¥–µ–ª–∏
            return 0.03

    async def _train_fallback_price_model(self):
        """üîÑ –§–æ–ª–±—ç–∫ –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã"""
        try:
            from sklearn.linear_model import LinearRegression

            # –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            X = [[i * 0.1 for _ in range(self.config['price_features_count'])]
                 for i in range(100)]
            y = [10000 + i * 500 for i in range(100)]

            self.scaler_price = StandardScaler()
            X_scaled = self.scaler_price.fit_transform(X)

            self.price_model = LinearRegression()
            self.price_model.fit(X_scaled, y)
            self.is_price_trained = True

            logger.info("üîÑ –§–æ–ª–±—ç–∫ –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã –æ–±—É—á–µ–Ω–∞")
            return True
        except:
            return False

    async def _train_fallback_freshness_model(self):
        """üîÑ –§–æ–ª–±—ç–∫ –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å
            X = [[i * 0.1 for _ in range(self.config['freshness_features_count'])]
                 for i in range(50)]
            y = [0.9 - i * 0.02 for i in range(50)]

            self.scaler_freshness = StandardScaler()
            X_scaled = self.scaler_freshness.fit_transform(X)

            self.freshness_model = RandomForestRegressor(n_estimators=10, random_state=42)
            self.freshness_model.fit(X_scaled, y)
            self.is_freshness_trained = True

            logger.info("üîÑ –§–æ–ª–±—ç–∫ –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∞")
            return True
        except:
            return False

    async def _save_price_model(self):
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ü–µ–Ω—ã"""
        try:
            if self.price_model and self.scaler_price:
                joblib.dump(self.price_model, 'ultra_price_model.joblib')
                joblib.dump(self.scaler_price, 'ultra_price_scaler.joblib')

                model_info = {
                    'version': self.model_version,
                    'saved_at': datetime.now().isoformat(),
                    'feature_count': self.config['price_features_count'],
                    'training_log': self.training_log[-5:]  # 5 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ª–æ–≥–æ–≤
                }

                with open('ultra_price_model_info.json', 'w', encoding='utf-8') as f:
                    json.dump(model_info, f, ensure_ascii=False, indent=2)

                logger.info("üíæ –£–ª—å—Ç—Ä–∞-–º–æ–¥–µ–ª—å —Ü–µ–Ω—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã: {e}")

    async def _save_freshness_model(self):
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            if self.freshness_model and self.scaler_freshness:
                joblib.dump(self.freshness_model, 'ultra_freshness_model.joblib')
                joblib.dump(self.scaler_freshness, 'ultra_freshness_scaler.joblib')

                freshness_info = {
                    'version': self.model_version,
                    'saved_at': datetime.now().isoformat(),
                    'feature_count': self.config['freshness_features_count'],
                    'training_log': self.training_log[-5:]
                }

                with open('ultra_freshness_model_info.json', 'w', encoding='utf-8') as f:
                    json.dump(freshness_info, f, ensure_ascii=False, indent=2)

                logger.info("üíæ –£–ª—å—Ç—Ä–∞-–º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")

    async def _load_price_model(self):
        """üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ü–µ–Ω—ã"""
        try:
            # üî• –§–ò–ö–°: ultra_price_model.joblib - —ç—Ç–æ –°–õ–û–í–ê–†–¨!
            model_data = joblib.load('ultra_price_model.joblib')

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ —Å–ª–æ–≤–∞—Ä—è
            if isinstance(model_data, dict) and 'model' in model_data:
                self.price_model = model_data['model']
                self.scaler_price = model_data.get('scaler', StandardScaler())
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Ü–µ–Ω—ã –∏–∑–≤–ª–µ—á–µ–Ω–∞ –∏–∑ —Å–ª–æ–≤–∞—Ä—è: {type(self.price_model).__name__}")
            else:
                self.price_model = model_data
                self.scaler_price = joblib.load('ultra_price_scaler.joblib')

            self.is_price_trained = True
            logger.info("üìÇ –£–ª—å—Ç—Ä–∞-–º–æ–¥–µ–ª—å —Ü–µ–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã: {e}")
            return False

    async def _load_freshness_model(self):
        """üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            self.freshness_model = joblib.load('ultra_freshness_model.joblib')
            self.scaler_freshness = joblib.load('ultra_freshness_scaler.joblib')
            self.is_freshness_trained = True

            logger.info("üìÇ –£–ª—å—Ç—Ä–∞-–º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return False

    async def get_model_stats(self):
        """üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–µ–π"""
        try:
            stats = {
                'model_version': self.model_version,
                'price_model_trained': self.is_price_trained,
                'freshness_model_trained': self.is_freshness_trained,
                'price_feature_count': self.config['price_features_count'],
                'freshness_feature_count': self.config['freshness_features_count'],
                'last_training': None,
                'training_log_count': len(self.training_log)
            }

            if self.training_log:
                last_training = self.training_log[-1]
                stats['last_training'] = last_training.get('timestamp')
                stats['last_training_samples'] = last_training.get('samples', 0)

                if 'metrics' in last_training:
                    stats['last_price_r2'] = last_training['metrics'].get('r2', 0)
                    stats['last_freshness_r2'] = last_training['metrics'].get('r2', 0)

            return stats

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

    async def load_model(self):
        """üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)"""
        try:
            logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–µ–π...")

            price_loaded = False
            freshness_loaded = False

            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Ü–µ–Ω—ã
            try:
                model_data = joblib.load('ultra_price_model.joblib')

                # üî• –§–ò–ö–°: –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                if isinstance(model_data, dict) and 'model' in model_data:
                    self.price_model = model_data['model']
                    self.scaler_price = model_data.get('scaler', StandardScaler())
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Ü–µ–Ω—ã –∏–∑–≤–ª–µ—á–µ–Ω–∞: {type(self.price_model).__name__}")
                else:
                    # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ –º–æ–¥–µ–ª—å (–Ω–µ —Å–ª–æ–≤–∞—Ä—å)
                    self.price_model = model_data
                    try:
                        self.scaler_price = joblib.load('ultra_price_scaler.joblib')
                    except:
                        self.scaler_price = StandardScaler()

                price_loaded = True
                logger.info("‚úÖ –£–ª—å—Ç—Ä–∞-–º–æ–¥–µ–ª—å —Ü–µ–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

                # üî• –í–ê–ñ–ù–û: –î—É–±–ª–∏—Ä—É–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                self.model = self.price_model
                self.feature_scaler = self.scaler_price

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —É–ª—å—Ç—Ä–∞-–º–æ–¥–µ–ª—å —Ü–µ–Ω—ã: {e}")
                price_loaded = False

            # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏
            try:
                self.freshness_model = joblib.load('ultra_freshness_model.joblib')

                try:
                    self.scaler_freshness = joblib.load('ultra_freshness_scaler.joblib')
                except:
                    self.scaler_freshness = StandardScaler()

                freshness_loaded = True
                logger.info("‚úÖ –£–ª—å—Ç—Ä–∞-–º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
                freshness_loaded = False

            # 3. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥–∏
            self.is_price_trained = price_loaded
            self.is_freshness_trained = freshness_loaded
            self.is_trained = price_loaded  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

            if self.is_trained:
                logger.info("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–ª–∏ —Å–æ–∑–¥–∞–Ω—ã")
                return True
            else:
                logger.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –Ω—É–∂–Ω–æ –æ–±—É—á–µ–Ω–∏–µ")
                return False

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            # –§–æ–ª–±—ç–∫
            from sklearn.linear_model import LinearRegression
            self.price_model = LinearRegression()
            self.scaler_price = StandardScaler()
            self.model = self.price_model
            self.feature_scaler = self.scaler_price
            self.is_trained = True
            logger.info("üîÑ –°–æ–∑–¥–∞–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏")
            return True

    def get_prediction_confidence(self, product_data):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (0.0-1.0)"""
        try:
            # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence = 0.7

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–≤–µ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤
            freshness = product_data.get('ml_freshness_score', 0.5)
            if freshness > 0.8:
                confidence += 0.2
            elif freshness > 0.6:
                confidence += 0.1

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            required_fields = ['price', 'title', 'description']
            present_fields = sum(1 for field in required_fields
                                 if field in product_data and product_data[field])
            confidence += (present_fields / len(required_fields)) * 0.2

            return min(confidence, 0.95)
        except:
            return 0.7

    def __getitem__(self, index):
        """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –¥–ª—è –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –∫–∞–∫ —Å–ø–∏—Å–æ–∫"""
        logger.warning(f"‚ö†Ô∏è –ö—Ç–æ-—Ç–æ –ø—ã—Ç–∞–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ MLPricePredictor –ø–æ –∏–Ω–¥–µ–∫—Å—É [{index}]")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º–æ–≥–æ —Å–µ–±—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        return self

    def __setitem__(self, index, value):
        """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É"""
        logger.warning(f"‚ö†Ô∏è –ö—Ç–æ-—Ç–æ –ø—ã—Ç–∞–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å MLPricePredictor –ø–æ –∏–Ω–¥–µ–∫—Å—É [{index}]")
        pass  # –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º

    @property
    def is_trained(self):
        """–°–≤–æ–π—Å—Ç–≤–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        return getattr(self, '_is_trained', False)

    @is_trained.setter
    def is_trained(self, value):
        """–°–µ—Ç—Ç–µ—Ä –¥–ª—è is_trained"""
        self._is_trained = bool(value)

    # üî• –î–û–ë–ê–í–¨ –≠–¢–ò –ú–ï–¢–û–î–´ –î–õ–Ø –ü–û–õ–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò:

    @property
    def freshness_predictor(self):
        """üî• –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨: —Å–æ–∑–¥–∞–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π freshness predictor"""
        from apps.parsing.ai.ml_freshness_predictor import MLFreshnessPredictor

        if not hasattr(self, '_freshness_predictor_compat'):
            self._freshness_predictor_compat = MLFreshnessPredictor()

            # –ï—Å–ª–∏ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–≤–µ–∂–µ—Å—Ç–∏ - –∫–æ–ø–∏—Ä—É–µ–º –µ–µ
            if self.freshness_model:
                self._freshness_predictor_compat.model = self.freshness_model
                self._freshness_predictor_compat.scaler = self.scaler_freshness
                self._freshness_predictor_compat.is_trained = True
                logger.info("‚úÖ –°–æ–≤–º–µ—Å—Ç–∏–º—ã–π freshness predictor —Å–æ–∑–¥–∞–Ω —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª—å—é")

        return self._freshness_predictor_compat

    def get_model(self, index=0):
        """üìä –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É"""
        if index == 0:
            return self.price_model
        elif index == 1:
            return self.freshness_model
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å –º–æ–¥–µ–ª–∏: {index}")
            return None

    def get_freshness_category(self, freshness_score):
        """üìä –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–≤–µ–∂–µ—Å—Ç–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
        if freshness_score >= 0.8:
            return "üî• –û—á–µ–Ω—å —Å–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.6:
            return "‚úÖ –°–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.4:
            return "‚ö° –°—Ä–µ–¥–Ω–µ —Å–≤–µ–∂–µ–µ"
        elif freshness_score >= 0.2:
            return "üìÖ –°—Ä–µ–¥–Ω–µ —Å—Ç–∞—Ä—ã–π"
        else:
            return "üíÄ –°—Ç–∞—Ä—ã–π"

    async def save_model(self):
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
        try:
            await self._save_price_model()
            await self._save_freshness_model()
            logger.info("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –º–µ—Ç–æ–¥)")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            return False