import logging
import asyncio
import re
from datetime import datetime
from typing import Dict, List, Any
import hashlib

logger = logging.getLogger('parser.ai.queries')

class QueryOptimizer:
    """üéØ –£–ú–ù–´–ô –û–ü–¢–ò–ú–ò–ó–ê–¢–û–† –ü–û–ò–°–ö–û–í–´–• –ó–ê–ü–†–û–°–û–í"""

    def __init__(self):
        self.freshness_modifiers = [
            "—Å–µ–≥–æ–¥–Ω—è", "—Ç–æ–ª—å–∫–æ —á—Ç–æ", "—Å–≤–µ–∂–∏–π", "–Ω–æ–≤—ã–π", "—Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª–µ–Ω",
            "—Å—Ä–æ—á–Ω–æ", "–±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–¥–∞–∂–∞", "—Ç–æ–ª—å–∫–æ –ø–æ—è–≤–∏–ª—Å—è"
        ]

        self.time_modifiers = {
            'morning': ["—É—Ç—Ä–æ", "—Å–µ–≥–æ–¥–Ω—è —É—Ç—Ä–æ–º", "—É—Ç—Ä–µ–Ω–Ω—è—è"],
            'afternoon': ["–¥–µ–Ω—å", "—Å–µ–≥–æ–¥–Ω—è –¥–Ω–µ–º", "–¥–Ω–µ–≤–Ω–∞—è"],
            'evening': ["–≤–µ—á–µ—Ä", "—Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º", "–≤–µ—á–µ—Ä–Ω—è—è"],
            'night': ["–Ω–æ—á—å", "—Å–µ–≥–æ–¥–Ω—è –Ω–æ—á—å—é", "–Ω–æ—á–Ω–∞—è"]
        }

        self.successful_queries = {}
        self.query_stats = {}

    async def optimize_queries(self, base_queries: List[str], time_of_day: str = None) -> List[str]:
        """üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        try:
            logger.info(f"üîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è {len(base_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤...")

            optimized_queries = set()

            for query in base_queries:
                # –ë–∞–∑–æ–≤—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
                base_optimized = await self._add_freshness_modifiers(query)
                optimized_queries.update(base_optimized)

                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
                if time_of_day:
                    time_optimized = await self._add_time_modifiers(query, time_of_day)
                    optimized_queries.update(time_optimized)

                # –°–∏–Ω–æ–Ω–∏–º–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
                synonym_optimized = await self._generate_synonyms(query)
                optimized_queries.update(synonym_optimized)

            final_queries = list(optimized_queries)
            logger.info(f"üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(final_queries)} –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")

            return final_queries[:15]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
            return base_queries

    async def _add_freshness_modifiers(self, query: str) -> List[str]:
        """‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        variants = []
        top_modifiers = self.freshness_modifiers[:3]

        for modifier in top_modifiers:
            variants.append(f"{modifier} {query}")
            variants.append(f"{query} {modifier}")

        return variants

    async def _add_time_modifiers(self, query: str, time_of_day: str) -> List[str]:
        """üïí –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        variants = []

        if time_of_day in self.time_modifiers:
            modifiers = self.time_modifiers[time_of_day]
            for modifier in modifiers:
                variants.append(f"{query} {modifier}")
                variants.append(f"{modifier} {query}")

        return variants

    async def _generate_synonyms(self, query: str) -> List[str]:
        """üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω–æ–Ω–∏–º–∏—á–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
        synonyms_map = {
            '–±/—É': ['–±—É', '–ø–æ–¥–µ—Ä–∂–∞–Ω–Ω—ã–π', 'second hand'],
            '–Ω–æ–≤—ã–π': ['–Ω–æ–≤–µ–Ω—å–∫–∏–π', '—Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π', '–æ—Ä–∏–≥–∏–Ω–∞–ª'],
            '—Å—Ä–æ—á–Ω–æ': ['—Å—Ä–æ—á–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞', '–Ω—É–∂–Ω–æ –±—ã—Å—Ç—Ä–æ', '–±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–¥–∞–∂–∞'],
            'iphone': ['–∞–π—Ñ–æ–Ω', 'iphone', 'apple iphone'],
            'macbook': ['–º–∞–∫–±—É–∫', 'mac book', 'apple macbook']
        }

        variants = []
        words = query.lower().split()

        for i, word in enumerate(words):
            if word in synonyms_map:
                for synonym in synonyms_map[word]:
                    new_words = words.copy()
                    new_words[i] = synonym
                    variants.append(' '.join(new_words))

        return variants

    async def learn_from_success(self, successful_queries: List[str]):
        """üß† –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö"""
        try:
            for query in successful_queries:
                query_hash = self._hash_query(query)

                if query_hash not in self.successful_queries:
                    self.successful_queries[query_hash] = {
                        'query': query,
                        'success_count': 0,
                        'last_used': datetime.now().isoformat()
                    }

                self.successful_queries[query_hash]['success_count'] += 1

            logger.info(f"üìö –û–±—É—á–µ–Ω–æ –Ω–∞ {len(successful_queries)} —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∑–∞–ø—Ä–æ—Å–∞—Ö: {e}")

    def _hash_query(self, query: str) -> str:
        """üîë –•–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞"""
        return hashlib.md5(query.encode()).hexdigest()[:8]

    async def get_top_queries(self, limit: int = 10) -> List[str]:
        """üèÜ –¢–æ–ø —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            sorted_queries = sorted(
                self.successful_queries.values(),
                key=lambda x: x['success_count'],
                reverse=True
            )
            return [q['query'] for q in sorted_queries[:limit]]
        except: return []

    async def get_optimization_stats(self) -> Dict[str, Any]:
        """üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        return {
            'total_successful_queries': len(self.successful_queries),
            'top_modifiers': self.freshness_modifiers[:5],
            'learning_enabled': True,
            'most_successful_queries': await self.get_top_queries(5)
        }