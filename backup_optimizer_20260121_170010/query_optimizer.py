import logging
import asyncio
import re
from datetime import datetime
from typing import Dict, List, Any
from collections import Counter
import hashlib

logger = logging.getLogger('parser.ai')


class QueryOptimizer:
    """üéØ –£–ú–ù–´–ô –û–ü–¢–ò–ú–ò–ó–ê–¢–û–† –ü–û–ò–°–ö–û–í–´–• –ó–ê–ü–†–û–°–û–í"""

    def __init__(self):
        self.freshness_modifiers = [
            "—Å–µ–≥–æ–¥–Ω—è",
            "—Ç–æ–ª—å–∫–æ —á—Ç–æ",
            "—Å–≤–µ–∂–∏–π",
            "–Ω–æ–≤—ã–π",
            "—Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª–µ–Ω",
            "—Å—Ä–æ—á–Ω–æ",
            "–±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–¥–∞–∂–∞",
            "—Ç–æ–ª—å–∫–æ –ø–æ—è–≤–∏–ª—Å—è",
            "–Ω–æ–≤–∏–Ω–∫–∞"
        ]

        self.time_specific_modifiers = {
            'morning': ["—É—Ç—Ä–æ", "—Å–µ–≥–æ–¥–Ω—è —É—Ç—Ä–æ–º", "—É—Ç—Ä–µ–Ω–Ω—è—è"],
            'afternoon': ["–¥–µ–Ω—å", "—Å–µ–≥–æ–¥–Ω—è –¥–Ω–µ–º", "–¥–Ω–µ–≤–Ω–∞—è"],
            'evening': ["–≤–µ—á–µ—Ä", "—Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º", "–≤–µ—á–µ—Ä–Ω—è—è"],
            'night': ["–Ω–æ—á—å", "—Å–µ–≥–æ–¥–Ω—è –Ω–æ—á—å—é", "–Ω–æ—á–Ω–∞—è"]
        }

        self.successful_combinations = {}
        self.query_stats = {}

    async def optimize_queries(self, base_queries: List[str], time_of_day: str = None) -> List[str]:
        """üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –°–í–ï–ñ–ò–• –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        try:
            logger.info(f"üîç –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è {len(base_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Å–≤–µ–∂–µ—Å—Ç–∏...")

            optimized_queries = set()

            for query in base_queries:
                # üî• –ë–ê–ó–û–í–´–ï –í–ê–†–ò–ê–ù–¢–´ –°–û –°–í–ï–ñ–ï–°–¢–¨–Æ
                base_fresh = await self._add_freshness_modifiers(query)
                optimized_queries.update(base_fresh)

                # üî• –í–†–ï–ú–ï–ù–ù–´–ï –í–ê–†–ò–ê–ù–¢–´
                if time_of_day:
                    time_fresh = await self._add_time_specific_modifiers(query, time_of_day)
                    optimized_queries.update(time_fresh)

                # üî• –°–ò–ù–û–ù–ò–ú–ò–ß–ù–´–ï –í–ê–†–ò–ê–ù–¢–´
                synonym_fresh = await self._generate_synonym_variants(query)
                optimized_queries.update(synonym_fresh)

            final_queries = list(optimized_queries)
            logger.info(f"üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(final_queries)} –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")

            return final_queries[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
            return base_queries

    async def _add_freshness_modifiers(self, query: str) -> List[str]:
        """‚ûï –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å–≤–µ–∂–µ—Å—Ç–∏ –∫ –∑–∞–ø—Ä–æ—Å—É"""
        variants = []

        # üî• –¢–û–ü-3 –ú–û–î–ò–§–ò–ö–ê–¢–û–†–ê –°–í–ï–ñ–ï–°–¢–ò
        top_modifiers = self.freshness_modifiers[:3]

        for modifier in top_modifiers:
            # –î–û–ë–ê–í–õ–Ø–ï–ú –í –ù–ê–ß–ê–õ–û
            variants.append(f"{modifier} {query}")
            # –î–û–ë–ê–í–õ–Ø–ï–ú –í –ö–û–ù–ï–¶
            variants.append(f"{query} {modifier}")

        return variants

    async def _add_time_specific_modifiers(self, query: str, time_of_day: str) -> List[str]:
        """üïí –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã"""
        variants = []

        if time_of_day in self.time_specific_modifiers:
            modifiers = self.time_specific_modifiers[time_of_day]

            for modifier in modifiers:
                variants.append(f"{query} {modifier}")
                variants.append(f"{modifier} {query}")

        return variants

    async def _generate_synonym_variants(self, query: str) -> List[str]:
        """üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω–æ–Ω–∏–º–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã"""
        synonyms_map = {
            '–±/—É': ['–±—É', '–ø–æ–¥–µ—Ä–∂–∞–Ω–Ω—ã–π', 'second hand'],
            '–Ω–æ–≤—ã–π': ['–Ω–æ–≤–µ–Ω—å–∫–∏–π', '—Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π', '–æ—Ä–∏–≥–∏–Ω–∞–ª'],
            '—Å—Ä–æ—á–Ω–æ': ['—Å—Ä–æ—á–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞', '–Ω—É–∂–Ω–æ –±—ã—Å—Ç—Ä–æ', '–±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–¥–∞–∂–∞'],
            'iphone': ['–∞–π—Ñ–æ–Ω', 'iphone', 'apple iphone'],
            'macbook': ['–º–∞–∫–±—É–∫', 'mac book', 'apple macbook'],
            'samsung': ['—Å–∞–º—Å—É–Ω–≥', 'samsung galaxy'],
            '—Ç–µ–ª–µ—Ñ–æ–Ω': ['—Å–º–∞—Ä—Ç—Ñ–æ–Ω', 'mobile', '–º–æ–±–∏–ª—å–Ω—ã–π'],
            '–Ω–æ—É—Ç–±—É–∫': ['–ª—ç–ø—Ç–æ–ø', 'laptop', '–Ω–æ—É—Ç']
        }

        variants = []
        words = query.lower().split()

        for i, word in enumerate(words):
            if word in synonyms_map:
                for synonym in synonyms_map[word]:
                    new_words = words.copy()
                    new_words[i] = synonym
                    variants.append(' '.join(new_words))

        return variants

    async def learn_from_successful_queries(self, successful_queries: List[str]):
        """üß† –£—á–∏–º—Å—è –Ω–∞ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö"""
        try:
            for query in successful_queries:
                query_hash = self._hash_query(query)

                if query_hash not in self.successful_combinations:
                    self.successful_combinations[query_hash] = {
                        'query': query,
                        'success_count': 0,
                        'last_used': datetime.now().isoformat()
                    }

                self.successful_combinations[query_hash]['success_count'] += 1
                self.successful_combinations[query_hash]['last_used'] = datetime.now().isoformat()

            logger.info(f"üìö –û–±—É—á–µ–Ω–æ –Ω–∞ {len(successful_queries)} —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö: {e}")

    def _hash_query(self, query: str) -> str:
        """üîë –•–µ—à–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        return hashlib.md5(query.encode()).hexdigest()[:8]

    async def get_top_queries(self, limit: int = 10) -> List[str]:
        """üèÜ –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            sorted_queries = sorted(
                self.successful_combinations.values(),
                key=lambda x: x['success_count'],
                reverse=True
            )

            return [q['query'] for q in sorted_queries[:limit]]

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
            return []

    async def get_optimization_stats(self) -> Dict[str, Any]:
        """üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        return {
            'total_successful_queries': len(self.successful_combinations),
            'top_modifiers': self.freshness_modifiers[:5],
            'learning_enabled': True,
            'success_rate': self._calculate_success_rate(),
            'most_successful_combinations': await self.get_top_queries(5)
        }

    def _calculate_success_rate(self) -> float:
        """üìà –†–∞—Å—á–µ—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        if not self.successful_combinations:
            return 0.0

        total_success = sum(q['success_count'] for q in self.successful_combinations.values())
        avg_success = total_success / len(self.successful_combinations)

        return min(avg_success / 10.0, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º

    async def optimize_for_category(self, category: str, base_queries: List[str]) -> List[str]:
        """üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        try:
            category_specific_modifiers = {
                'electronics': ['—Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π', '–æ—Ä–∏–≥–∏–Ω–∞–ª', '–Ω–æ–≤—ã–π', '–Ω–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω'],
                'clothing': ['–Ω–æ–≤—ã–π —Å –±–∏—Ä–∫–æ–π', '–Ω–µ –Ω–æ—à–µ–Ω–Ω—ã–π', '—Å —ç—Ç–∏–∫–µ—Ç–∫–æ–π'],
                'automotive': ['–ø—Ä–æ–±–µ–≥', '—Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—Ç–ª–∏—á–Ω–æ–µ', '–æ–±—Å–ª—É–∂–µ–Ω'],
                'real_estate': ['—Å–≤–µ–∂–∏–π', '—Å–µ–≥–æ–¥–Ω—è', '—Å—Ä–æ—á–Ω–æ']
            }

            optimized_queries = set()

            for query in base_queries:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
                if category in category_specific_modifiers:
                    for modifier in category_specific_modifiers[category][:2]:
                        optimized_queries.add(f"{query} {modifier}")
                        optimized_queries.add(f"{modifier} {query}")

                # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å–≤–µ–∂–µ—Å—Ç–∏
                base_optimized = await self._add_freshness_modifiers(query)
                optimized_queries.update(base_optimized)

            return list(optimized_queries)[:15]

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
            return base_queries

    async def analyze_query_performance(self, query: str, found_items: int, total_items: int):
        """üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        try:
            success_rate = found_items / total_items if total_items > 0 else 0

            if query not in self.query_stats:
                self.query_stats[query] = {
                    'total_searches': 0,
                    'successful_searches': 0,
                    'total_found': 0,
                    'success_rate': 0
                }

            stats = self.query_stats[query]
            stats['total_searches'] += 1
            stats['total_found'] += found_items

            if found_items > 0:
                stats['successful_searches'] += 1

            stats['success_rate'] = stats['successful_searches'] / stats['total_searches'] if stats[
                                                                                                  'total_searches'] > 0 else 0

            # –û–±–Ω–æ–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω
            if success_rate > 0.3:  # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã—à–µ 30%
                await self.learn_from_successful_queries([query])

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")

    async def get_query_recommendations(self, base_query: str, limit: int = 5) -> List[str]:
        """üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∑–∞–ø—Ä–æ—Å–∞"""
        try:
            recommendations = set()

            # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å–≤–µ–∂–µ—Å—Ç–∏
            freshness_recs = await self._add_freshness_modifiers(base_query)
            recommendations.update(freshness_recs)

            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
            synonym_recs = await self._generate_synonym_variants(base_query)
            recommendations.update(synonym_recs)

            # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
            top_queries = await self.get_top_queries(limit)
            for successful_query in top_queries:
                if base_query in successful_query:
                    recommendations.add(successful_query)

            return list(recommendations)[:limit]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return [base_query]