import re
import time
import logging
from datetime import datetime
from urllib.parse import quote, quote_plus
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from typing import Dict, Any, List, Optional

from .base_site_parser import BaseSiteParser
from ..utils.product_validator import ProductValidator
from ..utils.image_processor import ImageProcessor
from ..utils.moscow_metro import MOSCOW_METRO_DATABASE

logger = logging.getLogger('parser.avito')

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ cloudscraper
try:
    from apps.parsing.utils.cloudscraper_engine import CloudscraperEngine

    CLOUDSCRAPER_AVAILABLE = True
    logger.info("‚úÖ CloudscraperEngine –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞")
except ImportError as e:
    CLOUDSCRAPER_AVAILABLE = False
    logger.info(f"‚ÑπÔ∏è CloudscraperEngine –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

try:
    from apps.parsing.utils.custom_user_agents import apply_user_agent_to_driver

    USER_AGENTS_AVAILABLE = True
except ImportError as e:
    USER_AGENTS_AVAILABLE = False


class AvitoParser(BaseSiteParser):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è Avito.ru —Å –±—ã—Å—Ç—Ä—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏ –∏ –≥–∏–±—Ä–∏–¥–Ω—ã–º —Ä–µ–∂–∏–º–æ–º (cloudscraper + selenium)"""

    def __init__(self, driver, city=None):
        super().__init__(driver)
        self.logger = logger
        self.validator = ProductValidator()
        self.image_processor = ImageProcessor(driver)
        self.metro_database = MOSCOW_METRO_DATABASE
        self._captcha_notification_sent = False

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã —Å–≤–µ–∂–µ—Å—Ç–∏
        self.freshness_indicators = [
            '[data-marker*="new"]',
            '.iva-item-dateStep-__qB8a',
            '[data-marker="item-date"]',
            '.styles_remainingTime__P_aaq',
        ]

        self.city = city if city else "–ú–æ—Å–∫–≤–∞"
        self.site_name = "avito"
        self.base_url = "https://www.avito.ru"

        self.logger.info(f"üåç AvitoParser: –≥–æ—Ä–æ–¥ {self.city}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è cloudscraper –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        self.use_cloudscraper = CLOUDSCRAPER_AVAILABLE
        if self.use_cloudscraper:
            try:
                self.cloudscraper_engine = CloudscraperEngine(city=self.city)
                logger.info(f"‚úÖ CloudscraperEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ –¥–ª—è {self.city}")
                self.fallback_to_selenium = True  # –ê–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å CloudscraperEngine: {e}")
                self.use_cloudscraper = False
                self.cloudscraper_engine = None
        else:
            self.cloudscraper_engine = None
            self.fallback_to_selenium = True

        if USER_AGENTS_AVAILABLE:
            try:
                apply_user_agent_to_driver(driver, getattr(self, 'window_id', 0))
            except Exception as e:
                self.logger.debug(f"‚ö†Ô∏è User-Agent: {e}")

    def build_search_url(self, query, page=1, **kwargs):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ URL –¥–ª—è –ø–æ–∏—Å–∫–∞"""
        try:
            encoded_query = quote_plus(query)

            if self.city:
                try:
                    from apps.parsing.utils.city_translator import CITY_MAPPING
                    city_mapping = CITY_MAPPING
                    city_lower = self.city.strip().lower()

                    if city_lower in city_mapping:
                        city_part = city_mapping[city_lower]
                    else:
                        for rus_name, eng_name in city_mapping.items():
                            if rus_name.lower() == city_lower:
                                city_part = eng_name
                                break
                        else:
                            # –§–æ–ª–±—ç–∫ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
                            translit_map = {
                                '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd',
                                '–µ': 'e', '—ë': 'e', '–∂': 'zh', '–∑': 'z', '–∏': 'i',
                                '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm', '–Ω': 'n',
                                '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't',
                                '—É': 'u', '—Ñ': 'f', '—Ö': 'kh', '—Ü': 'ts', '—á': 'ch',
                                '—à': 'sh', '—â': 'shch', '—ä': '', '—ã': 'y', '—å': '',
                                '—ç': 'e', '—é': 'yu', '—è': 'ya'
                            }
                            city_translit = ''
                            for char in city_lower:
                                if char in translit_map:
                                    city_translit += translit_map[char]
                                elif char in ' -':
                                    city_translit += '-'
                                else:
                                    city_translit += char
                            city_part = city_translit
                except ImportError:
                    local_mapping = {
                        '–º–æ—Å–∫–≤–∞': 'moskva', '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥': 'sankt-peterburg',
                        '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫': 'novosibirsk', '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥': 'ekaterinburg',
                        '–∫–∞–∑–∞–Ω—å': 'kazan', '–Ω–∏–∂–Ω–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥': 'nizhniy_novgorod',
                        '—á–µ–ª—è–±–∏–Ω—Å–∫': 'chelyabinsk', '—Å–∞–º–∞—Ä–∞': 'samara', '–æ–º—Å–∫': 'omsk',
                        '—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É': 'rostov-na-donu', '—É—Ñ–∞': 'ufa',
                        '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫': 'krasnoyarsk', '–ø–µ—Ä–º—å': 'perm', '–≤–æ—Ä–æ–Ω–µ–∂': 'voronezh',
                        '–≤–æ–ª–≥–æ–≥—Ä–∞–¥': 'volgograd', '–ø–µ–Ω–∑–∞': 'penza', '—Å–æ—á–∏': 'sochi'
                    }
                    city_lower = self.city.strip().lower()
                    city_part = local_mapping.get(city_lower, 'moskva')
            else:
                city_part = 'moskva'

            # –ß–∏—Å—Ç–∏–º –¥–≤–æ–π–Ω—ã–µ –¥–µ—Ñ–∏—Å—ã
            city_part = re.sub(r'-+', '-', city_part)
            url = f"{self.base_url}/{city_part}?q={encoded_query}"

            params = ["s=104"]  # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ

            if hasattr(self, 'min_price') and self.min_price:
                params.append(f"pmin={int(self.min_price)}")
            if hasattr(self, 'max_price') and self.max_price:
                params.append(f"pmax={int(self.max_price)}")
            if page > 1:
                params.append(f"p={page}")

            if params:
                url += "&" + "&".join(params)

            self.logger.debug(f"üîó URL: {url}")
            return url

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ URL: {e}")
            return f"{self.base_url}/moskva?q={quote_plus(query)}&s=104"

    async def search_items(self, query, **kwargs):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
        try:
            # üî• –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ê–ï–ú CLOUDSCRAPER (–Ω–µ—Ç —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ–∫—Å–∏)
            # hybrid_mode = kwargs.get('hybrid_mode', True) and self.use_cloudscraper

            # if hybrid_mode:
            #     cloudscraper_result = await self._try_cloudscraper_first(query, kwargs)
            #     if cloudscraper_result is not None:
            #         return cloudscraper_result

            logger.info(f"üéØ Selenium –ø–æ–∏—Å–∫: '{query}' (cloudscraper –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω)")
            return await self._search_with_selenium(query, **kwargs)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ search_items: {e}")
            return await self._search_with_selenium(query, **kwargs)

    async def _try_cloudscraper_first(self, query: str, kwargs: dict) -> Optional[List]:
        """–ü—Ä–æ–±—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ cloudscraper –ø–µ—Ä–µ–¥ Selenium"""
        try:
            if not self.use_cloudscraper or not self.cloudscraper_engine:
                return None

            max_pages = kwargs.get('max_pages', 2)  # –î–ª—è cloudscraper –º–µ–Ω—å—à–µ —Å—Ç—Ä–∞–Ω–∏—Ü
            max_items = kwargs.get('max_items', 30)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏

            logger.info(f"‚ö° –ü—Ä–æ–±—É—é cloudscraper –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}' (–º–∞–∫—Å. {max_pages} —Å—Ç—Ä.)")

            start_time = time.time()
            cloud_result = self.cloudscraper_engine.search_items_fast(
                query,
                max_pages=max_pages,
                min_price=kwargs.get('min_price'),
                max_price=kwargs.get('max_price')
            )

            elapsed = time.time() - start_time

            if not cloud_result:
                logger.warning(f"‚ö†Ô∏è Cloudscraper –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è '{query}'")
                return None

            if cloud_result.get('blocked'):
                logger.warning(f"üö´ Cloudscraper –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è '{query}': {cloud_result.get('blocked_reason')}")
                return None

            items = cloud_result.get('items', [])

            if items:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç AvitoParser
                converted_items = []
                for item in items[:max_items]:
                    try:
                        converted_item = {
                            'name': item.get('name', ''),
                            'price': item.get('price', 0),
                            'target_price': item.get('price', 0),
                            'url': item.get('url', ''),
                            'item_id': item.get('item_id', ''),
                            'product_id': item.get('item_id', ''),
                            'category': query,
                            'description': f"–ù–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ cloudscraper –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'",
                            'time_listed': 24.0,  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                            'freshness_score': 0.3,
                            'is_fresh_by_indicators': False,
                            'site': 'avito',
                            'city': self.city,
                            'engine_used': 'cloudscraper'  # –û—Ç–º–µ—Ç–∫–∞ –æ –¥–≤–∏–∂–∫–µ
                        }

                        # –ï—Å–ª–∏ –µ—Å—Ç—å URL —Ç–æ–≤–∞—Ä–∞, –ø–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ —á–µ—Ä–µ–∑ Selenium
                        if converted_item.get('url') and kwargs.get('get_details', True):
                            try:
                                self.logger.info(f"üîç –ü–æ–ª—É—á–∞—é –¥–µ—Ç–∞–ª–∏ —Ç–æ–≤–∞—Ä–∞ —á–µ—Ä–µ–∑ Selenium: {converted_item['item_id']}")
                                detailed_item = await self.get_product_details(converted_item)
                                converted_item.update(detailed_item)
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —á–µ—Ä–µ–∑ Selenium: {e}")

                        converted_items.append(converted_item)
                    except Exception as e:
                        logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                        continue

                logger.info(
                    f"‚úÖ Cloudscraper –Ω–∞—à–µ–ª {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –∑–∞ {elapsed:.2f} —Å–µ–∫, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {len(converted_items)}")
                return converted_items
            else:
                logger.warning(f"‚ö†Ô∏è Cloudscraper –Ω–µ –Ω–∞—à–µ–ª —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è '{query}'")
                return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ _try_cloudscraper_first: {e}")
            return None

    async def _search_with_selenium(self, query, **kwargs):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Selenium-–ø–æ–∏—Å–∫ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥)"""
        try:
            self.logger.info(f"üéØ Selenium –ø–æ–∏—Å–∫: '{query}'")

            max_pages = kwargs.get('max_pages', 3)
            max_items = kwargs.get('max_items', 100)

            all_items = []

            for page in range(1, max_pages + 1):
                self.logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}/{max_pages} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}'")

                url = self.build_search_url(query, page=page)
                self.logger.debug(f"üåê –û—Ç–∫—Ä—ã–≤–∞–µ–º: {url[:80]}...")

                try:
                    self.driver.get(url)
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                    break

                time.sleep(1.0)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
                page_title = self.driver.title.lower()
                if any(word in page_title for word in ["–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è", "—Ä–æ–±–æ—Ç", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞"]):
                    self.logger.warning("üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                    await self._handle_captcha_situation()
                    break

                # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                items = await self.parse_search_results(query)

                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
                converted_items = []
                for item in items:
                    if 'title' in item:
                        converted_item = item.copy()
                        converted_item['name'] = converted_item['title']
                        del converted_item['title']
                        converted_items.append(converted_item)
                    else:
                        converted_items.append(item)

                self.logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(converted_items)} —Ç–æ–≤–∞—Ä–æ–≤")
                all_items.extend(converted_items)

                # –ï—Å–ª–∏ –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –º–∞–ª–æ —Ç–æ–≤–∞—Ä–æ–≤, –¥–∞–ª—å—à–µ –Ω–µ –ª–∏—Å—Ç–∞–µ–º
                if len(converted_items) < 10:
                    self.logger.info(f"‚ö†Ô∏è –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –º–∞–ª–æ —Ç–æ–≤–∞—Ä–æ–≤ ({len(converted_items)}), –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è")
                    break

                # –ï—Å–ª–∏ —É–∂–µ —Å–æ–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤
                if len(all_items) >= max_items:
                    self.logger.info(f"‚ö†Ô∏è –°–æ–±—Ä–∞–Ω–æ {len(all_items)} —Ç–æ–≤–∞—Ä–æ–≤ (–ª–∏–º–∏—Ç: {max_items})")
                    break

                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                time.sleep(0.5)

            # –û—Ç–º–µ—á–∞–µ–º, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω Selenium
            for item in all_items:
                item['engine_used'] = 'selenium'

            self.logger.info(f"üéØ –ò–¢–û–ì–û Selenium –¥–ª—è '{query}': {len(all_items)} —Ç–æ–≤–∞—Ä–æ–≤ —Å {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
            return all_items[:max_items]

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ _search_with_selenium: {e}", exc_info=True)
            return []

    async def parse_search_results(self, query):
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        try:
            self._captcha_notification_sent = False
            time.sleep(0.5)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—á–µ–≤–∏–¥–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            if self._check_real_captcha_block():
                await self._handle_captcha_situation()
                return []

            items = await self._find_all_items()

            if not items:
                self.logger.warning("‚ùå –ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                return []

            self.logger.info(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(items)} —Ç–æ–≤–∞—Ä–æ–≤")

            search_keywords = self._parse_search_query(query)
            products = []
            exact_matches = []
            partial_matches = []

            for item in items[:100]:
                try:
                    product = await self.parse_item_advanced(item, query)
                    if product:
                        relevance = self._check_relevance(product, search_keywords, query)
                        if relevance == "exact":
                            exact_matches.append(product)
                        elif relevance == "partial":
                            partial_matches.append(product)
                except:
                    continue

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            final_products = []
            if exact_matches:
                final_products.extend(exact_matches)
            if partial_matches:
                final_products.extend(partial_matches)

            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 20 –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if len(final_products) > 20:
                final_products = final_products[:20]

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ö–æ—Ä–æ—à–∏–µ —Å–¥–µ–ª–∫–∏
            good_deals = []
            for product in final_products:
                if await self.validator.is_good_deal(product):
                    good_deals.append(product)

            self.logger.info(f"üéØ –•–æ—Ä–æ—à–∏—Ö —Å–¥–µ–ª–æ–∫: {len(good_deals)}")
            return good_deals

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []

    def _check_real_captcha_block(self):
        """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É"""
        try:
            page_title = self.driver.title.lower()

            # –¢–æ–ª—å–∫–æ —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            blocking_indicators = [
                "–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
                "–ø—Ä–æ–±–ª–µ–º—ã —Å ip",
                "–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω",
                "–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã",
                "–≤—ã —Ä–æ–±–æ—Ç",
                "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç"
            ]

            for indicator in blocking_indicators:
                if indicator in page_title:
                    self.logger.warning(f"üö® –†–ï–ê–õ–¨–ù–ê–Ø –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞: '{indicator}'")
                    return True

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ URL
            page_url = self.driver.current_url.lower()
            if "blocked" in page_url or "robot" in page_url:
                self.logger.warning(f"üö® URL –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {page_url}")
                return True

            return False

        except Exception as e:
            self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {e}")
            return False

    async def _handle_captcha_situation(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–ø—á–∏ - –æ—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–¥–∏–Ω —Ä–∞–∑"""
        try:
            if hasattr(self, '_captcha_notification_sent') and self._captcha_notification_sent:
                self.logger.info("‚ö†Ô∏è –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
                return True

            self.logger.error("üö® –û–ë–ù–ê–†–£–ñ–ï–ù–ê –ö–ê–ü–ß–ê!")
            await self._send_captcha_notification()
            self._captcha_notification_sent = True
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–ø—á–∏: {e}")
            return False

    async def _send_captcha_notification(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram"""
        try:
            from telegram import Bot
            from shared.utils.config import get_bot_token, get_chat_id

            token = get_bot_token()
            chat_id = get_chat_id()

            if not token or not chat_id:
                self.logger.error("‚ùå –ù–µ—Ç —Ç–æ–∫–µ–Ω–∞ –∏–ª–∏ chat_id")
                return False

            bot = Bot(token=token)
            message = (
                "üö® <b>–ü–ê–†–°–ï–† –û–°–¢–ê–ù–û–í–õ–ï–ù!</b>\n\n"
                "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞ –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø–æ IP!\n\n"
                "‚ö° <b>–ß—Ç–æ –¥–µ–ª–∞—Ç—å:</b>\n"
                "1. –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä —Å Avito\n"
                "2. –†–µ—à–∏—Ç–µ –∫–∞–ø—á—É –≤—Ä—É—á–Ω—É—é\n"
                "3. –î–æ–∂–¥–∏—Ç–µ—Å—å —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏\n"
                "4. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞—Ä—Å–µ—Ä"
            )

            await bot.send_message(chat_id=chat_id, text=message, parse_mode='HTML')
            self.logger.info("‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
            return False

    async def _find_all_items(self):
        """–ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏"""
        items = []
        selectors = [
            '[data-marker="item"]',
            '.iva-item-root-_lk9K'
        ]

        for selector in selectors:
            try:
                found_items = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if found_items:
                    items = found_items
                    self.logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å '{selector}': {len(items)}")
                    break
            except:
                continue
        return items

    def _parse_search_query(self, query):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
        cleaned_query = re.sub(r'[^\w\s]', ' ', query.lower())
        words = cleaned_query.split()
        stop_words = {'–¥–ª—è', '–æ—Ç', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–∏–∑', '—É', '–æ', '–æ–±', '–±—É', '–±/—É'}

        keywords = [word.strip() for word in words
                    if (word.strip() and word.strip() not in stop_words and len(word.strip()) > 1)]

        if not keywords:
            keywords = [word for word in words if len(word) > 1]

        return keywords

    def _check_relevance(self, product, search_keywords, original_query):
        """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
        title = product['name'].lower()
        original_query_lower = original_query.lower()

        if original_query_lower in title:
            return "exact"

        if search_keywords:
            matched_keywords = sum(1 for keyword in search_keywords if keyword in title)
            match_percentage = matched_keywords / len(search_keywords)
            if match_percentage >= 0.5:
                return "exact"
            elif match_percentage >= 0.3:
                return "partial"

        return "other"

    async def parse_item_advanced(self, item, category):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —Ä–µ–∫–ª–∞–º—ã"""
        try:
            # üî• –ü–†–û–í–ï–†–Ø–ï–ú –ù–ê –†–ï–ö–õ–ê–ú–£ –ò –ë–ê–ù–ù–ï–†–´ –ü–ï–†–ï–î –ü–ê–†–°–ò–ù–ì–û–ú
            item_html = item.get_attribute('outerHTML')
            if item_html:
                # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º HTML –Ω–∞ —Ä–µ–∫–ª–∞–º–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
                html_lower = item_html.lower()
                if any(marker in html_lower for marker in [
                    'data-marker="recommendation"',
                    'class="ads-',
                    'class="banner-',
                    'class="promo-',
                    'data-marker="delivery"',
                    'data-marker="advertisement"',
                    '—Ä–µ–∫–ª–∞–º–∞',
                    '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏'
                ]):
                    self.logger.debug("üö´ –ü—Ä–æ–ø—É—â–µ–Ω —Ä–µ–∫–ª–∞–º–Ω—ã–π –±–∞–Ω–Ω–µ—Ä")
                    return None

            # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º CSS –∫–ª–∞—Å—Å—ã
            item_class = item.get_attribute('class') or ''
            if any(ad_class in item_class for ad_class in [
                'recommendation', 'ads-', 'ad-', 'banner-', 'promo-', 'delivery-'
            ]):
                self.logger.debug("üö´ –ü—Ä–æ–ø—É—â–µ–Ω –ø–æ –∫–ª–∞—Å—Å—É —Ä–µ–∫–ª–∞–º—ã")
                return None

            # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º data-–º–∞—Ä–∫–µ—Ä—ã
            data_marker = item.get_attribute('data-marker') or ''
            if any(marker in data_marker for marker in [
                'recommendation', 'ads', 'ad', 'delivery', 'shop', 'company'
            ]):
                self.logger.debug("üö´ –ü—Ä–æ–ø—É—â–µ–Ω –ø–æ data-marker")
                return None

            # üî• –¢–ï–ü–ï–†–¨ –ü–ê–†–°–ò–ú –û–°–ù–û–í–ù–´–ï –î–ê–ù–ù–´–ï
            title = self._extract_title(item)
            if not title:
                return None

            # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ —Ä–µ–∫–ª–∞–º–Ω—ã–µ —Å–ª–æ–≤–∞
            title_lower = title.lower()
            if any(word in title_lower for word in [
                '—Ä–µ–∫–ª–∞–º–∞', '–±–∞–Ω–Ω–µ—Ä', '–¥–æ—Å—Ç–∞–≤–∫–∞', '–º–∞–≥–∞–∑–∏–Ω', '–∞–∫—Ü–∏—è', '—Å–∫–∏–¥–∫–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞'
            ]):
                self.logger.debug(f"üö´ –†–µ–∫–ª–∞–º–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: {title[:50]}...")
                return None

            price = self._extract_price(item)
            if price <= 0:
                return None

            link, item_id = self._extract_link_and_id(item)
            if not link:
                return None

            # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º URL –Ω–∞ —Ä–µ–∫–ª–∞–º—É
            if link and any(ad_marker in link for ad_marker in [
                '/ads/', '/promo/', '/banner/', '/recommendations/'
            ]):
                self.logger.debug(f"üö´ –†–µ–∫–ª–∞–º–Ω—ã–π URL: {link[:80]}...")
                return None

            # üî• –û–°–¢–ê–õ–¨–ù–û–ô –ü–ê–†–°–ò–ù–ì
            target_price = self._calculate_target_price(price)
            time_listed = self._parse_time_listed(item)

            freshness_score = await self.analyze_listing_freshness(item, {
                'name': title,
                'price': price,
                'time_listed': time_listed
            })

            return {
                'name': title[:200],
                'price': price,
                'target_price': target_price,
                'url': link,
                'item_id': item_id,
                'product_id': item_id,
                'category': category,
                'description': f"–ù–∞–π–¥–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{category}'",
                'time_listed': time_listed,
                'freshness_score': freshness_score,
                'is_fresh_by_indicators': self._detect_fresh_listing_indicators(item),
                'site': 'avito',
                'city': self.city
            }

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞: {e}")
            return None

    def _extract_title(self, item):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        title_selectors = [
            '[data-marker="item-title"]',
            '.iva-item-titleStep-_CxvN',
            'h3[itemprop="name"]'
        ]

        for selector in title_selectors:
            try:
                title_elem = item.find_element(By.CSS_SELECTOR, selector)
                title = title_elem.text.strip()
                if title and len(title) > 3:
                    return title
            except:
                continue
        return None

    def _extract_price(self, item):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã"""
        price_selectors = [
            '[data-marker="item-price"]',
            '.price-price-_P9LN',
            '[itemprop="price"]'
        ]

        for selector in price_selectors:
            try:
                price_elem = item.find_element(By.CSS_SELECTOR, selector)
                price_text = price_elem.text.replace('‚ÇΩ', '').replace(' ', '').strip()
                price = self.parse_price(price_text)
                if price > 0:
                    return price
            except:
                continue
        return 0

    def _extract_link_and_id(self, item):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –∏ ID"""
        link_selectors = [
            '[data-marker="item-title"]',
            '.iva-item-titleStep-_CxvN a'
        ]

        for selector in link_selectors:
            try:
                link_elem = item.find_element(By.CSS_SELECTOR, selector)
                link = link_elem.get_attribute('href')
                if link and 'avito.ru' in link:
                    item_id = self._extract_item_id_from_url(link)
                    if item_id:
                        return link, item_id
            except:
                continue

        return None, None

    def _extract_item_id_from_url(self, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –∏–∑ URL"""
        try:
            patterns = [
                r'avito\.ru/.+/(\d{9,10})(?:\?|$)',
                r'avito\.ru/.+/.+_(\d{9,10})(?:\?|$)',
                r'avito\.ru/items/(\d{9,10})(?:\?|$)',
            ]

            for pattern in patterns:
                match = re.search(pattern, url)
                if match:
                    item_id = match.group(1)
                    if item_id.isdigit() and 9 <= len(item_id) <= 10:
                        return int(item_id)

            return None

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è ID: {e}")
            return None

    def _calculate_target_price(self, price):
        """–†–∞—Å—á–µ—Ç —Ü–µ–ª–µ–≤–æ–π —Ü–µ–Ω—ã"""
        return price

    def _detect_fresh_listing_indicators(self, item_element):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            for indicator in self.freshness_indicators:
                try:
                    elements = item_element.find_elements(By.CSS_SELECTOR, indicator)
                    if elements:
                        return True
                except:
                    continue

            item_text = item_element.text.lower()
            freshness_keywords = ['—Ç–æ–ª—å–∫–æ —á—Ç–æ', '—Å–µ–≥–æ–¥–Ω—è', '—Å–≤–µ–∂–∏–π', '–Ω–æ–≤—ã–π']

            for keyword in freshness_keywords:
                if keyword in item_text:
                    return True

            return False

        except:
            return False

    def _parse_time_listed(self, item_element):
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            time_selectors = [
                '[data-marker="item-date"]',
                '.iva-item-dateStep-__qB8a',
                '.styles_remainingTime__P_aaq'
            ]

            for selector in time_selectors:
                try:
                    time_elements = item_element.find_elements(By.CSS_SELECTOR, selector)
                    if time_elements:
                        time_text = time_elements[0].text.lower().strip()
                        return self._parse_time_text(time_text)
                except:
                    continue

            return 24.0

        except:
            return 24.0

    def _parse_time_text(self, time_text):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏"""
        try:
            if '—Ç–æ–ª—å–∫–æ —á—Ç–æ' in time_text:
                return 0.1
            elif '–º–∏–Ω—É—Ç' in time_text:
                minutes_match = re.search(r'(\d+)\s*–º–∏–Ω—É—Ç', time_text)
                if minutes_match:
                    minutes = int(minutes_match.group(1))
                    return max(minutes / 60.0, 0.1)
                return 0.5
            elif '—á–∞—Å' in time_text:
                hours_match = re.search(r'(\d+)\s*—á–∞—Å', time_text)
                if hours_match:
                    return float(hours_match.group(1))
                return 1.0
            elif '—Å–µ–≥–æ–¥–Ω—è' in time_text:
                return 6.0
            elif '–≤—á–µ—Ä–∞' in time_text:
                return 24.0
            elif '–¥–µ–Ω—å' in time_text or '–¥–Ω' in time_text:
                days_match = re.search(r'(\d+)\s*(–¥–µ–Ω—å|–¥–Ω|–¥–Ω—è)', time_text)
                if days_match:
                    days = int(days_match.group(1))
                    return days * 24.0
                return 24.0
            else:
                numbers_match = re.search(r'(\d+)', time_text)
                if numbers_match:
                    number = int(numbers_match.group(1))
                    if number < 24:
                        return float(number)
                    elif number < 100:
                        return number * 24.0

                return 48.0

        except:
            return 24.0

    async def analyze_listing_freshness(self, item_element, product_data):
        """–ê–Ω–∞–ª–∏–∑ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            is_fresh_by_indicators = self._detect_fresh_listing_indicators(item_element)
            time_listed = product_data.get('time_listed', 24)

            freshness_score = self._calculate_freshness_score(time_listed, is_fresh_by_indicators)
            return freshness_score

        except:
            return 0.3

    def _calculate_freshness_score(self, time_listed, has_indicators):
        """–†–∞—Å—á–µ—Ç score —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            if time_listed <= 0.5:
                base_score = 0.95
            elif time_listed <= 2:
                base_score = 0.85
            elif time_listed <= 6:
                base_score = 0.70
            elif time_listed <= 24:
                base_score = 0.40
            else:
                base_score = 0.10

            if has_indicators:
                base_score += 0.15

            return min(max(base_score, 0.0), 1.0)

        except:
            return 0.5

    async def get_product_details(self, product):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π —Ç–æ–≤–∞—Ä–∞"""
        try:
            if not product.get('url'):
                return product

            if not product.get('item_id'):
                item_id = self._extract_item_id_from_url(product['url'])
                if item_id:
                    product['item_id'] = item_id
                    product['product_id'] = item_id

            self.logger.info(f"üîç –î–µ—Ç–∞–ª–∏ —Ç–æ–≤–∞—Ä–∞ ID {product.get('product_id')}")
            self.driver.get(product['url'])
            time.sleep(1.5)

            # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            condition = self._extract_condition()
            color = self._extract_color_from_details()
            location_data = self._extract_location_details_improved()
            seller_info = await self._extract_seller_info_with_avatar()

            # üî• üî• üî• –í–ê–ñ–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –ö–ê–¢–ï–ì–û–†–ò–ò –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
            avito_category = self._extract_category()

            # üî• üî• üî• –í–û–°–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï ImageProcessor!
            try:
                self.logger.info("üì∏ –ò—Å–ø–æ–ª—å–∑—É–µ–º ImageProcessor –¥–ª—è —Å–±–æ—Ä–∞ –í–°–ï–• —Ñ–æ—Ç–æ...")
                image_urls = self.image_processor.get_avito_images()

                if not image_urls or len(image_urls) == 0:
                    self.logger.warning("‚ö†Ô∏è –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –Ω–µ —Å–æ–±—Ä–∞–ª —Ñ–æ—Ç–æ, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π")
                    image_urls = self.image_processor.get_avito_images_fast()

                if not image_urls:
                    self.logger.error("‚ùå ImageProcessor –Ω–µ —Å–æ–±—Ä–∞–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–æ—Ç–æ!")
                    image_urls = []

            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ ImageProcessor: {e}")
                image_urls = []

            main_image_url = image_urls[0] if image_urls else None

            # üî• üî• üî• –í–ê–ñ–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è!
            description = self._extract_description_full()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            try:
                seller_name = seller_info.get('seller_name') or self._extract_seller_name()
                seller_rating, reviews_count = self._extract_seller_rating()
                city = self._extract_city()
                posted_date = self.extract_posted_date()
                views_data = self._extract_views_count()

                # üî• –û–ë–ù–û–í–õ–Ø–ï–ú –ü–†–û–î–£–ö–¢ –° –ü–û–õ–ù–´–ú –û–ü–ò–°–ê–ù–ò–ï–ú –ò –ö–ê–¢–ï–ì–û–†–ò–ï–ô
                product.update({
                    'description': description,
                    'seller_name': seller_name or '–ù–µ —É–∫–∞–∑–∞–Ω',
                    'seller_rating': seller_rating,
                    'reviews_count': reviews_count or 0,
                    'avito_category': avito_category or product.get('category', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                    'city': city or self.city,
                    'image_url': main_image_url,
                    'image_urls': image_urls,
                    'posted_date': posted_date or '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞',
                    'views_count': views_data.get('total_views', 0),
                    'views_today': views_data.get('today_views', 0),
                    'parsed_at': time.time(),
                    'metro_stations': location_data['metro_stations'],
                    'address': location_data['address'],
                    'full_location': location_data['full_location'],
                    'color': color,
                    'condition': condition,
                    'seller_avatar': seller_info.get('seller_avatar'),
                    'seller_type': seller_info.get('seller_type', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                    'seller_profile_url': seller_info.get('seller_profile_url'),
                })

                self.logger.info(
                    f"‚úÖ –î–µ—Ç–∞–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã: {product.get('name', '')[:50]}... | –§–æ—Ç–æ: {len(image_urls)} —à—Ç | –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {avito_category} | –û–ø–∏—Å–∞–Ω–∏–µ: {len(description)} —Å–∏–º–≤.")

            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª–µ–π: {e}")

            return product

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
            return product

    def _extract_image_urls_from_element(self, element):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞"""
        urls = []
        try:
            src = element.get_attribute('src')
            if src:
                urls.append(src)

            for attr in ['data-src', 'data-url', 'data-original', 'data-large', 'data-image', 'data-img']:
                data_url = element.get_attribute(attr)
                if data_url:
                    urls.append(data_url)

            href = element.get_attribute('href')
            if href and self._is_avito_image_url(href):
                urls.append(href)

            style = element.get_attribute('style')
            if style and 'background-image' in style:
                match = re.search(r'url\(["\']?(.*?)["\']?\)', style)
                if match:
                    urls.append(match.group(1))

            html = element.get_attribute('outerHTML')
            if html:
                html_urls = re.findall(r'https?://[^"\'\s<>]*avito\.st[^"\'\s<>]*', html)
                urls.extend(html_urls)

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è URL –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")

        return [url for url in urls if url and self._is_avito_image_url(url)]

    def _is_avito_image_url(self, url):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º Avito"""
        if not url:
            return False

        url_lower = url.lower()

        avito_domains = [
            'avito.st',
            'img.avito.st',
            'avatars.mds.yandex.net',
            'stub_avatars',
            'i.mycdn.me',
            'avatars.yandex.net'
        ]

        image_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.gif']

        is_avito_domain = any(domain in url_lower for domain in avito_domains)
        is_image_extension = any(url_lower.endswith(ext) for ext in image_extensions)
        has_avito_pattern = any(pattern in url_lower for pattern in ['/image/', '/images/', '/get-image/', 'image/1/'])

        return is_avito_domain or (is_image_extension and has_avito_pattern)

    def _normalize_image_url(self, url):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not url:
            return None

        url = url.strip()

        if url.startswith('//'):
            url = 'https:' + url

        if '?' in url:
            url = url.split('?')[0]

        url = url.rstrip('"\'')
        if any(pattern in url for pattern in ['64x64', '80x80', '100x100']):
            url = re.sub(r'\d+x\d+', '1280x960', url)

        return url

    def _check_captcha_page(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ø—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞"""
        try:
            page_title = self.driver.title.lower()
            page_url = self.driver.current_url.lower()

            critical_indicators = [
                "–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
                "–ø—Ä–æ–±–ª–µ–º—ã —Å ip",
                "–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω",
                "–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã",
                "–≤—ã —Ä–æ–±–æ—Ç",
                "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç"
            ]

            for indicator in critical_indicators:
                if indicator in page_title:
                    self.logger.warning(f"üö® –ö–∞–ø—á–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ: '{indicator}'")
                    return True

            if "blocked" in page_url or "captcha" in page_url:
                self.logger.warning(f"üö® URL –∫–∞–ø—á–∏: {page_url}")
                return True

            return False

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–ø—á–∏: {e}")
            return False

    def _extract_condition(self):
        """–ü–∞—Ä—Å–∏—Ç —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä '–°–æ—Å—Ç–æ—è–Ω–∏–µ' –∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        try:
            self.logger.info("üîç –ü–æ–∏—Å–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ '–°–æ—Å—Ç–æ—è–Ω–∏–µ' –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö...")

            params_selectors = [
                '[data-marker="item-view/item-params"]',
                '.params__paramsList__item___XzY3MG',
                '[class*="params__paramsList"]',
            ]

            for selector in params_selectors:
                try:
                    params_blocks = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    self.logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä '{selector}': –Ω–∞–π–¥–µ–Ω–æ {len(params_blocks)} –±–ª–æ–∫–æ–≤")

                    for block in params_blocks:
                        try:
                            condition = self._find_condition_in_block(block)
                            if condition:
                                condition_lower = condition.lower()
                                if any(word in condition_lower for word in ['–Ω–æ–≤', 'new', '–±–∏—Ä–∫']):
                                    condition = "–ù–æ–≤–æ–µ —Å –±–∏—Ä–∫–æ–π"
                                elif any(word in condition_lower for word in ['–±/—É', '–±—É', 'used']):
                                    condition = "–ë/—É"
                                elif any(word in condition_lower for word in ['–∫–∞–∫ –Ω–æ–≤', 'like new']):
                                    condition = "–ö–∞–∫ –Ω–æ–≤—ã–π"

                                self.logger.info(f"‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: '{condition}'")
                                return condition

                        except Exception as e:
                            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–ª–æ–∫–∞: {e}")
                            continue

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            self.logger.info("üîß –°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö")
            return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
            return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

    def _find_condition_in_block(self, block):
        """–ò—â–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä '–°–æ—Å—Ç–æ—è–Ω–∏–µ' –≤ –±–ª–æ–∫–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        try:
            item_elements = block.find_elements(By.CSS_SELECTOR, '.params__paramsList__item___XzY3MG')
            self.logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {len(item_elements)}")

            for item in item_elements:
                try:
                    item_text = item.text.strip()
                    self.logger.info(f"üîç –¢–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: '{item_text}'")

                    if '–°–æ—Å—Ç–æ—è–Ω–∏–µ' in item_text:
                        separators = [':', ' ']

                        for separator in separators:
                            if f'–°–æ—Å—Ç–æ—è–Ω–∏–µ{separator}' in item_text:
                                parts = item_text.split(f'–°–æ—Å—Ç–æ—è–Ω–∏–µ{separator}')
                                if len(parts) > 1:
                                    value = parts[1].strip()
                                    if value:
                                        self.logger.info(f"‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ '{separator}': '{value}'")
                                        return value

                        if '–°–æ—Å—Ç–æ—è–Ω–∏–µ' in item_text and not any(sep in item_text for sep in [':', ' ']):
                            value = item_text.replace('–°–æ—Å—Ç–æ—è–Ω–∏–µ', '').strip()
                            if value:
                                self.logger.info(f"‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ (–±–µ–∑ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è): '{value}'")
                                return value

                except Exception as e:
                    self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
                    continue

            try:
                state_spans = block.find_elements(By.XPATH, ".//span[contains(text(), '–°–æ—Å—Ç–æ—è–Ω–∏–µ')]")
                self.logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ span —Å '–°–æ—Å—Ç–æ—è–Ω–∏–µ': {len(state_spans)}")

                for span in state_spans:
                    try:
                        parent = span.find_element(By.XPATH, "./..")
                        full_text = parent.text.strip()
                        self.logger.info(f"üîç –¢–µ–∫—Å—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞: '{full_text}'")

                        if '–°–æ—Å—Ç–æ—è–Ω–∏–µ' in full_text:
                            if ':' in full_text:
                                value = full_text.split(':')[-1].strip()
                            else:
                                value = full_text.replace('–°–æ—Å—Ç–æ—è–Ω–∏–µ', '').strip()

                            if value and value != '–°–æ—Å—Ç–æ—è–Ω–∏–µ':
                                self.logger.info(f"‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ span: '{value}'")
                                return value
                    except Exception as e:
                        self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ span: {e}")
                        continue
            except Exception as e:
                self.logger.debug(f"‚ùå –ü–æ–∏—Å–∫ –ø–æ span –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")

            return None

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ –±–ª–æ–∫–µ: {e}")
            return None

    def _extract_color_from_details(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ü–≤–µ—Ç–∞"""
        try:
            params_selectors = [
                '[data-marker="item-view/item-params"]',
                '.params__paramsList___XzY3MG'
            ]

            for selector in params_selectors:
                try:
                    params_blocks = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for block in params_blocks:
                        color = self._find_color_in_params_block(block)
                        if color and color != "–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π":
                            return color
                except:
                    continue

            return "–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π"

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ —Ü–≤–µ—Ç–∞: {e}")
            return "–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π"

    def _find_color_in_params_block(self, block):
        """–ü–æ–∏—Å–∫ —Ü–≤–µ—Ç–∞ –≤ –±–ª–æ–∫–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        try:
            item_elements = block.find_elements(By.CSS_SELECTOR, '.params__paramsList__item___XzY3MG')

            for item in item_elements:
                item_text = item.text.strip()
                if '–¶–≤–µ—Ç' in item_text:
                    separators = [':', ' ']
                    for separator in separators:
                        if f'–¶–≤–µ—Ç{separator}' in item_text:
                            parts = item_text.split(f'–¶–≤–µ—Ç{separator}')
                            if len(parts) > 1:
                                value = parts[1].strip()
                                if value:
                                    return self._normalize_color_name(value)

                    if '–¶–≤–µ—Ç' in item_text and not any(sep in item_text for sep in [':', ' ']):
                        value = item_text.replace('–¶–≤–µ—Ç', '').strip()
                        if value:
                            return self._normalize_color_name(value)

            return None

        except:
            return None

    def _normalize_color_name(self, color_text):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è —Ü–≤–µ—Ç–∞"""
        if not color_text:
            return "–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π"

        color_text = color_text.strip().lower()

        color_mapping = {
            '—á–µ—Ä–Ω—ã–π': '–ß–µ—Ä–Ω—ã–π', '—á—ë—Ä–Ω—ã–π': '–ß–µ—Ä–Ω—ã–π',
            '–±–µ–ª—ã–π': '–ë–µ–ª—ã–π', '–∫—Ä–∞—Å–Ω—ã–π': '–ö—Ä–∞—Å–Ω—ã–π',
            '—Å–∏–Ω–∏–π': '–°–∏–Ω–∏–π', '–∑–µ–ª–µ–Ω—ã–π': '–ó–µ–ª–µ–Ω—ã–π',
            '–∑–µ–ª—ë–Ω—ã–π': '–ó–µ–ª–µ–Ω—ã–π', '–∂–µ–ª—Ç—ã–π': '–ñ–µ–ª—Ç—ã–π',
            '–∂—ë–ª—Ç—ã–π': '–ñ–µ–ª—Ç—ã–π', '–æ—Ä–∞–Ω–∂–µ–≤—ã–π': '–û—Ä–∞–Ω–∂–µ–≤—ã–π',
            '—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π': '–§–∏–æ–ª–µ—Ç–æ–≤—ã–π', '—Ä–æ–∑–æ–≤—ã–π': '–†–æ–∑–æ–≤—ã–π',
            '–∫–æ—Ä–∏—á–Ω–µ–≤—ã–π': '–ö–æ—Ä–∏—á–Ω–µ–≤—ã–π', '—Å–µ—Ä—ã–π': '–°–µ—Ä—ã–π',
            '–≥–æ–ª—É–±–æ–π': '–ì–æ–ª—É–±–æ–π', '–±–∏—Ä—é–∑–æ–≤—ã–π': '–ë–∏—Ä—é–∑–æ–≤—ã–π',
            '–±–µ–∂–µ–≤—ã–π': '–ë–µ–∂–µ–≤—ã–π', '–±–æ—Ä–¥–æ–≤—ã–π': '–ë–æ—Ä–¥–æ–≤—ã–π',
            '–∑–æ–ª–æ—Ç–æ–π': '–ó–æ–ª–æ—Ç–æ–π', '—Å–µ—Ä–µ–±—Ä—è–Ω—ã–π': '–°–µ—Ä–µ–±—Ä—è–Ω—ã–π',
            '—Å–µ—Ä–µ–±—Ä–∏—Å—Ç—ã–π': '–°–µ—Ä–µ–±—Ä—è–Ω—ã–π'
        }

        if color_text in color_mapping:
            return color_mapping[color_text]

        for key, value in color_mapping.items():
            if key in color_text:
                return value

        if color_text and len(color_text) < 30:
            return color_text.capitalize()

        return "–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π"

    def _extract_location_details_improved(self):
        """–£–õ–£–ß–®–ï–ù–ù–´–ô –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞"""
        try:
            location_data = {
                'metro_stations': [],
                'address': None,
                'full_location': None
            }

            self._find_location_on_main_page(location_data)

            if not location_data['metro_stations'] or not location_data['address']:
                if self._expand_location_map_improved():
                    time.sleep(1.0)
                    self._find_location_after_map_expansion_improved(location_data)

            if not location_data['metro_stations']:
                self._find_metro_in_expanded_card(location_data)

            self._build_final_location_improved(location_data)

            metro_count = len(location_data['metro_stations'])
            if metro_count > 0:
                station_names = [station['name'] for station in location_data['metro_stations']]
                self.logger.info(f"üìç –ù–∞–π–¥–µ–Ω–æ –º–µ—Ç—Ä–æ: {', '.join(station_names[:3])}" +
                                 (f" –∏ –µ—â—ë {metro_count - 3}" if metro_count > 3 else ""))

            return location_data

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è: {e}")
            return {
                'metro_stations': [],
                'address': None,
                'full_location': '–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'
            }

    def _find_location_on_main_page(self, location_data):
        """–£–ü–†–û–©–ï–ù–ù–´–ô –ø–æ–∏—Å–∫ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        try:
            address_selectors = [
                '[data-marker="item-view/item-address"]',
                '[class*="address"]',
                '.style-address',
                '.item-address',
                '.seller-address',
                '.xLPJ6',
                '//span[contains(text(), "–ú–æ—Å–∫–≤–∞")]',
                '//*[contains(text(), "—É–ª.") or contains(text(), "–ø—Ä–æ—Å–ø–µ–∫—Ç") or contains(text(), "—à–æ—Å—Å–µ")]'
            ]

            for selector in address_selectors:
                try:
                    if selector.startswith('//'):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for elem in elements:
                        text = elem.text.strip()
                        if text and self._is_valid_address_simple(text):
                            location_data['address'] = text
                            break

                    if location_data['address']:
                        break

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä –∞–¥—Ä–µ—Å–∞ '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            metro_selectors = [
                '[data-marker*="metro"]',
                '[class*="metro"]',
                '.style-metro',
                '.metro-station',
                '//*[contains(@class, "metro")]',
                '//*[contains(text(), "–º–µ—Ç—Ä–æ") or contains(text(), "–ú–µ—Ç—Ä–æ")]',
                '//*[contains(@class, "geo-geo")]',
                '.geo-geo',
            ]

            for selector in metro_selectors:
                try:
                    if selector.startswith('//'):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for elem in elements:
                        text = elem.text.strip()
                        if text:
                            self._extract_metro_from_text_simple(text, location_data)

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä –º–µ—Ç—Ä–æ '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {e}")

    def _is_valid_address_simple(self, line):
        """–£–õ–£–ß–®–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –∞–¥—Ä–µ—Å–∞"""
        try:
            if not line or len(line) < 5:
                return False

            line_lower = line.lower()

            critical_address_indicators = [
                '–º–æ—Å–∫–≤–∞, —É–ª.',
                '–º–æ—Å–∫–≤–∞, —É–ª–∏—Ü–∞',
                '–º–æ—Å–∫–≤–∞, –ø—Ä–æ—Å–ø–µ–∫—Ç',
                '–º–æ—Å–∫–≤–∞, —à–æ—Å—Å–µ',
                '–º–æ—Å–∫–≤–∞, –±—É–ª—å–≤–∞—Ä',
                '–º–æ—Å–∫–≤–∞, –ø–µ—Ä–µ—É–ª–æ–∫',
                '–º–æ—Å–∫–≤–∞, –Ω–∞–±–µ—Ä–µ–∂–Ω–∞—è',
                '—É–ª. ',
                '—É–ª–∏—Ü–∞ ',
                '–ø—Ä–æ—Å–ø–µ–∫—Ç ',
                '—à–æ—Å—Å–µ ',
                '–±—É–ª—å–≤–∞—Ä ',
                '–ø–µ—Ä–µ—É–ª–æ–∫ ',
                '–Ω–∞–±–µ—Ä–µ–∂–Ω–∞—è ',
                '–ø–ª. ',
                '–ø–ª–æ—â–∞–¥—å '
            ]

            additional_indicators = [
                '–¥–æ–º', '–¥.', '–∫–æ—Ä–ø—É—Å', '–∫–æ—Ä–ø.', '—Å—Ç—Ä–æ–µ–Ω–∏–µ', '—Å—Ç—Ä.',
                '—Ä–∞–π–æ–Ω', '—Ä-–Ω', '–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω', '–º–∫—Ä.', '–∫–≤–∞—Ä—Ç–∞–ª'
            ]

            exclude_indicators = [
                '—Ü–µ–Ω–∞', '—Ä—É–±', '‚ÇΩ', '–ø—Ä–æ—Å–º–æ—Ç—Ä', '–æ—Ç–∑—ã–≤', '—Ä–µ–π—Ç–∏–Ω–≥',
                '–ø—Ä–æ–¥–∞–≤–µ—Ü', '–æ–±—ä—è–≤–ª–µ–Ω–∏–µ', '–∏–∑–±—Ä–∞–Ω–Ω–æ–µ', '–º–µ—Ç—Ä–æ', '—Å—Ç–∞–Ω—Ü–∏—è'
            ]

            has_critical_indicator = any(indicator in line_lower for indicator in critical_address_indicators)
            has_additional_indicator = any(indicator in line_lower for indicator in additional_indicators)
            has_exclude_indicator = any(indicator in line_lower for indicator in exclude_indicators)
            has_russian_letters = re.search(r'[–∞-—è–ê-–Ø]', line)

            result = (
                    (has_critical_indicator and not has_exclude_indicator) or
                    (line_lower.startswith('–º–æ—Å–∫–≤–∞,') and has_russian_letters and not has_exclude_indicator) or
                    (has_additional_indicator and has_russian_letters and not has_exclude_indicator and len(line) > 10)
            )

            return result

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–¥—Ä–µ—Å–∞: {e}")
            return False

    def _extract_metro_from_text_simple(self, text, location_data):
        """–ü–†–û–°–¢–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–π –º–µ—Ç—Ä–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            text_lower = text.lower()

            for station_name in self.metro_database.keys():
                station_lower = station_name.lower()

                if station_lower in text_lower:
                    metro_data = self._get_metro_data_by_station(station_name)
                    station_data = {
                        'name': station_name,
                        'color': metro_data['color'],
                        'line_number': metro_data['line_number'],
                        'line_name': metro_data['line_name'],
                        'circle_color': metro_data['circle_color']
                    }

                    if not any(s['name'] == station_name for s in location_data['metro_stations']):
                        location_data['metro_stations'].append(station_data)
                        return True

            return False

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç—Ä–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞: {e}")
            return False

    def _expand_location_map_improved(self):
        """–£–õ–£–ß–®–ï–ù–ù–û–ï —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ –∫–∞—Ä—Ç—ã –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è"""
        try:
            self.logger.info("üó∫Ô∏è –£–õ–£–ß–®–ï–ù–ù–û–ï —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ –∫–∞—Ä—Ç—ã –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è...")

            map_button_selectors = [
                '[data-marker="item-map-button"]',
                '[data-text-open="–£–∑–Ω–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏"]',
                'button[data-text-open*="–£–∑–Ω–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏"]',
                '.style-item-address-button-1yOgg',
                '[class*="map-button"]',
                '[class*="address-button"]',
                '.fDM1R',
                'button[class*="fDM1R"]',
                '.desktop-1q9f1w0',
                'button[class*="desktop"]',
                '//button[contains(text(), "–£–∑–Ω–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏")]',
                '//span[contains(text(), "–£–∑–Ω–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏")]',
                '//a[contains(text(), "–£–∑–Ω–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏")]',
                '//*[contains(text(), "–£–∑–Ω–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏")]',
                '//*[contains(@class, "item-map-button")]',
            ]

            for selector in map_button_selectors:
                try:
                    if selector.startswith('//'):
                        map_buttons = self.driver.find_elements(By.XPATH, selector)
                    else:
                        map_buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    self.logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ –∫–Ω–æ–ø–æ–∫ '{selector}': {len(map_buttons)}")

                    for button in map_buttons:
                        try:
                            button_text = button.text.strip()
                            self.logger.info(f"üîç –¢–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏: '{button_text}'")

                            if any(word in button_text.lower() for word in
                                   ['—É–∑–Ω–∞—Ç—å', '–ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏', '–∫–∞—Ä—Ç–∞', 'map', '–∞–¥—Ä–µ—Å', 'location']):
                                self.logger.info(f"üéØ –ù–∞–∂–∞—Ç–∏–µ –Ω–∞ –∫–Ω–æ–ø–∫—É: '{button_text}'")

                                self.driver.execute_script(
                                    "arguments[0].scrollIntoView({block: 'center', behavior: 'smooth'});", button)

                                try:
                                    button.click()
                                    self.logger.info("‚úÖ –ö–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")
                                    return True
                                except:
                                    try:
                                        self.driver.execute_script("arguments[0].click();", button)
                                        self.logger.info("‚úÖ –ö–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ –≤—ã–ø–æ–ª–Ω–µ–Ω —á–µ—Ä–µ–∑ JavaScript")
                                        return True
                                    except:
                                        try:
                                            ActionChains(self.driver).move_to_element(button).click().perform()
                                            self.logger.info("‚úÖ –ö–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ –≤—ã–ø–æ–ª–Ω–µ–Ω —á–µ—Ä–µ–∑ ActionChains")
                                            return True
                                        except Exception as e:
                                            self.logger.debug(f"‚ùå –í—Å–µ —Å–ø–æ—Å–æ–±—ã –∫–ª–∏–∫–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏: {e}")
                                            continue

                        except Exception as e:
                            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∏–∫–∞ –ø–æ –∫–Ω–æ–ø–∫–µ: {e}")
                            continue

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä –∫–Ω–æ–ø–∫–∏ '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            self.logger.warning("‚ö†Ô∏è –ö–Ω–æ–ø–∫–∞ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∫–∞—Ä—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return False

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∫–∞—Ä—Ç—ã: {e}")
            return False

    def _find_location_after_map_expansion_improved(self, location_data):
        """–£–õ–£–ß–®–ï–ù–ù–´–ô –ø–æ–∏—Å–∫ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∫–∞—Ä—Ç—ã"""
        try:
            time.sleep(0.5)

            address_card_selectors = [
                '[data-marker="sellerAddressInfoCard"]',
            ]

            for selector in address_card_selectors:
                try:
                    address_cards = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for card in address_cards:
                        try:
                            card_text = card.text.strip()
                            if card_text:
                                self._parse_location_card_content_improved(card_text, location_data)
                                if location_data['address'] or location_data['metro_stations']:
                                    self.logger.info(
                                        f"üìç –ù–∞–π–¥–µ–Ω –∞–¥—Ä–µ—Å –≤ '{selector}': {location_data['address'] or '–Ω–µ—Ç –∞–¥—Ä–µ—Å–∞'}")
                                    if location_data['metro_stations']:
                                        self.logger.info(f"üöá –°—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ: {len(location_data['metro_stations'])}")
                                    return
                        except Exception as e:
                            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                            continue

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä –∫–∞—Ä—Ç–æ—á–∫–∏ '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            expanded_selectors = [
                '//*[contains(@class, "address")]',
                '//*[contains(text(), "—É–ª.")]',
                '//*[contains(@class, "geo")]',
            ]

            for selector in expanded_selectors:
                try:
                    elements = self.driver.find_elements(By.XPATH, selector)
                    for elem in elements:
                        text = elem.text.strip()
                        if text:
                            if not location_data['address'] and self._is_valid_address_simple(text):
                                location_data['address'] = text
                                self.logger.info(f"üìç –ê–¥—Ä–µ—Å –Ω–∞–π–¥–µ–Ω –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ –≤ '{selector}': '{text}'")
                                return

                            self._extract_metro_from_text_simple(text, location_data)

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä –ø–æ—Å–ª–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            if not location_data['address'] and not location_data['metro_stations']:
                self.logger.debug("üìç –ê–¥—Ä–µ—Å –∏ –º–µ—Ç—Ä–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ—Å–ª–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∫–∞—Ä—Ç—ã")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Å–ª–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∫–∞—Ä—Ç—ã: {e}")

    def _find_metro_in_expanded_card(self, location_data):
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –º–µ—Ç—Ä–æ –≤ —Ä–∞—Å–∫—Ä—ã—Ç–æ–π –∫–∞—Ä—Ç–æ—á–∫–µ"""
        try:
            metro_specific_selectors = [
                '//*[contains(@class, "metro-station")]',
                '//*[contains(@class, "metro-list")]',
                '//*[contains(@class, "station-item")]',
                '//*[contains(@class, "geo-station")]',
                '//span[contains(@class, "metro")]',
                '//div[contains(@class, "metro")]',
            ]

            for selector in metro_specific_selectors:
                try:
                    metro_elements = self.driver.find_elements(By.XPATH, selector)
                    for elem in metro_elements:
                        text = elem.text.strip()
                        if text:
                            self._extract_metro_from_text_simple(text, location_data)
                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä –º–µ—Ç—Ä–æ '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –º–µ—Ç—Ä–æ: {e}")

    def _parse_location_card_content_improved(self, card_text, location_data):
        """–£–õ–£–ß–®–ï–ù–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∫–∞—Ä—Ç–æ—á–∫–∏ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è"""
        try:
            lines = [line.strip() for line in card_text.split('\n') if line.strip()]

            for line in lines:
                if '–º–æ—Å–∫–≤–∞,' in line.lower() and any(
                        addr_indicator in line.lower() for addr_indicator in ['—É–ª.', '—É–ª–∏—Ü–∞', '–ø—Ä–æ—Å–ø–µ–∫—Ç', '—à–æ—Å—Å–µ']):
                    location_data['address'] = line
                    break

            if not location_data['address']:
                for line in lines:
                    if self._is_valid_address_simple(line):
                        location_data['address'] = line
                        break

            for line in lines:
                self._extract_metro_from_text_simple(line, location_data)

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")

    def _get_metro_data_by_station(self, station_name):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ –∏–∑ –±–∞–∑—ã"""
        if station_name in self.metro_database:
            data = self.metro_database[station_name]
            return {
                'color': data['color'],
                'line_number': data['line_number'],
                'line_name': data['line_name'],
                'circle_color': self._get_circle_color_for_line(data['line_number'])
            }

        return {
            'color': '#666666',
            'line_number': '?',
            'line_name': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ª–∏–Ω–∏—è',
            'circle_color': '#ffffff'
        }

    def _get_circle_color_for_line(self, line_number):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ü–≤–µ—Ç –∫—Ä—É–∂–∫–∞ (–±–µ–ª—ã–π –∏–ª–∏ —á–µ—Ä–Ω—ã–π) –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ü–≤–µ—Ç–∞ –ª–∏–Ω–∏–∏"""
        dark_lines = {'1', '2', '3', '5', '7', '8', '9', '10', '11', '12'}
        return '#000000' if line_number in dark_lines else '#ffffff'

    def _build_final_location_improved(self, location_data):
        """–£–õ–£–ß–®–ï–ù–ù–û–ï —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è"""
        try:
            parts = []

            if location_data['metro_stations']:
                metro_names = [station['name'] for station in location_data['metro_stations']]
                metro_str = ' | '.join(metro_names[:3])
                parts.append(metro_str)

            if location_data['address']:
                parts.append(location_data['address'])

            if parts:
                location_data['full_location'] = ' | '.join(parts)
            else:
                location_data['full_location'] = '–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'

            self.logger.info(f"üìç –ò—Ç–æ–≥–æ–≤–æ–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {location_data['full_location']}")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è: {e}")
            location_data['full_location'] = '–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'

    def extract_posted_date(self):
        """–£–õ–£–ß–®–ï–ù–ù–´–ô –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞—Ç—ã —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            primary_selectors = [
                '[data-marker="item-view/item-date"]',
                '*[data-marker="item-view/item-date"]',
            ]

            for selector in primary_selectors:
                try:
                    date_elems = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for date_elem in date_elems:
                        date_info = self._extract_date_from_element(date_elem)
                        if date_info:
                            self.logger.info(f"‚úÖ –î–∞—Ç–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ '{selector}': '{date_info}'")
                            return date_info

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            self.logger.warning("‚ùå –î–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å–µ–ª–µ–∫—Ç–æ—Ä–µ, –∏—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ")
            return '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞—Ç—ã: {e}")
            return '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'

    def _extract_date_from_element(self, element):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞, –≤–∫–ª—é—á–∞—è –í–°–ï –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã"""
        try:
            full_text = element.text.strip()
            if full_text:
                cleaned = self._clean_date_text(full_text)
                if cleaned and cleaned != '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞':
                    return cleaned

            try:
                all_text_nodes = self.driver.execute_script("""
                    var texts = [];
                    var walker = document.createTreeWalker(
                        arguments[0],
                        NodeFilter.SHOW_TEXT,
                        null,
                        false
                    );
                    var node;
                    while (node = walker.nextNode()) {
                        var text = node.textContent.trim();
                        if (text && text.length > 1) {
                            texts.push(text);
                        }
                    }
                    return texts;
                """, element)

                if all_text_nodes:
                    combined_text = ' '.join(all_text_nodes).strip()
                    cleaned = self._clean_date_text(combined_text)
                    if cleaned and cleaned != '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞':
                        return cleaned
            except Exception as e:
                self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —É–∑–ª–æ–≤: {e}")

            inner_html = element.get_attribute('innerHTML')
            if inner_html:
                import re
                text_only = re.sub(r'<[^>]+>', ' ', inner_html)
                text_only = ' '.join(text_only.split()).strip()

                if text_only:
                    cleaned = self._clean_date_text(text_only)
                    if cleaned and cleaned != '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞':
                        return cleaned

            xpath_patterns = [
                ".//text()[contains(., '—Å–µ–≥–æ–¥–Ω—è') or contains(., '–≤—á–µ—Ä–∞') or contains(., '—á–∞—Å') or contains(., '–º–∏–Ω—É—Ç')]",
                ".//*[contains(text(), '—Å–µ–≥–æ–¥–Ω—è') or contains(text(), '–≤—á–µ—Ä–∞')]",
            ]

            for xpath in xpath_patterns:
                try:
                    nodes = element.find_elements(By.XPATH, xpath)
                    for node in nodes:
                        text = node.text if hasattr(node, 'text') else str(node)
                        if text:
                            cleaned = self._clean_date_text(text)
                            if cleaned and cleaned != '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞':
                                return cleaned
                except:
                    continue

            return None

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞—Ç—ã –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
            return None

    def _clean_date_text(self, date_text):
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–∞—Ç—ã –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not date_text:
            return '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'

        try:
            cleaned = date_text.strip()
            cleaned = re.sub(r'^[¬∑‚Ä¢*\-‚Äì‚Äî\s]+', '', cleaned)
            cleaned = re.sub(r'\s+', ' ', cleaned)

            if cleaned.startswith('–≤ '):
                cleaned = '–í ' + cleaned[2:]

            if cleaned and len(cleaned) > 1:
                if cleaned[0].islower():
                    cleaned = cleaned[0].upper() + cleaned[1:]

            if len(cleaned) < 3:
                return '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'

            return cleaned

        except Exception as e:
            self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞—Ç—ã: {e}")
            return date_text.strip() if date_text else '–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'

    def _extract_category(self):
        """üî• üî• üî• –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ô –ú–ï–¢–û–î –ò–ó –°–¢–ê–†–û–ì–û –ü–ê–†–°–ï–†–ê: –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏"""
        try:
            self.logger.info("üìä –ü–æ–∏—Å–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–∞ –≤ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω–æ–π —Ü–µ–ø–æ—á–∫–µ...")

            navigation_selectors = [
                '[data-marker="breadcrumbs"]',
                '[data-marker="item-navigation"]',
                '.breadcrumbs',
                '.js-breadcrumbs',
                '.breadcrumb'
            ]

            navigation_element = None
            for selector in navigation_selectors:
                try:
                    navigation_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –±–ª–æ–∫ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                    break
                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            if not navigation_element:
                self.logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –±–ª–æ–∫ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
                return None

            try:
                links = navigation_element.find_elements(By.TAG_NAME, 'a')
                breadcrumbs = []
                for link in links:
                    try:
                        text = link.text.strip()
                        if text and text not in ['–ì–ª–∞–≤–Ω–∞—è', 'Avito', '–í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏', '']:
                            breadcrumbs.append(text)
                            self.logger.debug(f"üîó –•–ª–µ–±–Ω–∞—è –∫—Ä–æ—à–∫–∞: {text}")
                    except Exception as e:
                        self.logger.debug(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Å—ã–ª–∫–∏: {e}")
                        continue

                self.logger.info(f"üìä –ù–∞–π–¥–µ–Ω—ã —Ö–ª–µ–±–Ω—ã–µ –∫—Ä–æ—à–∫–∏: {breadcrumbs}")

                if len(breadcrumbs) >= 3:
                    category = breadcrumbs[-2]
                    self.logger.info(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–∞–π–¥–µ–Ω–∞ (–ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç): '{category}'")
                    return category
                elif len(breadcrumbs) == 2:
                    category = breadcrumbs[0]
                    self.logger.info(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–∞–π–¥–µ–Ω–∞ (–ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç): '{category}'")
                    return category
                elif len(breadcrumbs) == 1:
                    category = breadcrumbs[0]
                    self.logger.info(f"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–∞–π–¥–µ–Ω–∞ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç): '{category}'")
                    return category
                else:
                    self.logger.warning("‚ö†Ô∏è –í —Ö–ª–µ–±–Ω—ã—Ö –∫—Ä–æ—à–∫–∞—Ö –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
                    return None

            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏: {e}")
                return None

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {e}")
            return None

    def _extract_seller_name(self):
        """–ò–º—è –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        seller_selectors = [
            '[data-marker="seller-info/name"]',
            '.seller-info-name'
        ]

        for selector in seller_selectors:
            try:
                seller_elem = self.driver.find_element(By.CSS_SELECTOR, selector)
                seller_name = seller_elem.text.strip()
                if seller_name:
                    return seller_name
            except:
                continue
        return None

    def _extract_seller_rating(self):
        """–†–µ–π—Ç–∏–Ω–≥ –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        try:
            rating = None
            reviews_count = None

            rating_selectors = [
                '.seller-info-rating span',
                '[data-marker="seller-rating/score"]'
            ]

            for selector in rating_selectors:
                try:
                    rating_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in rating_elements:
                        text = elem.text.strip()
                        if text and re.match(r'^\d+[.,]?\d*$', text):
                            rating_text = text.replace(',', '.')
                            rating = float(rating_text)
                            if 1 <= rating <= 5:
                                break
                    if rating:
                        break
                except:
                    continue

            reviews_selectors = [
                '[data-marker="seller-rating/count"]',
                '.seller-info-rating a'
            ]

            for selector in reviews_selectors:
                try:
                    reviews_elem = self.driver.find_element(By.CSS_SELECTOR, selector)
                    reviews_text = reviews_elem.text.strip()
                    reviews_match = re.search(r'(\d+)', reviews_text)
                    if reviews_match:
                        reviews_count = int(reviews_match.group(1))
                        break
                except:
                    continue

            return rating, reviews_count

        except:
            return None, None

    def _extract_city(self):
        """–ü–æ–∏—Å–∫ –≥–æ—Ä–æ–¥–∞"""
        try:
            location_selectors = [
                '[data-marker="item-view/title-address"]',
                '.style__item-address__string___XzQ5MT'
            ]

            for selector in location_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        if text:
                            city = self._parse_city_from_text(text)
                            if city:
                                return city
                except:
                    continue

            return self.city

        except:
            return self.city

    def _parse_city_from_text(self, text):
        """–ü–∞—Ä—Å–∏–Ω–≥ –≥–æ—Ä–æ–¥–∞"""
        try:
            if not text:
                return None

            major_cities = {
                '–º–æ—Å–∫–≤–∞': '–ú–æ—Å–∫–≤–∞', '–º—Å–∫': '–ú–æ—Å–∫–≤–∞',
                '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '—Å–ø–±': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥',
                '–≤–æ—Ä–æ–Ω–µ–∂': '–í–æ—Ä–æ–Ω–µ–∂', '–∫–∞–∑–∞–Ω—å': '–ö–∞–∑–∞–Ω—å',
                '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥': '–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫': '–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫',
                '–Ω–∏–∂–Ω–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥': '–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥', '—Å–∞–º–∞—Ä–∞': '–°–∞–º–∞—Ä–∞',
                '–æ–º—Å–∫': '–û–º—Å–∫', '—á–µ–ª—è–±–∏–Ω—Å–∫': '–ß–µ–ª—è–±–∏–Ω—Å–∫',
                '—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É': '–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É', '—É—Ñ–∞': '–£—Ñ–∞',
                '–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫': '–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫', '–ø–µ—Ä–º—å': '–ü–µ—Ä–º—å',
                '–≤–æ–ª–≥–æ–≥—Ä–∞–¥': '–í–æ–ª–≥–æ–≥—Ä–∞–¥', '—Å–æ—á–∏': '–°–æ—á–∏',
                '–ø–µ–Ω–∑–∞': '–ü–µ–Ω–∑–∞'
            }

            text_lower = text.lower()

            for city_pattern, city_name in major_cities.items():
                if city_pattern in text_lower:
                    return city_name

            return None

        except:
            return None

    def _extract_views_count(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä—ã"""
        try:
            views_data = {'total_views': 0, 'today_views': 0}

            total_views_selectors = [
                '[data-marker="item-view/total-views"]',
                '.style-item-views-F2T5T'
            ]

            for selector in total_views_selectors:
                try:
                    views_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in views_elements:
                        views_text = elem.text.strip()
                        if views_text and '–ø—Ä–æ—Å–º–æ—Ç—Ä' in views_text.lower():
                            numbers = re.findall(r'\d+', views_text)
                            if numbers:
                                views_data['total_views'] = int(numbers[0])
                                break
                    if views_data['total_views'] > 0:
                        break
                except:
                    continue

            return views_data

        except:
            return {'total_views': 0, 'today_views': 0}

    def parse_price(self, price_text):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω—ã"""
        try:
            digits = ''.join(filter(str.isdigit, price_text))
            return int(digits) if digits else 0
        except:
            return 0

    async def parse_product_item(self, item_element, query=None):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–∞"""
        try:
            product_data = await self.parse_item_advanced(item_element, query)
            if not product_data:
                return None

            freshness_score = await self.analyze_listing_freshness(item_element, product_data)
            product_data['freshness_score'] = freshness_score
            product_data['is_fresh_by_indicators'] = self._detect_fresh_listing_indicators(item_element)

            return product_data

        except:
            return None

    async def parse_item(self, item, category):
        """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –º–µ—Ç–æ–¥"""
        return await self.parse_product_item(item, category)

    async def _extract_seller_info_with_avatar(self):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥–∞–≤—Ü–µ —Å –∞–≤–∞—Ç–∞—Ä–∫–æ–π - –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –í–ê–†–ò–ê–ù–¢"""
        try:
            self.logger.info("üîç –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥–∞–≤—Ü–µ...")

            seller_info = {
                'seller_name': '–ù–µ —É–∫–∞–∑–∞–Ω',
                'seller_type': '–ù–µ —É–∫–∞–∑–∞–Ω',
                'seller_avatar': None,
                'seller_profile_url': None
            }

            avatar_selectors = [
                '.style__seller-info-shop-img___XzY4OG',
                '.style__seller-info-avatar-image___XzY4OG',
            ]

            for selector in avatar_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        avatar_url = element.get_attribute('src')
                        if avatar_url and self._is_valid_avatar_url(avatar_url):
                            seller_info['seller_avatar'] = self._normalize_avatar_url(avatar_url)
                            self.logger.info(f"‚úÖ –ê–≤–∞—Ç–∞—Ä–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ src: {seller_info['seller_avatar'][:50]}...")
                            break

                        style_attr = element.get_attribute('style')
                        if style_attr and 'background-image' in style_attr:
                            match = re.search(r'url\(["\']?(.*?)["\']?\)', style_attr)
                            if match:
                                avatar_url = match.group(1)
                                if self._is_valid_avatar_url(avatar_url):
                                    seller_info['seller_avatar'] = self._normalize_avatar_url(avatar_url)
                                    self.logger.info(
                                        f"‚úÖ –ê–≤–∞—Ç–∞—Ä–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ style: {seller_info['seller_avatar'][:50]}...")
                                    break

                        try:
                            bg_image = self.driver.execute_script(
                                "return window.getComputedStyle(arguments[0]).getPropertyValue('background-image');",
                                element
                            )
                            if bg_image and bg_image != 'none':
                                match = re.search(r'url\(["\']?(.*?)["\']?\)', bg_image)
                                if match:
                                    avatar_url = match.group(1)
                                    if self._is_valid_avatar_url(avatar_url):
                                        seller_info['seller_avatar'] = self._normalize_avatar_url(avatar_url)
                                        self.logger.info(
                                            f"‚úÖ –ê–≤–∞—Ç–∞—Ä–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ —á–µ—Ä–µ–∑ computed style: {seller_info['seller_avatar'][:50]}...")
                                        break
                        except:
                            pass

                    if seller_info['seller_avatar']:
                        break

                except:
                    continue

            if not seller_info['seller_avatar']:
                self.logger.info("‚ÑπÔ∏è –ê–≤–∞—Ç–∞—Ä–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

            name_selectors = [
                '[data-marker="seller-info/name"]',
                '.seller-info-name',
                '.style__seller-info-name___XzY4OG',
                '[class*="seller-name"]',
                'h3[class*="seller"]'
            ]

            for selector in name_selectors:
                try:
                    name_elem = self.driver.find_element(By.CSS_SELECTOR, selector)
                    seller_name = name_elem.text.strip()
                    if seller_name and seller_name != '–ß–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ':
                        seller_info['seller_name'] = seller_name
                        self.logger.info(f"‚úÖ –ò–º—è –ø—Ä–æ–¥–∞–≤—Ü–∞ –Ω–∞–π–¥–µ–Ω–æ: '{seller_name}'")
                        break
                except:
                    continue

            try:
                seller_text = self.driver.page_source.lower()
                if '—á–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ' in seller_text:
                    seller_info['seller_type'] = "–ß–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ"
                    self.logger.info("‚úÖ –¢–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞: –ß–∞—Å—Ç–Ω–æ–µ –ª–∏—Ü–æ")
                elif any(word in seller_text for word in
                         ['–∫–æ–º–ø–∞–Ω–∏—è', '—Ñ–∏—Ä–º–∞', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è', '–º–∞–≥–∞–∑–∏–Ω', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω']):
                    seller_info['seller_type'] = "–ö–æ–º–ø–∞–Ω–∏—è"
                    self.logger.info("‚úÖ –¢–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞: –ö–æ–º–ø–∞–Ω–∏—è")
                else:
                    seller_text_raw = self.driver.page_source
                    if '–ø—Ä–æ—Ñ–∏–ª—å –∫–æ–º–ø–∞–Ω–∏–∏' in seller_text_raw or '–º–∞–≥–∞–∑–∏–Ω' in seller_text_raw.lower():
                        seller_info['seller_type'] = "–ö–æ–º–ø–∞–Ω–∏—è"
                        self.logger.info("‚úÖ –¢–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞: –ö–æ–º–ø–∞–Ω–∏—è (–ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º)")
                    else:
                        seller_info['seller_type'] = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
                        self.logger.info("‚ÑπÔ∏è –¢–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞: {e}")
                seller_info['seller_type'] = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

            seller_profile_url = await self._extract_seller_profile_url()
            if seller_profile_url:
                seller_info['seller_profile_url'] = seller_profile_url
                self.logger.info(f"‚úÖ –°—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–¥–∞–≤—Ü–∞ –Ω–∞–π–¥–µ–Ω–∞: {seller_profile_url[:80]}...")
            else:
                self.logger.info("‚ÑπÔ∏è –°—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–¥–∞–≤—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

            if seller_info['seller_name'] != '–ù–µ —É–∫–∞–∑–∞–Ω':
                self.logger.info(f"üìä –ò—Ç–æ–≥ –ø–æ –ø—Ä–æ–¥–∞–≤—Ü—É: {seller_info['seller_name']} ({seller_info['seller_type']})")
            else:
                self.logger.info("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–¥–∞–≤—Ü–µ —Å–æ–±—Ä–∞–Ω–∞")

            return seller_info

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–¥–∞–≤—Ü–µ: {e}")
            return {
                'seller_name': '–ù–µ —É–∫–∞–∑–∞–Ω',
                'seller_type': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω',
                'seller_avatar': None,
                'seller_profile_url': None
            }

    async def _extract_seller_profile_url(self):
        """üî• –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–¥–∞–≤—Ü–∞ (–¥–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞)"""
        try:
            self.logger.info("üîó –ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–¥–∞–≤—Ü–∞...")

            profile_selectors = [
                '[data-marker="seller-link/link"]',
                '.styles.module__root___XzVhMW[href*="/brands/"]',
                'a[href*="/brands/"][title*="–ø—Ä–æ—Ñ–∏–ª—å"]',
                'a[data-marker="seller-link/link"]',
                '//a[contains(@href, "/brands/")]',
                '//a[contains(@title, "–ø—Ä–æ—Ñ–∏–ª—å")]'
            ]

            for selector in profile_selectors:
                try:
                    if selector.startswith('//'):
                        profile_links = self.driver.find_elements(By.XPATH, selector)
                    else:
                        profile_links = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for link in profile_links:
                        profile_url = link.get_attribute('href')
                        if profile_url and '/brands/' in profile_url:
                            self.logger.info(f"‚úÖ –°—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–¥–∞–≤—Ü–∞ –Ω–∞–π–¥–µ–Ω–∞: {profile_url}")
                            return profile_url

                except Exception as e:
                    self.logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä '{selector}' –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue

            self.logger.info("‚ÑπÔ∏è –°—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–¥–∞–≤—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å: {e}")
            return None

    def _is_valid_avatar_url(self, url):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤–∞—Ç–∞—Ä–∫–∏"""
        if not url:
            return False
        return 'avito.st/image/1/1.' in url or 'stub_avatars' in url

    def _normalize_avatar_url(self, url):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL"""
        if not url:
            return None
        if url.startswith('//'):
            return 'https:' + url
        elif url.startswith('/'):
            return 'https://www.avito.ru' + url
        return url

    def _extract_description_full(self):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –ª–æ–≥–∞–º–∏"""
        try:
            # üî• –ü–†–û–ë–£–ï–ú –ù–ê–ô–¢–ò –ò –ù–ê–ñ–ê–¢–¨ –ö–ù–û–ü–ö–£ "–ß–ò–¢–ê–¢–¨ –ü–û–õ–ù–û–°–¢–¨–Æ"
            expand_selectors = [
                '//button[contains(text(), "–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é")]',
                '//a[contains(text(), "–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é")]',
                '[data-marker="item-description/expand"]',
                'button[aria-label*="—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å"]',
            ]

            clicked = False
            for selector in expand_selectors:
                try:
                    if selector.startswith('//'):
                        buttons = self.driver.find_elements(By.XPATH, selector)
                    else:
                        buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for button in buttons:
                        try:
                            self.driver.execute_script("arguments[0].click();", button)
                            time.sleep(0.5)
                            clicked = True
                            self.logger.info("‚úÖ –ö–Ω–æ–ø–∫–∞ '–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é' –Ω–∞–∂–∞—Ç–∞")
                            break
                        except:
                            continue
                    if clicked:
                        break
                except:
                    continue

            time.sleep(0.5)  # üî• –ñ–î–ï–ú –û–ë–ù–û–í–õ–ï–ù–ò–Ø –°–¢–†–ê–ù–ò–¶–´

            # üî• –ü–ï–†–í–´–ô –ü–†–ò–û–†–ò–¢–ï–¢: –ò–©–ï–ú –í <p> –≤–Ω—É—Ç—Ä–∏ data-marker
            try:
                # –ò—â–µ–º div —Å data-marker="item-view/item-description"
                desc_divs = self.driver.find_elements(By.CSS_SELECTOR, '[data-marker="item-view/item-description"]')
                for desc_div in desc_divs:
                    # –ò—â–µ–º –í–°–ï <p> –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ div
                    p_elements = desc_div.find_elements(By.TAG_NAME, 'p')
                    paragraphs = []
                    for p in p_elements:
                        p_text = p.text.strip()
                        if p_text:
                            paragraphs.append(p_text)

                    if paragraphs:
                        description = '\n\n'.join(paragraphs)
                        self.logger.info(f"‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑ <p> —Ç–µ–≥–æ–≤: {len(description)} —Å–∏–º–≤–æ–ª–æ–≤")
                        return description
            except:
                pass

            # üî• –í–¢–û–†–û–ô –ü–†–ò–û–†–ò–¢–ï–¢: –ë–ï–†–ï–ú –í–ï–°–¨ –¢–ï–ö–°–¢ –ò–ó data-marker
            description_selectors = [
                '[data-marker="item-view/item-description"]',
                '.style__item-description-text___XzQzYT',
                '[itemprop="description"]',
                '.item-description-text',
            ]

            description = None
            selector_used = None

            for selector in description_selectors:
                try:
                    desc_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for desc_elem in desc_elements:
                        desc_text = desc_elem.text.strip()
                        if desc_text and len(desc_text) > 10:
                            description = desc_text
                            selector_used = selector
                            break
                    if description:
                        break
                except:
                    continue

            # üî• –¢–†–ï–¢–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢: –†–û–î–ò–¢–ï–õ–¨–°–ö–ò–ô –ë–õ–û–ö
            if not description:
                parent_selectors = [
                    '#bx_item-description',
                    '.style__item-description___XzQzYT',
                    '.item-view-description'
                ]

                for selector in parent_selectors:
                    try:
                        parent_elems = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        for parent_elem in parent_elems:
                            # –ò—â–µ–º –í–°–ï <p> –≤–Ω—É—Ç—Ä–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –±–ª–æ–∫–∞
                            p_elements = parent_elem.find_elements(By.TAG_NAME, 'p')
                            paragraphs = []
                            for p in p_elements:
                                p_text = p.text.strip()
                                if p_text:
                                    paragraphs.append(p_text)

                            if paragraphs:
                                description = '\n\n'.join(paragraphs)
                                selector_used = "parent_p_tags"
                                break

                            # –ï—Å–ª–∏ –Ω–µ—Ç <p>, –±–µ—Ä–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
                            full_text = parent_elem.text.strip()
                            if full_text and len(full_text) > 50:
                                # –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ "–û–ø–∏—Å–∞–Ω–∏–µ"
                                lines = full_text.split('\n')
                                if len(lines) > 1:
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤–∞—è –ª–∏–Ω–∏—è —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                                    if lines[0].lower().strip() in ['–æ–ø–∏—Å–∞–Ω–∏–µ', 'description']:
                                        description = '\n'.join(lines[1:]).strip()
                                    else:
                                        description = full_text
                                else:
                                    description = full_text
                                selector_used = "parent_block"
                                break

                        if description:
                            break
                    except:
                        continue

            # üî• –õ–û–ì–ò
            if description:
                if selector_used == "parent_p_tags":
                    self.logger.info(f"‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑ <p> —Ç–µ–≥–æ–≤ —Ä–æ–¥–∏—Ç–µ–ª—è: {len(description)} —Å–∏–º–≤–æ–ª–æ–≤")
                elif selector_used == "parent_block":
                    self.logger.info(f"‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –±–ª–æ–∫–∞: {len(description)} —Å–∏–º–≤–æ–ª–æ–≤")
                else:
                    self.logger.info(f"‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ: {len(description)} —Å–∏–º–≤–æ–ª–æ–≤")
                return description
            else:
                self.logger.info("‚ÑπÔ∏è –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                return "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏—è: {e}")
            return "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"