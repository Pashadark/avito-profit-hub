import logging
import numpy as np
import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import defaultdict, deque
import hashlib

logger = logging.getLogger('parser.ai')


class FreshnessLearningSystem:
    """üî• –°–ò–°–¢–ï–ú–ê –û–ë–£–ß–ï–ù–ò–Ø –î–õ–Ø –°–í–ï–ñ–ï–°–¢–ò –û–ë–™–Ø–í–õ–ï–ù–ò–ô"""

    def __init__(self, db_path="freshness_knowledge.db"):
        self.db_path = db_path
        self.freshness_patterns = {}
        self.timing_optimization = {}
        self.category_freshness = {}
        self.successful_patterns = deque(maxlen=1000)

        # üî• –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô –°–í–ï–ñ–ï–°–¢–ò
        self.freshness_knowledge = {
            'publication_cycles': {},
            'optimal_times': {},
            'successful_queries': {},
            'category_patterns': {}
        }

        logger.info("üß† –°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

    async def learn_from_product(self, product_data: Dict[str, Any]):
        """üéØ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞ - –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î –î–õ–Ø –ü–ê–†–°–ï–†–ê"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            learning_entry = {
                'timestamp': datetime.now().isoformat(),
                'product_data': product_data,
                'freshness_score': product_data.get('freshness_score', 0),
                'time_listed': product_data.get('time_listed', 24)
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —É—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            self.successful_patterns.append(learning_entry)

            # üî• –û–ë–£–ß–ê–ï–ú–°–Ø –ù–ê –û–°–ù–û–í–ï –î–ê–ù–ù–´–• –¢–û–í–ê–†–ê
            category = product_data.get('category', 'unknown')
            found_time = datetime.now()

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä–µ–º–µ–Ω–∏
            await self._update_timing_pattern(category, found_time)

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ–∂–µ—Å—Ç–∏
            freshness_features = self._extract_freshness_features(product_data)
            await self._update_freshness_patterns(freshness_features, category)

            # –û–±–Ω–æ–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            query = product_data.get('search_query', '')
            if query:
                await self._update_successful_queries(query, category)

            logger.info(f"üìö –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ç–æ–≤–∞—Ä–µ: {product_data.get('name', 'Unknown')}")
            return True

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ç–æ–≤–∞—Ä–µ: {e}")
            return False

    async def learn_from_successful_finds(self, successful_items):
        """üî• –£–ß–ò–ú–°–Ø –Ω–∞ —É—Å–ø–µ—à–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –°–í–ï–ñ–ò–• –æ–±—ä—è–≤–ª–µ–Ω–∏—è—Ö"""
        try:
            logger.info(f"üß† –û–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(successful_items)} —Å–≤–µ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏—è—Ö...")

            for item in successful_items:
                # üî• –£–ß–ò–ú–°–Ø –ö–û–ì–î–ê –ü–û–Ø–í–õ–Ø–Æ–¢–°–Ø –°–í–ï–ñ–ò–ï –û–ë–™–Ø–í–õ–ï–ù–ò–Ø
                found_time = item.get('found_at')
                category = item.get('category', 'unknown')

                if found_time:
                    await self._update_timing_pattern(category, found_time)

                # üî• –£–ß–ò–ú–°–Ø –ü–†–ò–ó–ù–ê–ö–ê–ú –°–í–ï–ñ–ò–• –û–ë–™–Ø–í–õ–ï–ù–ò–ô
                freshness_features = self._extract_freshness_features(item)
                await self._update_freshness_patterns(freshness_features, category)

                # üî• –£–ß–ò–ú–°–Ø –£–°–ü–ï–®–ù–´–ú –ó–ê–ü–†–û–°–ê–ú
                query = item.get('search_query', '')
                if query:
                    await self._update_successful_queries(query, category)

            # üî• –°–û–•–†–ê–ù–Ø–ï–ú –û–ë–£–ß–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï
            await self._save_learning_state()

            logger.info("üéØ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")

    async def _update_timing_pattern(self, category, found_time):
        """üïí –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—è–≤–ª–µ–Ω–∏—è —Å–≤–µ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        try:
            if isinstance(found_time, str):
                found_time = datetime.fromisoformat(found_time.replace('Z', '+00:00'))

            hour = found_time.hour
            day_of_week = found_time.weekday()

            if category not in self.timing_optimization:
                self.timing_optimization[category] = {
                    'hourly_pattern': [0] * 24,
                    'daily_pattern': [0] * 7,
                    'total_finds': 0
                }

            # –û–ë–ù–û–í–õ–Ø–ï–ú –ß–ê–°–û–í–´–ï –ü–ê–¢–¢–ï–†–ù–´
            self.timing_optimization[category]['hourly_pattern'][hour] += 1
            self.timing_optimization[category]['daily_pattern'][day_of_week] += 1
            self.timing_optimization[category]['total_finds'] += 1

            logger.debug(f"üìä –û–±–Ω–æ–≤–ª–µ–Ω timing pattern –¥–ª—è {category}: —á–∞—Å {hour}, –¥–µ–Ω—å {day_of_week}")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è timing pattern: {e}")

    async def _update_freshness_patterns(self, features, category):
        """üéØ –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            if category not in self.freshness_patterns:
                self.freshness_patterns[category] = {
                    'feature_counts': defaultdict(int),
                    'total_samples': 0,
                    'successful_features': []
                }

            # –û–ë–ù–û–í–õ–Ø–ï–ú –°–ß–ï–¢–ß–ò–ö–ò –ü–†–ò–ó–ù–ê–ö–û–í
            for feature, value in features.items():
                if value > 0.5:  # –ó–Ω–∞—á–∏–º—ã–π –ø—Ä–∏–∑–Ω–∞–∫
                    feature_key = f"{feature}_{value:.1f}"
                    self.freshness_patterns[category]['feature_counts'][feature_key] += 1

            self.freshness_patterns[category]['total_samples'] += 1

            # –°–û–•–†–ê–ù–Ø–ï–ú –£–°–ü–ï–®–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´
            self.successful_patterns.append({
                'category': category,
                'features': features,
                'timestamp': datetime.now().isoformat()
            })

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è freshness patterns: {e}")

    async def _update_successful_queries(self, query, category):
        """üîç –û–±–Ω–æ–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã"""
        try:
            if category not in self.freshness_knowledge['successful_queries']:
                self.freshness_knowledge['successful_queries'][category] = {}

            if query not in self.freshness_knowledge['successful_queries'][category]:
                self.freshness_knowledge['successful_queries'][category][query] = 0

            self.freshness_knowledge['successful_queries'][category][query] += 1

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è successful queries: {e}")

    def _extract_freshness_features(self, item):
        """üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–≤–µ–∂–µ—Å—Ç–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            title = item.get('name', '').lower()
            description = item.get('description', '').lower()
            text = f"{title} {description}"

            features = {}

            # üî• –¢–ï–ö–°–¢–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò –°–í–ï–ñ–ï–°–¢–ò
            freshness_keywords = [
                '—Ç–æ–ª—å–∫–æ —á—Ç–æ', '—Å–µ–≥–æ–¥–Ω—è', '–º–∏–Ω—É—Ç', '—á–∞—Å', '—Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª–µ–Ω',
                '—Å—Ä–æ—á–Ω–æ', '–±—ã—Å—Ç—Ä–æ', '—Å—Ä–æ—á–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞', '–Ω–æ–≤—ã–π', '–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è'
            ]

            for keyword in freshness_keywords:
                features[f'keyword_{keyword}'] = 1.0 if keyword in text else 0.0

            # üî• –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
            time_listed = item.get('time_listed', 24)
            features['time_listed'] = min(time_listed / 24.0, 1.0)
            features['is_today'] = 1.0 if '—Å–µ–≥–æ–¥–Ω—è' in str(item.get('posted_date', '')).lower() else 0.0
            features['is_yesterday'] = 1.0 if '–≤—á–µ—Ä–∞' in str(item.get('posted_date', '')).lower() else 0.0

            # üî• –ü–†–ò–ó–ù–ê–ö–ò –ê–ö–¢–ò–í–ù–û–°–¢–ò
            features['has_images'] = 1.0 if item.get('images') else 0.0
            features['seller_rating'] = min(item.get('seller_rating', 0) / 5.0, 1.0)
            features['description_length'] = min(len(description) / 500.0, 1.0)

            return features

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")
            return {}

    async def get_optimal_search_times(self, category):
        """üïí –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—É—á—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        try:
            if category in self.timing_optimization:
                pattern = self.timing_optimization[category]['hourly_pattern']
                total_finds = self.timing_optimization[category]['total_finds']

                if total_finds > 10:
                    # –ù–û–†–ú–ê–õ–ò–ó–£–ï–ú –ò –ù–ê–•–û–î–ò–ú –ü–ò–ö–ò
                    normalized_pattern = [count / total_finds for count in pattern]
                    best_hours = sorted(range(24), key=lambda h: normalized_pattern[h], reverse=True)[:3]
                    return best_hours

            # üî• –ó–ê–ü–ê–°–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø
            return [9, 14, 19]  # –£—Ç—Ä–æ, –¥–µ–Ω—å, –≤–µ—á–µ—Ä

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏: {e}")
            return [9, 14, 19]

    async def get_successful_queries(self, category, limit=5):
        """üîç –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∞–º—ã–µ —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        try:
            if category in self.freshness_knowledge['successful_queries']:
                queries = self.freshness_knowledge['successful_queries'][category]
                sorted_queries = sorted(queries.items(), key=lambda x: x[1], reverse=True)
                return [q[0] for q in sorted_queries[:limit]]
            return []

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
            return []

    async def get_freshness_insights(self, category):
        """üìä –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        try:
            insights = {
                'optimal_times': await self.get_optimal_search_times(category),
                'successful_queries': await self.get_successful_queries(category),
                'total_learned_samples': 0,
                'feature_importance': [],
                'confidence_level': 'medium'
            }

            if category in self.freshness_patterns:
                pattern_data = self.freshness_patterns[category]
                insights['total_learned_samples'] = pattern_data['total_samples']

                # –¢–û–ü –ü–†–ò–ó–ù–ê–ö–ò
                top_features = sorted(
                    pattern_data['feature_counts'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:5]
                insights['feature_importance'] = top_features

                # –£–†–û–í–ï–ù–¨ –£–í–ï–†–ï–ù–ù–û–°–¢–ò
                if pattern_data['total_samples'] > 100:
                    insights['confidence_level'] = 'high'
                elif pattern_data['total_samples'] > 20:
                    insights['confidence_level'] = 'medium'
                else:
                    insights['confidence_level'] = 'low'

            return insights

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤: {e}")
            return {}

    async def collect_freshness_feedback(self, product, actual_freshness, predicted_freshness):
        """üì• –°–±–æ—Ä –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–≤–µ–∂–µ—Å—Ç–∏"""
        try:
            features = self._extract_freshness_features(product)
            error = abs(predicted_freshness - actual_freshness)

            # –°–û–•–†–ê–ù–Ø–ï–ú –î–õ–Ø –ë–£–î–£–©–ï–ì–û –û–ë–£–ß–ï–ù–ò–Ø
            feedback_data = {
                'timestamp': datetime.now().isoformat(),
                'category': product.get('category', 'unknown'),
                'features': features,
                'predicted_freshness': predicted_freshness,
                'actual_freshness': actual_freshness,
                'error': error,
                'product_title': product.get('name', '')[:100]
            }

            # –î–û–ë–ê–í–õ–Ø–ï–ú –í –û–ß–ï–†–ï–î–¨ –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø
            self.successful_patterns.append(feedback_data)

            logger.debug(f"üì• –°–æ–±—Ä–∞–Ω–∞ –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏. –û—à–∏–±–∫–∞: {error:.3f}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}")

    async def get_learning_progress(self):
        """üìà –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        try:
            total_categories = len(self.timing_optimization)
            total_samples = sum(
                pattern['total_samples']
                for pattern in self.freshness_patterns.values()
                if 'total_samples' in pattern
            )

            # –£–†–û–í–ï–ù–¨ –ò–ù–¢–ï–õ–õ–ï–ö–¢–ê –°–ò–°–¢–ï–ú–´
            intelligence_level = min(total_samples / 100.0, 1.0)

            return {
                'total_categories_learned': total_categories,
                'total_samples_collected': total_samples,
                'intelligence_level': f"{intelligence_level:.1%}",
                'successful_patterns_count': len(self.successful_patterns),
                'system_confidence': 'high' if intelligence_level > 0.7 else 'medium' if intelligence_level > 0.3 else 'low',
                'last_learning_update': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return {}

    async def _save_learning_state(self):
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            state = {
                'timing_optimization': self.timing_optimization,
                'freshness_patterns': self.freshness_patterns,
                'freshness_knowledge': self.freshness_knowledge,
                'successful_patterns': list(self.successful_patterns),
                'last_saved': datetime.now().isoformat()
            }

            with open('freshness_learning_state.json', 'w', encoding='utf-8') as f:
                json.dump(state, f, ensure_ascii=False, indent=2)

            logger.info("üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è: {e}")

    async def load_learning_state(self):
        """üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            with open('freshness_learning_state.json', 'r', encoding='utf-8') as f:
                state = json.load(f)

            self.timing_optimization = state.get('timing_optimization', {})
            self.freshness_patterns = state.get('freshness_patterns', {})
            self.freshness_knowledge = state.get('freshness_knowledge', {})
            self.successful_patterns = deque(
                state.get('successful_patterns', []),
                maxlen=1000
            )

            logger.info("üì• –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            return True

        except FileNotFoundError:
            logger.info("üì• –§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False

    async def get_learning_stats(self) -> Dict[str, Any]:
        """üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        progress = await self.get_learning_progress()
        return {
            'status': 'active',
            'system': 'FreshnessLearningSystem',
            'learning_samples': progress.get('total_samples_collected', 0),
            'patterns_learned': progress.get('successful_patterns_count', 0),
            'intelligence_level': progress.get('intelligence_level', '0%'),
            'confidence': progress.get('system_confidence', 'low')
        }